{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 구별로 모델 별도 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import joblib\n",
    "\n",
    "# 맥에서 글씨 깨짐 방지\n",
    "from matplotlib import rc\n",
    "rc('font', family='AppleGothic')\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_343037/938219984.py:1: DtypeWarning: Columns (16,17,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../data/16_over_30_under_50_years.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/16_over_30_under_50_years.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1128094, 89)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일부 feature 제거 - 기준은 내마음대로\n",
    "\n",
    "df.drop(['해제사유발생일', '등기신청일자', '거래유형', '중개사소재지', 'k-단지분류(아파트,주상복합등등)', 'k-전화번호',\n",
    "         'k-팩스번호', '단지소개기존clob', 'k-세대타입(분양형태)', 'k-복도유형', 'k-난방방식', 'k-전체동수', 'k-전체세대수',\n",
    "         'k-사용검사일-사용승인일', 'k-관리비부과면적', 'k-전용면적별세대현황(60이하)', 'k-전용면적별세대현황(60~85이하)',\n",
    "         'k-85~135이하', 'k-135초과', 'k-홈페이지', 'k-등록일자', 'k-수정일자', '고용보험관리번호', '경비비관리형태',\n",
    "         '기타/의무/임대/임의=1/2/3/4', '단지승인일', '사용허가여부', '관리비 업로드', '단지신청일'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추가로 제거가 필요한 feature 제거\n",
    "df.drop(['시군구', '번지', '본번', '부번', '아파트명', '도로명', 'k-관리방식', 'k-건설사(시공사)', 'k-시행사', 'k-연면적', 'k-주거전용면적',\n",
    "         '세대전기계약방법', '청소비관리형태', '건축면적', '주차대수', '시군구 번지', '좌표X,좌표Y', 'index', '역사_ID', '역사명', '위도', '경도',\n",
    "         '가장 가까운 버스 정류장 index', '가장 가까운 버스 정류장 노드 ID', '가장 가까운 버스 정류소번호', '가장 가까운 버스 정류소명',\n",
    "         '가장 가까운 버스 정류소 타입', '가장 가까운 버스 정류장 X좌표', '가장 가까운 버스 정류장 Y좌표', '동'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['전용면적', '계약년월', '계약일', '층', '건축년도', '좌표X', '좌표Y', 'target', 'is_test',\n",
       "       '가장 가까운 거리', '호선', '인근 지하철 역 개수', '가장 가까운 버스 정류장 거리', '인근 버스 정류장 개수',\n",
       "       '계약년', '계약월', 'GDP', '한국은행 기준금리', '기대 인플레이션', '지가지수', '아파트 인허가', '미분양',\n",
       "       '거래량', '건설사 랭킹', '구', '구별 지가지수', '공시지가 평균', '매수우위지수', '건물나이',\n",
       "       '30년이상50년이하'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['지가지수', '아파트 인허가', '미분양', '건설사 랭킹'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1128094, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>전용면적</th>\n",
       "      <th>계약년월</th>\n",
       "      <th>계약일</th>\n",
       "      <th>층</th>\n",
       "      <th>건축년도</th>\n",
       "      <th>좌표X</th>\n",
       "      <th>좌표Y</th>\n",
       "      <th>target</th>\n",
       "      <th>is_test</th>\n",
       "      <th>가장 가까운 거리</th>\n",
       "      <th>...</th>\n",
       "      <th>인근 버스 정류장 개수</th>\n",
       "      <th>계약년</th>\n",
       "      <th>계약월</th>\n",
       "      <th>GDP</th>\n",
       "      <th>한국은행 기준금리</th>\n",
       "      <th>기대 인플레이션</th>\n",
       "      <th>거래량</th>\n",
       "      <th>구</th>\n",
       "      <th>구별 지가지수</th>\n",
       "      <th>공시지가 평균</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79.97</td>\n",
       "      <td>201712</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1987</td>\n",
       "      <td>127.05721</td>\n",
       "      <td>37.476763</td>\n",
       "      <td>124000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1127.738351</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>1623074.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>13740.0</td>\n",
       "      <td>강남구</td>\n",
       "      <td>75.121</td>\n",
       "      <td>6.858562e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79.97</td>\n",
       "      <td>201712</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>1987</td>\n",
       "      <td>127.05721</td>\n",
       "      <td>37.476763</td>\n",
       "      <td>123500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1127.738351</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>1623074.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>13740.0</td>\n",
       "      <td>강남구</td>\n",
       "      <td>75.121</td>\n",
       "      <td>6.858562e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.98</td>\n",
       "      <td>201712</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>1987</td>\n",
       "      <td>127.05721</td>\n",
       "      <td>37.476763</td>\n",
       "      <td>91500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1127.738351</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>1623074.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>13740.0</td>\n",
       "      <td>강남구</td>\n",
       "      <td>75.121</td>\n",
       "      <td>6.858562e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79.97</td>\n",
       "      <td>201801</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1987</td>\n",
       "      <td>127.05721</td>\n",
       "      <td>37.476763</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1127.738351</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1725373.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>15107.0</td>\n",
       "      <td>강남구</td>\n",
       "      <td>75.461</td>\n",
       "      <td>7.322618e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.97</td>\n",
       "      <td>201801</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1987</td>\n",
       "      <td>127.05721</td>\n",
       "      <td>37.476763</td>\n",
       "      <td>117000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1127.738351</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1725373.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>15107.0</td>\n",
       "      <td>강남구</td>\n",
       "      <td>75.461</td>\n",
       "      <td>7.322618e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>79.97</td>\n",
       "      <td>201801</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "      <td>127.05721</td>\n",
       "      <td>37.476763</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1127.738351</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1725373.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>15107.0</td>\n",
       "      <td>강남구</td>\n",
       "      <td>75.461</td>\n",
       "      <td>7.322618e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>79.97</td>\n",
       "      <td>201803</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>1987</td>\n",
       "      <td>127.05721</td>\n",
       "      <td>37.476763</td>\n",
       "      <td>139500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1127.738351</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>1725373.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>24122.0</td>\n",
       "      <td>강남구</td>\n",
       "      <td>76.313</td>\n",
       "      <td>7.322618e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>54.98</td>\n",
       "      <td>201804</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1987</td>\n",
       "      <td>127.05721</td>\n",
       "      <td>37.476763</td>\n",
       "      <td>107500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1127.738351</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1725373.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>12347.0</td>\n",
       "      <td>강남구</td>\n",
       "      <td>76.483</td>\n",
       "      <td>7.322618e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>79.97</td>\n",
       "      <td>201806</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>1987</td>\n",
       "      <td>127.05721</td>\n",
       "      <td>37.476763</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1127.738351</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>1725373.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>10401.0</td>\n",
       "      <td>강남구</td>\n",
       "      <td>77.037</td>\n",
       "      <td>7.322618e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>54.98</td>\n",
       "      <td>201807</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1987</td>\n",
       "      <td>127.05721</td>\n",
       "      <td>37.476763</td>\n",
       "      <td>112000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1127.738351</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>1725373.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>11753.0</td>\n",
       "      <td>강남구</td>\n",
       "      <td>77.567</td>\n",
       "      <td>7.322618e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    전용면적    계약년월  계약일  층  건축년도        좌표X        좌표Y    target  is_test  \\\n",
       "0  79.97  201712    8  3  1987  127.05721  37.476763  124000.0        0   \n",
       "1  79.97  201712   22  4  1987  127.05721  37.476763  123500.0        0   \n",
       "2  54.98  201712   28  5  1987  127.05721  37.476763   91500.0        0   \n",
       "3  79.97  201801    3  4  1987  127.05721  37.476763  130000.0        0   \n",
       "4  79.97  201801    8  2  1987  127.05721  37.476763  117000.0        0   \n",
       "5  79.97  201801   11  1  1987  127.05721  37.476763  130000.0        0   \n",
       "6  79.97  201803   19  2  1987  127.05721  37.476763  139500.0        0   \n",
       "7  54.98  201804    5  5  1987  127.05721  37.476763  107500.0        0   \n",
       "8  79.97  201806   28  3  1987  127.05721  37.476763  145000.0        0   \n",
       "9  54.98  201807    9  3  1987  127.05721  37.476763  112000.0        0   \n",
       "\n",
       "     가장 가까운 거리  ... 인근 버스 정류장 개수   계약년  계약월        GDP  한국은행 기준금리  기대 인플레이션  \\\n",
       "0  1127.738351  ...          7.0  2017   12  1623074.1        1.5       2.5   \n",
       "1  1127.738351  ...          7.0  2017   12  1623074.1        1.5       2.5   \n",
       "2  1127.738351  ...          7.0  2017   12  1623074.1        1.5       2.5   \n",
       "3  1127.738351  ...          7.0  2018    1  1725373.4        1.5       2.6   \n",
       "4  1127.738351  ...          7.0  2018    1  1725373.4        1.5       2.6   \n",
       "5  1127.738351  ...          7.0  2018    1  1725373.4        1.5       2.6   \n",
       "6  1127.738351  ...          7.0  2018    3  1725373.4        1.5       2.6   \n",
       "7  1127.738351  ...          7.0  2018    4  1725373.4        1.5       2.6   \n",
       "8  1127.738351  ...          7.0  2018    6  1725373.4        1.5       2.6   \n",
       "9  1127.738351  ...          7.0  2018    7  1725373.4        1.5       2.6   \n",
       "\n",
       "       거래량    구  구별 지가지수       공시지가 평균  \n",
       "0  13740.0  강남구   75.121  6.858562e+06  \n",
       "1  13740.0  강남구   75.121  6.858562e+06  \n",
       "2  13740.0  강남구   75.121  6.858562e+06  \n",
       "3  15107.0  강남구   75.461  7.322618e+06  \n",
       "4  15107.0  강남구   75.461  7.322618e+06  \n",
       "5  15107.0  강남구   75.461  7.322618e+06  \n",
       "6  24122.0  강남구   76.313  7.322618e+06  \n",
       "7  12347.0  강남구   76.483  7.322618e+06  \n",
       "8  10401.0  강남구   77.037  7.322618e+06  \n",
       "9  11753.0  강남구   77.567  7.322618e+06  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 계약월 변수 생성\n",
    "df['계약월'] = df['계약년월'].astype(str).str[4:].astype(int)\n",
    "\n",
    "# 계약년월, 계약일, 건축년도, 계약년 변수 제거\n",
    "df.drop(['계약년월', '계약일'], axis=1, inplace=True)\n",
    "\n",
    "df['계약월_sin'] = np.sin(2 * np.pi * df['계약월'] / 12)\n",
    "df.drop(['계약월'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>전용면적</th>\n",
       "      <th>층</th>\n",
       "      <th>건축년도</th>\n",
       "      <th>좌표X</th>\n",
       "      <th>좌표Y</th>\n",
       "      <th>target</th>\n",
       "      <th>is_test</th>\n",
       "      <th>가장 가까운 거리</th>\n",
       "      <th>호선</th>\n",
       "      <th>인근 지하철 역 개수</th>\n",
       "      <th>...</th>\n",
       "      <th>인근 버스 정류장 개수</th>\n",
       "      <th>계약년</th>\n",
       "      <th>GDP</th>\n",
       "      <th>한국은행 기준금리</th>\n",
       "      <th>기대 인플레이션</th>\n",
       "      <th>거래량</th>\n",
       "      <th>구</th>\n",
       "      <th>구별 지가지수</th>\n",
       "      <th>공시지가 평균</th>\n",
       "      <th>계약월_sin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79.97</td>\n",
       "      <td>3</td>\n",
       "      <td>1987</td>\n",
       "      <td>127.05721</td>\n",
       "      <td>37.476763</td>\n",
       "      <td>124000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1127.738351</td>\n",
       "      <td>분당선</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>1623074.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>13740.0</td>\n",
       "      <td>강남구</td>\n",
       "      <td>75.121</td>\n",
       "      <td>6.858562e+06</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79.97</td>\n",
       "      <td>4</td>\n",
       "      <td>1987</td>\n",
       "      <td>127.05721</td>\n",
       "      <td>37.476763</td>\n",
       "      <td>123500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1127.738351</td>\n",
       "      <td>분당선</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>1623074.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>13740.0</td>\n",
       "      <td>강남구</td>\n",
       "      <td>75.121</td>\n",
       "      <td>6.858562e+06</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.98</td>\n",
       "      <td>5</td>\n",
       "      <td>1987</td>\n",
       "      <td>127.05721</td>\n",
       "      <td>37.476763</td>\n",
       "      <td>91500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1127.738351</td>\n",
       "      <td>분당선</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>1623074.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>13740.0</td>\n",
       "      <td>강남구</td>\n",
       "      <td>75.121</td>\n",
       "      <td>6.858562e+06</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79.97</td>\n",
       "      <td>4</td>\n",
       "      <td>1987</td>\n",
       "      <td>127.05721</td>\n",
       "      <td>37.476763</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1127.738351</td>\n",
       "      <td>분당선</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1725373.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>15107.0</td>\n",
       "      <td>강남구</td>\n",
       "      <td>75.461</td>\n",
       "      <td>7.322618e+06</td>\n",
       "      <td>5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.97</td>\n",
       "      <td>2</td>\n",
       "      <td>1987</td>\n",
       "      <td>127.05721</td>\n",
       "      <td>37.476763</td>\n",
       "      <td>117000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1127.738351</td>\n",
       "      <td>분당선</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1725373.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>15107.0</td>\n",
       "      <td>강남구</td>\n",
       "      <td>75.461</td>\n",
       "      <td>7.322618e+06</td>\n",
       "      <td>5.000000e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    전용면적  층  건축년도        좌표X        좌표Y    target  is_test    가장 가까운 거리   호선  \\\n",
       "0  79.97  3  1987  127.05721  37.476763  124000.0        0  1127.738351  분당선   \n",
       "1  79.97  4  1987  127.05721  37.476763  123500.0        0  1127.738351  분당선   \n",
       "2  54.98  5  1987  127.05721  37.476763   91500.0        0  1127.738351  분당선   \n",
       "3  79.97  4  1987  127.05721  37.476763  130000.0        0  1127.738351  분당선   \n",
       "4  79.97  2  1987  127.05721  37.476763  117000.0        0  1127.738351  분당선   \n",
       "\n",
       "   인근 지하철 역 개수  ...  인근 버스 정류장 개수   계약년        GDP  한국은행 기준금리  기대 인플레이션  \\\n",
       "0          2.0  ...           7.0  2017  1623074.1        1.5       2.5   \n",
       "1          2.0  ...           7.0  2017  1623074.1        1.5       2.5   \n",
       "2          2.0  ...           7.0  2017  1623074.1        1.5       2.5   \n",
       "3          2.0  ...           7.0  2018  1725373.4        1.5       2.6   \n",
       "4          2.0  ...           7.0  2018  1725373.4        1.5       2.6   \n",
       "\n",
       "       거래량    구 구별 지가지수       공시지가 평균       계약월_sin  \n",
       "0  13740.0  강남구  75.121  6.858562e+06 -2.449294e-16  \n",
       "1  13740.0  강남구  75.121  6.858562e+06 -2.449294e-16  \n",
       "2  13740.0  강남구  75.121  6.858562e+06 -2.449294e-16  \n",
       "3  15107.0  강남구  75.461  7.322618e+06  5.000000e-01  \n",
       "4  15107.0  강남구  75.461  7.322618e+06  5.000000e-01  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['전용면적', '층', '건축년도', '좌표X', '좌표Y', 'target', 'is_test', '가장 가까운 거리',\n",
       "       '호선', '인근 지하철 역 개수', '가장 가까운 버스 정류장 거리', '인근 버스 정류장 개수', '계약년', 'GDP',\n",
       "       '한국은행 기준금리', '기대 인플레이션', '거래량', '구', '구별 지가지수', '공시지가 평균', '계약월_sin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전용면적\n",
      "층\n",
      "건축년도\n",
      "좌표X\n",
      "좌표Y\n",
      "가장 가까운 거리\n",
      "인근 지하철 역 개수\n",
      "가장 가까운 버스 정류장 거리\n",
      "인근 버스 정류장 개수\n",
      "계약년\n",
      "GDP\n",
      "한국은행 기준금리\n",
      "기대 인플레이션\n",
      "거래량\n",
      "구별 지가지수\n",
      "공시지가 평균\n",
      "계약월_sin\n"
     ]
    }
   ],
   "source": [
    "def scailing(col, scaler_type):\n",
    "    if scaler_type == 'min_max': scaler = MinMaxScaler()\n",
    "    else : scaler = StandardScaler()\n",
    "\n",
    "    return scaler.fit_transform(df[[col]])\n",
    "\n",
    "cols = ['전용면적', '층', '건축년도', '좌표X', '좌표Y', '가장 가까운 거리',\n",
    "       '인근 지하철 역 개수', '가장 가까운 버스 정류장 거리', '인근 버스 정류장 개수', '계약년', 'GDP',\n",
    "       '한국은행 기준금리', '기대 인플레이션', '거래량', '구별 지가지수', '공시지가 평균', '계약월_sin']\n",
    "\n",
    "for col in cols:\n",
    "    print(col)\n",
    "    scaler_type = 'min_max'\n",
    "    if col == '계약월_sin': scaler_type = 'standard'\n",
    "\n",
    "    df[[col]] = scailing(col, scaler_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>전용면적</th>\n",
       "      <th>층</th>\n",
       "      <th>건축년도</th>\n",
       "      <th>좌표X</th>\n",
       "      <th>좌표Y</th>\n",
       "      <th>target</th>\n",
       "      <th>is_test</th>\n",
       "      <th>가장 가까운 거리</th>\n",
       "      <th>호선</th>\n",
       "      <th>인근 지하철 역 개수</th>\n",
       "      <th>...</th>\n",
       "      <th>인근 버스 정류장 개수</th>\n",
       "      <th>계약년</th>\n",
       "      <th>GDP</th>\n",
       "      <th>한국은행 기준금리</th>\n",
       "      <th>기대 인플레이션</th>\n",
       "      <th>거래량</th>\n",
       "      <th>구</th>\n",
       "      <th>구별 지가지수</th>\n",
       "      <th>공시지가 평균</th>\n",
       "      <th>계약월_sin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.168839</td>\n",
       "      <td>0.095890</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.678243</td>\n",
       "      <td>0.167126</td>\n",
       "      <td>124000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.353721</td>\n",
       "      <td>분당선</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.776663</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.466276</td>\n",
       "      <td>강남구</td>\n",
       "      <td>0.395747</td>\n",
       "      <td>0.509398</td>\n",
       "      <td>-0.022272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.168839</td>\n",
       "      <td>0.109589</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.678243</td>\n",
       "      <td>0.167126</td>\n",
       "      <td>123500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.353721</td>\n",
       "      <td>분당선</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.776663</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.466276</td>\n",
       "      <td>강남구</td>\n",
       "      <td>0.395747</td>\n",
       "      <td>0.509398</td>\n",
       "      <td>-0.022272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.108520</td>\n",
       "      <td>0.123288</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.678243</td>\n",
       "      <td>0.167126</td>\n",
       "      <td>91500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.353721</td>\n",
       "      <td>분당선</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.776663</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.466276</td>\n",
       "      <td>강남구</td>\n",
       "      <td>0.395747</td>\n",
       "      <td>0.509398</td>\n",
       "      <td>-0.022272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.168839</td>\n",
       "      <td>0.109589</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.678243</td>\n",
       "      <td>0.167126</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.353721</td>\n",
       "      <td>분당선</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.893613</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.522738</td>\n",
       "      <td>강남구</td>\n",
       "      <td>0.403844</td>\n",
       "      <td>0.551484</td>\n",
       "      <td>0.684200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.168839</td>\n",
       "      <td>0.082192</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.678243</td>\n",
       "      <td>0.167126</td>\n",
       "      <td>117000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.353721</td>\n",
       "      <td>분당선</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.893613</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.522738</td>\n",
       "      <td>강남구</td>\n",
       "      <td>0.403844</td>\n",
       "      <td>0.551484</td>\n",
       "      <td>0.684200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128089</th>\n",
       "      <td>0.180135</td>\n",
       "      <td>0.232877</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.807949</td>\n",
       "      <td>0.728162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.227756</td>\n",
       "      <td>경춘선</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.879231</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.149932</td>\n",
       "      <td>중랑구</td>\n",
       "      <td>0.964896</td>\n",
       "      <td>0.156150</td>\n",
       "      <td>-0.728745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128090</th>\n",
       "      <td>0.180063</td>\n",
       "      <td>0.219178</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.807949</td>\n",
       "      <td>0.728162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.227756</td>\n",
       "      <td>경춘선</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.879231</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.149932</td>\n",
       "      <td>중랑구</td>\n",
       "      <td>0.964896</td>\n",
       "      <td>0.156150</td>\n",
       "      <td>-0.728745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128091</th>\n",
       "      <td>0.221168</td>\n",
       "      <td>0.219178</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.807949</td>\n",
       "      <td>0.728162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.227756</td>\n",
       "      <td>경춘선</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.879231</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.176160</td>\n",
       "      <td>중랑구</td>\n",
       "      <td>0.967372</td>\n",
       "      <td>0.156150</td>\n",
       "      <td>-1.245919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128092</th>\n",
       "      <td>0.180835</td>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.807949</td>\n",
       "      <td>0.728162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.227756</td>\n",
       "      <td>경춘선</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.879231</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.162942</td>\n",
       "      <td>중랑구</td>\n",
       "      <td>0.972255</td>\n",
       "      <td>0.156150</td>\n",
       "      <td>-1.435218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128093</th>\n",
       "      <td>0.180135</td>\n",
       "      <td>0.232877</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.807949</td>\n",
       "      <td>0.728162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.227756</td>\n",
       "      <td>경춘선</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.879231</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.162942</td>\n",
       "      <td>중랑구</td>\n",
       "      <td>0.972255</td>\n",
       "      <td>0.156150</td>\n",
       "      <td>-1.435218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1128094 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             전용면적         층      건축년도       좌표X       좌표Y    target  is_test  \\\n",
       "0        0.168839  0.095890  0.419355  0.678243  0.167126  124000.0        0   \n",
       "1        0.168839  0.109589  0.419355  0.678243  0.167126  123500.0        0   \n",
       "2        0.108520  0.123288  0.419355  0.678243  0.167126   91500.0        0   \n",
       "3        0.168839  0.109589  0.419355  0.678243  0.167126  130000.0        0   \n",
       "4        0.168839  0.082192  0.419355  0.678243  0.167126  117000.0        0   \n",
       "...           ...       ...       ...       ...       ...       ...      ...   \n",
       "1128089  0.180135  0.232877  0.854839  0.807949  0.728162       NaN        1   \n",
       "1128090  0.180063  0.219178  0.854839  0.807949  0.728162       NaN        1   \n",
       "1128091  0.221168  0.219178  0.854839  0.807949  0.728162       NaN        1   \n",
       "1128092  0.180835  0.301370  0.854839  0.807949  0.728162       NaN        1   \n",
       "1128093  0.180135  0.232877  0.854839  0.807949  0.728162       NaN        1   \n",
       "\n",
       "         가장 가까운 거리   호선  인근 지하철 역 개수  ...  인근 버스 정류장 개수     계약년       GDP  \\\n",
       "0         0.353721  분당선     0.086957  ...           0.2  0.6250  0.776663   \n",
       "1         0.353721  분당선     0.086957  ...           0.2  0.6250  0.776663   \n",
       "2         0.353721  분당선     0.086957  ...           0.2  0.6250  0.776663   \n",
       "3         0.353721  분당선     0.086957  ...           0.2  0.6875  0.893613   \n",
       "4         0.353721  분당선     0.086957  ...           0.2  0.6875  0.893613   \n",
       "...            ...  ...          ...  ...           ...     ...       ...   \n",
       "1128089   0.227756  경춘선     0.173913  ...           0.2  1.0000  0.879231   \n",
       "1128090   0.227756  경춘선     0.173913  ...           0.2  1.0000  0.879231   \n",
       "1128091   0.227756  경춘선     0.173913  ...           0.2  1.0000  0.879231   \n",
       "1128092   0.227756  경춘선     0.173913  ...           0.2  1.0000  0.879231   \n",
       "1128093   0.227756  경춘선     0.173913  ...           0.2  1.0000  0.879231   \n",
       "\n",
       "         한국은행 기준금리  기대 인플레이션       거래량    구   구별 지가지수   공시지가 평균   계약월_sin  \n",
       "0         0.210526  0.290323  0.466276  강남구  0.395747  0.509398 -0.022272  \n",
       "1         0.210526  0.290323  0.466276  강남구  0.395747  0.509398 -0.022272  \n",
       "2         0.210526  0.290323  0.466276  강남구  0.395747  0.509398 -0.022272  \n",
       "3         0.210526  0.322581  0.522738  강남구  0.403844  0.551484  0.684200  \n",
       "4         0.210526  0.322581  0.522738  강남구  0.403844  0.551484  0.684200  \n",
       "...            ...       ...       ...  ...       ...       ...       ...  \n",
       "1128089   0.631579  0.548387  0.149932  중랑구  0.964896  0.156150 -0.728745  \n",
       "1128090   0.631579  0.548387  0.149932  중랑구  0.964896  0.156150 -0.728745  \n",
       "1128091   0.631579  0.548387  0.176160  중랑구  0.967372  0.156150 -1.245919  \n",
       "1128092   0.631579  0.548387  0.162942  중랑구  0.972255  0.156150 -1.435218  \n",
       "1128093   0.631579  0.548387  0.162942  중랑구  0.972255  0.156150 -1.435218  \n",
       "\n",
       "[1128094 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 호선 One-Hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ohe = OneHotEncoder(sparse=False)\n",
    "ohe_re = ohe.fit_transform(df[['호선']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>전용면적</th>\n",
       "      <th>층</th>\n",
       "      <th>건축년도</th>\n",
       "      <th>좌표X</th>\n",
       "      <th>좌표Y</th>\n",
       "      <th>target</th>\n",
       "      <th>is_test</th>\n",
       "      <th>가장 가까운 거리</th>\n",
       "      <th>호선</th>\n",
       "      <th>인근 지하철 역 개수</th>\n",
       "      <th>...</th>\n",
       "      <th>경춘선</th>\n",
       "      <th>공항철도1호선</th>\n",
       "      <th>과천선</th>\n",
       "      <th>분당선</th>\n",
       "      <th>신림선</th>\n",
       "      <th>신분당선</th>\n",
       "      <th>신분당선(연장2)</th>\n",
       "      <th>우이신설선</th>\n",
       "      <th>일산선</th>\n",
       "      <th>중앙선</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.168839</td>\n",
       "      <td>0.095890</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.678243</td>\n",
       "      <td>0.167126</td>\n",
       "      <td>124000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.353721</td>\n",
       "      <td>분당선</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.168839</td>\n",
       "      <td>0.109589</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.678243</td>\n",
       "      <td>0.167126</td>\n",
       "      <td>123500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.353721</td>\n",
       "      <td>분당선</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.108520</td>\n",
       "      <td>0.123288</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.678243</td>\n",
       "      <td>0.167126</td>\n",
       "      <td>91500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.353721</td>\n",
       "      <td>분당선</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.168839</td>\n",
       "      <td>0.109589</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.678243</td>\n",
       "      <td>0.167126</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.353721</td>\n",
       "      <td>분당선</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.168839</td>\n",
       "      <td>0.082192</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.678243</td>\n",
       "      <td>0.167126</td>\n",
       "      <td>117000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.353721</td>\n",
       "      <td>분당선</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128089</th>\n",
       "      <td>0.180135</td>\n",
       "      <td>0.232877</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.807949</td>\n",
       "      <td>0.728162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.227756</td>\n",
       "      <td>경춘선</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128090</th>\n",
       "      <td>0.180063</td>\n",
       "      <td>0.219178</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.807949</td>\n",
       "      <td>0.728162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.227756</td>\n",
       "      <td>경춘선</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128091</th>\n",
       "      <td>0.221168</td>\n",
       "      <td>0.219178</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.807949</td>\n",
       "      <td>0.728162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.227756</td>\n",
       "      <td>경춘선</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128092</th>\n",
       "      <td>0.180835</td>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.807949</td>\n",
       "      <td>0.728162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.227756</td>\n",
       "      <td>경춘선</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128093</th>\n",
       "      <td>0.180135</td>\n",
       "      <td>0.232877</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.807949</td>\n",
       "      <td>0.728162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.227756</td>\n",
       "      <td>경춘선</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1128094 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             전용면적         층      건축년도       좌표X       좌표Y    target  is_test  \\\n",
       "0        0.168839  0.095890  0.419355  0.678243  0.167126  124000.0        0   \n",
       "1        0.168839  0.109589  0.419355  0.678243  0.167126  123500.0        0   \n",
       "2        0.108520  0.123288  0.419355  0.678243  0.167126   91500.0        0   \n",
       "3        0.168839  0.109589  0.419355  0.678243  0.167126  130000.0        0   \n",
       "4        0.168839  0.082192  0.419355  0.678243  0.167126  117000.0        0   \n",
       "...           ...       ...       ...       ...       ...       ...      ...   \n",
       "1128089  0.180135  0.232877  0.854839  0.807949  0.728162       NaN        1   \n",
       "1128090  0.180063  0.219178  0.854839  0.807949  0.728162       NaN        1   \n",
       "1128091  0.221168  0.219178  0.854839  0.807949  0.728162       NaN        1   \n",
       "1128092  0.180835  0.301370  0.854839  0.807949  0.728162       NaN        1   \n",
       "1128093  0.180135  0.232877  0.854839  0.807949  0.728162       NaN        1   \n",
       "\n",
       "         가장 가까운 거리   호선  인근 지하철 역 개수  ...  경춘선  공항철도1호선  과천선  분당선  신림선  신분당선  \\\n",
       "0         0.353721  분당선     0.086957  ...  0.0      0.0  0.0  1.0  0.0   0.0   \n",
       "1         0.353721  분당선     0.086957  ...  0.0      0.0  0.0  1.0  0.0   0.0   \n",
       "2         0.353721  분당선     0.086957  ...  0.0      0.0  0.0  1.0  0.0   0.0   \n",
       "3         0.353721  분당선     0.086957  ...  0.0      0.0  0.0  1.0  0.0   0.0   \n",
       "4         0.353721  분당선     0.086957  ...  0.0      0.0  0.0  1.0  0.0   0.0   \n",
       "...            ...  ...          ...  ...  ...      ...  ...  ...  ...   ...   \n",
       "1128089   0.227756  경춘선     0.173913  ...  1.0      0.0  0.0  0.0  0.0   0.0   \n",
       "1128090   0.227756  경춘선     0.173913  ...  1.0      0.0  0.0  0.0  0.0   0.0   \n",
       "1128091   0.227756  경춘선     0.173913  ...  1.0      0.0  0.0  0.0  0.0   0.0   \n",
       "1128092   0.227756  경춘선     0.173913  ...  1.0      0.0  0.0  0.0  0.0   0.0   \n",
       "1128093   0.227756  경춘선     0.173913  ...  1.0      0.0  0.0  0.0  0.0   0.0   \n",
       "\n",
       "         신분당선(연장2) 우이신설선  일산선  중앙선  \n",
       "0              0.0   0.0  0.0  0.0  \n",
       "1              0.0   0.0  0.0  0.0  \n",
       "2              0.0   0.0  0.0  0.0  \n",
       "3              0.0   0.0  0.0  0.0  \n",
       "4              0.0   0.0  0.0  0.0  \n",
       "...            ...   ...  ...  ...  \n",
       "1128089        0.0   0.0  0.0  0.0  \n",
       "1128090        0.0   0.0  0.0  0.0  \n",
       "1128091        0.0   0.0  0.0  0.0  \n",
       "1128092        0.0   0.0  0.0  0.0  \n",
       "1128093        0.0   0.0  0.0  0.0  \n",
       "\n",
       "[1128094 rows x 45 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df, pd.DataFrame(ohe_re, columns=[col for col in ohe.categories_[0]])], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['호선'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df['is_test'] == 0]\n",
    "test_df = df[df['is_test'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1118822, 44)\n",
      "(9272, 44)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_325043/1571330888.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop(['is_test'], axis=1, inplace=True)\n",
      "/tmp/ipykernel_325043/1571330888.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop(['is_test'], axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "train_df.drop(['is_test'], axis=1, inplace=True)\n",
    "test_df.drop(['is_test'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1118822, 43)\n",
      "(9272, 43)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 구별로 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['강남구',\n",
       " '강동구',\n",
       " '강북구',\n",
       " '강서구',\n",
       " '관악구',\n",
       " '광진구',\n",
       " '구로구',\n",
       " '금천구',\n",
       " '노원구',\n",
       " '도봉구',\n",
       " '동대문구',\n",
       " '동작구',\n",
       " '마포구',\n",
       " '서대문구',\n",
       " '서초구',\n",
       " '성동구',\n",
       " '성북구',\n",
       " '송파구',\n",
       " '양천구',\n",
       " '영등포구',\n",
       " '용산구',\n",
       " '은평구',\n",
       " '종로구',\n",
       " '중구',\n",
       " '중랑구']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "district_list = train_df['구'].unique().tolist()\n",
    "print(len(district_list))\n",
    "district_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_list = []\n",
    "\n",
    "for district in district_list:\n",
    "    train_df_list.append(train_df[train_df['구'] == district])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>구</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>강남구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>강남구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>강남구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>강남구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>강남구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118450</th>\n",
       "      <td>강남구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118451</th>\n",
       "      <td>강남구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118452</th>\n",
       "      <td>강남구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118453</th>\n",
       "      <td>강남구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118454</th>\n",
       "      <td>강남구</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69083 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           구\n",
       "0        강남구\n",
       "1        강남구\n",
       "2        강남구\n",
       "3        강남구\n",
       "4        강남구\n",
       "...      ...\n",
       "1118450  강남구\n",
       "1118451  강남구\n",
       "1118452  강남구\n",
       "1118453  강남구\n",
       "1118454  강남구\n",
       "\n",
       "[69083 rows x 1 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_list[0][['구']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_list = []\n",
    "\n",
    "for district in district_list:\n",
    "    test_df_list.append(test_df[test_df['구'] == district])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>구</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1118822</th>\n",
       "      <td>강남구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118823</th>\n",
       "      <td>강남구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118824</th>\n",
       "      <td>강남구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118825</th>\n",
       "      <td>강남구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118826</th>\n",
       "      <td>강남구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123928</th>\n",
       "      <td>강남구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123929</th>\n",
       "      <td>강남구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123930</th>\n",
       "      <td>강남구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123931</th>\n",
       "      <td>강남구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123932</th>\n",
       "      <td>강남구</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>573 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           구\n",
       "1118822  강남구\n",
       "1118823  강남구\n",
       "1118824  강남구\n",
       "1118825  강남구\n",
       "1118826  강남구\n",
       "...      ...\n",
       "1123928  강남구\n",
       "1123929  강남구\n",
       "1123930  강남구\n",
       "1123931  강남구\n",
       "1123932  강남구\n",
       "\n",
       "[573 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_list[0][['구']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data X, y 분할\n",
    "train_X_list = []\n",
    "train_y_list = []\n",
    "\n",
    "for i in range(25):\n",
    "    train_X_list.append(train_df_list[i].drop(['target'], axis=1))\n",
    "    train_y_list.append(train_df_list[i][['target']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['전용면적', '층', '건축년도', '좌표X', '좌표Y', '가장 가까운 거리', '인근 지하철 역 개수',\n",
       "       '가장 가까운 버스 정류장 거리', '인근 버스 정류장 개수', '계약년', 'GDP', '한국은행 기준금리',\n",
       "       '기대 인플레이션', '거래량', '구', '구별 지가지수', '공시지가 평균', '계약월_sin', '1호선', '2호선',\n",
       "       '3호선', '4호선', '5호선', '6호선', '7호선', '8호선', '9호선', '9호선(연장)', '경부선',\n",
       "       '경원선', '경의중앙선', '경인선', '경춘선', '공항철도1호선', '과천선', '분당선', '신림선', '신분당선',\n",
       "       '신분당선(연장2)', '우이신설선', '일산선', '중앙선'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_list[0].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train, valid 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_X_list = [None for _ in range(25)]\n",
    "valid_y_list = [None for _ in range(25)]\n",
    "\n",
    "for i in range(25):\n",
    "    train_X_list[i], valid_X_list[i], train_y_list[i], valid_y_list[i] = train_test_split(train_X_list[i], train_y_list[i], train_size=0.9, test_size=0.1, random_state=74)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'metric_freq': 20,\n",
    "    'device': 'gpu',\n",
    "    'verbosity': 0\n",
    "}\n",
    "\n",
    "def make_model(train_X, train_y, valid_X, valid_y, i):\n",
    "    model = lgb.LGBMRegressor(n_estimators=100000,\n",
    "                          metric='rmse',\n",
    "                          data_sample_strategy='goss')\n",
    "    \n",
    "    model.fit(\n",
    "        train_X, train_y,\n",
    "        eval_set = [(train_X, train_y), (valid_X, valid_y)],\n",
    "        eval_metric='rmse',\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=60),\n",
    "                   lgb.log_evaluation(period=10, show_stdv=True)]\n",
    "    )\n",
    "\n",
    "    joblib.dump(model, f'../models/14/{i}.pkl')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001015 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1890\n",
      "[LightGBM] [Info] Number of data points in the train set: 62174, number of used features: 25\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 114864.819860\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[10]\ttraining's rmse: 40944.5\tvalid_1's rmse: 40829.2\n",
      "[20]\ttraining's rmse: 27631.5\tvalid_1's rmse: 27720.3\n",
      "[30]\ttraining's rmse: 21882.4\tvalid_1's rmse: 22116.3\n",
      "[40]\ttraining's rmse: 19117.4\tvalid_1's rmse: 19448.1\n",
      "[50]\ttraining's rmse: 17438.8\tvalid_1's rmse: 17856.7\n",
      "[60]\ttraining's rmse: 16352.9\tvalid_1's rmse: 16795.8\n",
      "[70]\ttraining's rmse: 15540.8\tvalid_1's rmse: 16049\n",
      "[80]\ttraining's rmse: 14887.1\tvalid_1's rmse: 15411\n",
      "[90]\ttraining's rmse: 14401.4\tvalid_1's rmse: 14981.1\n",
      "[100]\ttraining's rmse: 13936.7\tvalid_1's rmse: 14614.5\n",
      "[110]\ttraining's rmse: 13563.9\tvalid_1's rmse: 14327.3\n",
      "[120]\ttraining's rmse: 13253.1\tvalid_1's rmse: 14058.2\n",
      "[130]\ttraining's rmse: 12959.1\tvalid_1's rmse: 13837.9\n",
      "[140]\ttraining's rmse: 12708.2\tvalid_1's rmse: 13645\n",
      "[150]\ttraining's rmse: 12454.2\tvalid_1's rmse: 13461.8\n",
      "[160]\ttraining's rmse: 12226\tvalid_1's rmse: 13281.8\n",
      "[170]\ttraining's rmse: 12046.8\tvalid_1's rmse: 13168.9\n",
      "[180]\ttraining's rmse: 11859.2\tvalid_1's rmse: 13038.7\n",
      "[190]\ttraining's rmse: 11689.7\tvalid_1's rmse: 12930.8\n",
      "[200]\ttraining's rmse: 11529.4\tvalid_1's rmse: 12816.1\n",
      "[210]\ttraining's rmse: 11398.2\tvalid_1's rmse: 12724.4\n",
      "[220]\ttraining's rmse: 11245.7\tvalid_1's rmse: 12621.3\n",
      "[230]\ttraining's rmse: 11118.5\tvalid_1's rmse: 12541.5\n",
      "[240]\ttraining's rmse: 10985.3\tvalid_1's rmse: 12487.8\n",
      "[250]\ttraining's rmse: 10848.3\tvalid_1's rmse: 12402.4\n",
      "[260]\ttraining's rmse: 10747.6\tvalid_1's rmse: 12338.1\n",
      "[270]\ttraining's rmse: 10658.3\tvalid_1's rmse: 12297.4\n",
      "[280]\ttraining's rmse: 10537.2\tvalid_1's rmse: 12226.8\n",
      "[290]\ttraining's rmse: 10432.7\tvalid_1's rmse: 12175.5\n",
      "[300]\ttraining's rmse: 10331.4\tvalid_1's rmse: 12137\n",
      "[310]\ttraining's rmse: 10252.3\tvalid_1's rmse: 12111.7\n",
      "[320]\ttraining's rmse: 10170.6\tvalid_1's rmse: 12074.2\n",
      "[330]\ttraining's rmse: 10085.4\tvalid_1's rmse: 12019.3\n",
      "[340]\ttraining's rmse: 10012.7\tvalid_1's rmse: 11995.9\n",
      "[350]\ttraining's rmse: 9945.62\tvalid_1's rmse: 11977.1\n",
      "[360]\ttraining's rmse: 9880.28\tvalid_1's rmse: 11952.1\n",
      "[370]\ttraining's rmse: 9803.12\tvalid_1's rmse: 11903.7\n",
      "[380]\ttraining's rmse: 9740.75\tvalid_1's rmse: 11892.7\n",
      "[390]\ttraining's rmse: 9668.87\tvalid_1's rmse: 11854.8\n",
      "[400]\ttraining's rmse: 9602.54\tvalid_1's rmse: 11825\n",
      "[410]\ttraining's rmse: 9549.77\tvalid_1's rmse: 11810\n",
      "[420]\ttraining's rmse: 9479.68\tvalid_1's rmse: 11779.3\n",
      "[430]\ttraining's rmse: 9417.39\tvalid_1's rmse: 11745.9\n",
      "[440]\ttraining's rmse: 9366.91\tvalid_1's rmse: 11723.8\n",
      "[450]\ttraining's rmse: 9306.2\tvalid_1's rmse: 11690.8\n",
      "[460]\ttraining's rmse: 9258.32\tvalid_1's rmse: 11663.5\n",
      "[470]\ttraining's rmse: 9206.81\tvalid_1's rmse: 11638.1\n",
      "[480]\ttraining's rmse: 9160.06\tvalid_1's rmse: 11623.8\n",
      "[490]\ttraining's rmse: 9098.28\tvalid_1's rmse: 11603.9\n",
      "[500]\ttraining's rmse: 9046.71\tvalid_1's rmse: 11594.3\n",
      "[510]\ttraining's rmse: 9000.81\tvalid_1's rmse: 11583.2\n",
      "[520]\ttraining's rmse: 8952.8\tvalid_1's rmse: 11571.1\n",
      "[530]\ttraining's rmse: 8909.66\tvalid_1's rmse: 11552.5\n",
      "[540]\ttraining's rmse: 8859.71\tvalid_1's rmse: 11530\n",
      "[550]\ttraining's rmse: 8815.64\tvalid_1's rmse: 11517.4\n",
      "[560]\ttraining's rmse: 8771.88\tvalid_1's rmse: 11503.7\n",
      "[570]\ttraining's rmse: 8727.96\tvalid_1's rmse: 11483.8\n",
      "[580]\ttraining's rmse: 8682.34\tvalid_1's rmse: 11478.6\n",
      "[590]\ttraining's rmse: 8638.47\tvalid_1's rmse: 11464.2\n",
      "[600]\ttraining's rmse: 8597.95\tvalid_1's rmse: 11450.1\n",
      "[610]\ttraining's rmse: 8555.74\tvalid_1's rmse: 11453\n",
      "[620]\ttraining's rmse: 8515.5\tvalid_1's rmse: 11434.6\n",
      "[630]\ttraining's rmse: 8474.83\tvalid_1's rmse: 11425.3\n",
      "[640]\ttraining's rmse: 8441.59\tvalid_1's rmse: 11423.9\n",
      "[650]\ttraining's rmse: 8404.41\tvalid_1's rmse: 11417.3\n",
      "[660]\ttraining's rmse: 8364.49\tvalid_1's rmse: 11402\n",
      "[670]\ttraining's rmse: 8328.52\tvalid_1's rmse: 11392\n",
      "[680]\ttraining's rmse: 8299.34\tvalid_1's rmse: 11389.3\n",
      "[690]\ttraining's rmse: 8269.51\tvalid_1's rmse: 11386.3\n",
      "[700]\ttraining's rmse: 8238.89\tvalid_1's rmse: 11380.5\n",
      "[710]\ttraining's rmse: 8201.03\tvalid_1's rmse: 11366.3\n",
      "[720]\ttraining's rmse: 8168.54\tvalid_1's rmse: 11360.5\n",
      "[730]\ttraining's rmse: 8134.49\tvalid_1's rmse: 11361.9\n",
      "[740]\ttraining's rmse: 8106.41\tvalid_1's rmse: 11351.6\n",
      "[750]\ttraining's rmse: 8075.48\tvalid_1's rmse: 11341.7\n",
      "[760]\ttraining's rmse: 8044.81\tvalid_1's rmse: 11326.4\n",
      "[770]\ttraining's rmse: 8017.7\tvalid_1's rmse: 11327.5\n",
      "[780]\ttraining's rmse: 7983.39\tvalid_1's rmse: 11312.4\n",
      "[790]\ttraining's rmse: 7951.01\tvalid_1's rmse: 11306.5\n",
      "[800]\ttraining's rmse: 7928.44\tvalid_1's rmse: 11299.1\n",
      "[810]\ttraining's rmse: 7906.37\tvalid_1's rmse: 11291.5\n",
      "[820]\ttraining's rmse: 7881.43\tvalid_1's rmse: 11285\n",
      "[830]\ttraining's rmse: 7854.71\tvalid_1's rmse: 11276.1\n",
      "[840]\ttraining's rmse: 7826.32\tvalid_1's rmse: 11269.7\n",
      "[850]\ttraining's rmse: 7800.35\tvalid_1's rmse: 11265.1\n",
      "[860]\ttraining's rmse: 7775.85\tvalid_1's rmse: 11260.8\n",
      "[870]\ttraining's rmse: 7752.25\tvalid_1's rmse: 11252.8\n",
      "[880]\ttraining's rmse: 7729.64\tvalid_1's rmse: 11256\n",
      "[890]\ttraining's rmse: 7701.98\tvalid_1's rmse: 11262.4\n",
      "[900]\ttraining's rmse: 7673.63\tvalid_1's rmse: 11259.5\n",
      "[910]\ttraining's rmse: 7649.02\tvalid_1's rmse: 11250\n",
      "[920]\ttraining's rmse: 7629.43\tvalid_1's rmse: 11246.6\n",
      "[930]\ttraining's rmse: 7610.34\tvalid_1's rmse: 11247.9\n",
      "[940]\ttraining's rmse: 7582.78\tvalid_1's rmse: 11246\n",
      "[950]\ttraining's rmse: 7556.48\tvalid_1's rmse: 11242.6\n",
      "[960]\ttraining's rmse: 7531.23\tvalid_1's rmse: 11244.3\n",
      "[970]\ttraining's rmse: 7509.26\tvalid_1's rmse: 11241.7\n",
      "[980]\ttraining's rmse: 7488.46\tvalid_1's rmse: 11242.1\n",
      "[990]\ttraining's rmse: 7465.39\tvalid_1's rmse: 11248.2\n",
      "[1000]\ttraining's rmse: 7445.03\tvalid_1's rmse: 11241\n",
      "[1010]\ttraining's rmse: 7422.81\tvalid_1's rmse: 11235.5\n",
      "[1020]\ttraining's rmse: 7401.51\tvalid_1's rmse: 11231\n",
      "[1030]\ttraining's rmse: 7382.22\tvalid_1's rmse: 11226.8\n",
      "[1040]\ttraining's rmse: 7359\tvalid_1's rmse: 11228.2\n",
      "[1050]\ttraining's rmse: 7340.14\tvalid_1's rmse: 11225.5\n",
      "[1060]\ttraining's rmse: 7323.02\tvalid_1's rmse: 11214.7\n",
      "[1070]\ttraining's rmse: 7304.85\tvalid_1's rmse: 11210.4\n",
      "[1080]\ttraining's rmse: 7285.62\tvalid_1's rmse: 11205.5\n",
      "[1090]\ttraining's rmse: 7263.22\tvalid_1's rmse: 11209.6\n",
      "[1100]\ttraining's rmse: 7243.96\tvalid_1's rmse: 11206.5\n",
      "[1110]\ttraining's rmse: 7228.34\tvalid_1's rmse: 11198.9\n",
      "[1120]\ttraining's rmse: 7210.4\tvalid_1's rmse: 11193.3\n",
      "[1130]\ttraining's rmse: 7192.79\tvalid_1's rmse: 11191.3\n",
      "[1140]\ttraining's rmse: 7172.87\tvalid_1's rmse: 11189\n",
      "[1150]\ttraining's rmse: 7155.47\tvalid_1's rmse: 11186\n",
      "[1160]\ttraining's rmse: 7140.36\tvalid_1's rmse: 11185\n",
      "[1170]\ttraining's rmse: 7124.23\tvalid_1's rmse: 11179.4\n",
      "[1180]\ttraining's rmse: 7106.76\tvalid_1's rmse: 11180.5\n",
      "[1190]\ttraining's rmse: 7089.97\tvalid_1's rmse: 11180.6\n",
      "[1200]\ttraining's rmse: 7073.79\tvalid_1's rmse: 11178.6\n",
      "[1210]\ttraining's rmse: 7057.67\tvalid_1's rmse: 11172\n",
      "[1220]\ttraining's rmse: 7041.96\tvalid_1's rmse: 11175\n",
      "[1230]\ttraining's rmse: 7022.25\tvalid_1's rmse: 11172.7\n",
      "[1240]\ttraining's rmse: 7004.45\tvalid_1's rmse: 11173.6\n",
      "[1250]\ttraining's rmse: 6987.34\tvalid_1's rmse: 11173.8\n",
      "[1260]\ttraining's rmse: 6971.25\tvalid_1's rmse: 11166.7\n",
      "[1270]\ttraining's rmse: 6956.52\tvalid_1's rmse: 11163.2\n",
      "[1280]\ttraining's rmse: 6940.91\tvalid_1's rmse: 11158\n",
      "[1290]\ttraining's rmse: 6922.54\tvalid_1's rmse: 11161.4\n",
      "[1300]\ttraining's rmse: 6908.19\tvalid_1's rmse: 11161.6\n",
      "[1310]\ttraining's rmse: 6890.78\tvalid_1's rmse: 11163.4\n",
      "[1320]\ttraining's rmse: 6876.19\tvalid_1's rmse: 11160.3\n",
      "[1330]\ttraining's rmse: 6861.13\tvalid_1's rmse: 11159.4\n",
      "[1340]\ttraining's rmse: 6845.37\tvalid_1's rmse: 11163.7\n",
      "[1350]\ttraining's rmse: 6828.65\tvalid_1's rmse: 11168.8\n",
      "[1360]\ttraining's rmse: 6814.37\tvalid_1's rmse: 11167.7\n",
      "[1370]\ttraining's rmse: 6801.31\tvalid_1's rmse: 11163.9\n",
      "[1380]\ttraining's rmse: 6788.22\tvalid_1's rmse: 11166.6\n",
      "[1390]\ttraining's rmse: 6773.61\tvalid_1's rmse: 11173.9\n",
      "Early stopping, best iteration is:\n",
      "[1333]\ttraining's rmse: 6856.48\tvalid_1's rmse: 11157.8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1800\n",
      "[LightGBM] [Info] Number of data points in the train set: 55705, number of used features: 20\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 54406.421686\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[10]\ttraining's rmse: 14115.9\tvalid_1's rmse: 14298.1\n",
      "[20]\ttraining's rmse: 9304.67\tvalid_1's rmse: 9653.05\n",
      "[30]\ttraining's rmse: 7387.04\tvalid_1's rmse: 7822.87\n",
      "[40]\ttraining's rmse: 6391.44\tvalid_1's rmse: 6846.11\n",
      "[50]\ttraining's rmse: 5834.65\tvalid_1's rmse: 6312.25\n",
      "[60]\ttraining's rmse: 5423.39\tvalid_1's rmse: 5901.55\n",
      "[70]\ttraining's rmse: 5122.97\tvalid_1's rmse: 5618.33\n",
      "[80]\ttraining's rmse: 4893.39\tvalid_1's rmse: 5388.07\n",
      "[90]\ttraining's rmse: 4717.41\tvalid_1's rmse: 5208.41\n",
      "[100]\ttraining's rmse: 4584.33\tvalid_1's rmse: 5075.17\n",
      "[110]\ttraining's rmse: 4449.78\tvalid_1's rmse: 4942.22\n",
      "[120]\ttraining's rmse: 4349.48\tvalid_1's rmse: 4849.23\n",
      "[130]\ttraining's rmse: 4263.59\tvalid_1's rmse: 4770.09\n",
      "[140]\ttraining's rmse: 4186.61\tvalid_1's rmse: 4691.95\n",
      "[150]\ttraining's rmse: 4099.26\tvalid_1's rmse: 4612.82\n",
      "[160]\ttraining's rmse: 4027.35\tvalid_1's rmse: 4550.25\n",
      "[170]\ttraining's rmse: 3969.19\tvalid_1's rmse: 4496.51\n",
      "[180]\ttraining's rmse: 3912.81\tvalid_1's rmse: 4453.34\n",
      "[190]\ttraining's rmse: 3855.57\tvalid_1's rmse: 4400.13\n",
      "[200]\ttraining's rmse: 3794.99\tvalid_1's rmse: 4342.21\n",
      "[210]\ttraining's rmse: 3754.7\tvalid_1's rmse: 4306.82\n",
      "[220]\ttraining's rmse: 3707.49\tvalid_1's rmse: 4262.44\n",
      "[230]\ttraining's rmse: 3667.18\tvalid_1's rmse: 4236.76\n",
      "[240]\ttraining's rmse: 3634.72\tvalid_1's rmse: 4209.8\n",
      "[250]\ttraining's rmse: 3598.97\tvalid_1's rmse: 4178.1\n",
      "[260]\ttraining's rmse: 3562.02\tvalid_1's rmse: 4149.13\n",
      "[270]\ttraining's rmse: 3529.42\tvalid_1's rmse: 4128.37\n",
      "[280]\ttraining's rmse: 3499.24\tvalid_1's rmse: 4105.48\n",
      "[290]\ttraining's rmse: 3467.67\tvalid_1's rmse: 4080.81\n",
      "[300]\ttraining's rmse: 3438.56\tvalid_1's rmse: 4055.07\n",
      "[310]\ttraining's rmse: 3411.92\tvalid_1's rmse: 4035.94\n",
      "[320]\ttraining's rmse: 3384.05\tvalid_1's rmse: 4015.5\n",
      "[330]\ttraining's rmse: 3356.26\tvalid_1's rmse: 3994.69\n",
      "[340]\ttraining's rmse: 3332.7\tvalid_1's rmse: 3972.8\n",
      "[350]\ttraining's rmse: 3309.44\tvalid_1's rmse: 3956.69\n",
      "[360]\ttraining's rmse: 3288.56\tvalid_1's rmse: 3944.29\n",
      "[370]\ttraining's rmse: 3267.24\tvalid_1's rmse: 3929.11\n",
      "[380]\ttraining's rmse: 3248.35\tvalid_1's rmse: 3914.46\n",
      "[390]\ttraining's rmse: 3228.26\tvalid_1's rmse: 3903.79\n",
      "[400]\ttraining's rmse: 3206.28\tvalid_1's rmse: 3894.88\n",
      "[410]\ttraining's rmse: 3188.28\tvalid_1's rmse: 3885.07\n",
      "[420]\ttraining's rmse: 3168.39\tvalid_1's rmse: 3875.01\n",
      "[430]\ttraining's rmse: 3151\tvalid_1's rmse: 3859.89\n",
      "[440]\ttraining's rmse: 3131.6\tvalid_1's rmse: 3847.86\n",
      "[450]\ttraining's rmse: 3117.46\tvalid_1's rmse: 3839.28\n",
      "[460]\ttraining's rmse: 3101.97\tvalid_1's rmse: 3828.33\n",
      "[470]\ttraining's rmse: 3088.42\tvalid_1's rmse: 3823.55\n",
      "[480]\ttraining's rmse: 3072.41\tvalid_1's rmse: 3811.79\n",
      "[490]\ttraining's rmse: 3056.39\tvalid_1's rmse: 3804.71\n",
      "[500]\ttraining's rmse: 3042.46\tvalid_1's rmse: 3797.18\n",
      "[510]\ttraining's rmse: 3027.67\tvalid_1's rmse: 3794.19\n",
      "[520]\ttraining's rmse: 3014.36\tvalid_1's rmse: 3789.83\n",
      "[530]\ttraining's rmse: 3001.41\tvalid_1's rmse: 3783.21\n",
      "[540]\ttraining's rmse: 2987.78\tvalid_1's rmse: 3774.4\n",
      "[550]\ttraining's rmse: 2973.85\tvalid_1's rmse: 3765.91\n",
      "[560]\ttraining's rmse: 2962.32\tvalid_1's rmse: 3760.12\n",
      "[570]\ttraining's rmse: 2950.15\tvalid_1's rmse: 3755.66\n",
      "[580]\ttraining's rmse: 2936.86\tvalid_1's rmse: 3752.1\n",
      "[590]\ttraining's rmse: 2925.3\tvalid_1's rmse: 3746.92\n",
      "[600]\ttraining's rmse: 2914.4\tvalid_1's rmse: 3741.19\n",
      "[610]\ttraining's rmse: 2900.57\tvalid_1's rmse: 3735.27\n",
      "[620]\ttraining's rmse: 2889.21\tvalid_1's rmse: 3727.6\n",
      "[630]\ttraining's rmse: 2877.3\tvalid_1's rmse: 3721.52\n",
      "[640]\ttraining's rmse: 2865.53\tvalid_1's rmse: 3715.58\n",
      "[650]\ttraining's rmse: 2856.59\tvalid_1's rmse: 3712\n",
      "[660]\ttraining's rmse: 2847.05\tvalid_1's rmse: 3708.27\n",
      "[670]\ttraining's rmse: 2835.58\tvalid_1's rmse: 3702.71\n",
      "[680]\ttraining's rmse: 2825.97\tvalid_1's rmse: 3699.33\n",
      "[690]\ttraining's rmse: 2817.22\tvalid_1's rmse: 3694.03\n",
      "[700]\ttraining's rmse: 2807.03\tvalid_1's rmse: 3689.46\n",
      "[710]\ttraining's rmse: 2797.71\tvalid_1's rmse: 3685.52\n",
      "[720]\ttraining's rmse: 2788\tvalid_1's rmse: 3682.12\n",
      "[730]\ttraining's rmse: 2779.78\tvalid_1's rmse: 3680.84\n",
      "[740]\ttraining's rmse: 2770.69\tvalid_1's rmse: 3680.6\n",
      "[750]\ttraining's rmse: 2761.33\tvalid_1's rmse: 3677.86\n",
      "[760]\ttraining's rmse: 2751.95\tvalid_1's rmse: 3675.57\n",
      "[770]\ttraining's rmse: 2741.76\tvalid_1's rmse: 3673.1\n",
      "[780]\ttraining's rmse: 2733.83\tvalid_1's rmse: 3669.26\n",
      "[790]\ttraining's rmse: 2725.65\tvalid_1's rmse: 3664.29\n",
      "[800]\ttraining's rmse: 2717.43\tvalid_1's rmse: 3663.51\n",
      "[810]\ttraining's rmse: 2708.51\tvalid_1's rmse: 3658.98\n",
      "[820]\ttraining's rmse: 2700.97\tvalid_1's rmse: 3657.12\n",
      "[830]\ttraining's rmse: 2692.35\tvalid_1's rmse: 3653.62\n",
      "[840]\ttraining's rmse: 2684.64\tvalid_1's rmse: 3652.78\n",
      "[850]\ttraining's rmse: 2677.25\tvalid_1's rmse: 3651.71\n",
      "[860]\ttraining's rmse: 2668.36\tvalid_1's rmse: 3649.86\n",
      "[870]\ttraining's rmse: 2661.21\tvalid_1's rmse: 3647.16\n",
      "[880]\ttraining's rmse: 2654.03\tvalid_1's rmse: 3643.22\n",
      "[890]\ttraining's rmse: 2645.89\tvalid_1's rmse: 3642.1\n",
      "[900]\ttraining's rmse: 2638.86\tvalid_1's rmse: 3639.62\n",
      "[910]\ttraining's rmse: 2632.01\tvalid_1's rmse: 3638.17\n",
      "[920]\ttraining's rmse: 2625.35\tvalid_1's rmse: 3636.68\n",
      "[930]\ttraining's rmse: 2618.66\tvalid_1's rmse: 3633.56\n",
      "[940]\ttraining's rmse: 2610.68\tvalid_1's rmse: 3632.9\n",
      "[950]\ttraining's rmse: 2604.52\tvalid_1's rmse: 3630.12\n",
      "[960]\ttraining's rmse: 2597.59\tvalid_1's rmse: 3628.98\n",
      "[970]\ttraining's rmse: 2591.27\tvalid_1's rmse: 3625.72\n",
      "[980]\ttraining's rmse: 2585.43\tvalid_1's rmse: 3624.72\n",
      "[990]\ttraining's rmse: 2579.29\tvalid_1's rmse: 3623.66\n",
      "[1000]\ttraining's rmse: 2571.56\tvalid_1's rmse: 3622.17\n",
      "[1010]\ttraining's rmse: 2563.65\tvalid_1's rmse: 3620.3\n",
      "[1020]\ttraining's rmse: 2556.78\tvalid_1's rmse: 3616.28\n",
      "[1030]\ttraining's rmse: 2551.8\tvalid_1's rmse: 3614.9\n",
      "[1040]\ttraining's rmse: 2544.85\tvalid_1's rmse: 3612.53\n",
      "[1050]\ttraining's rmse: 2539.38\tvalid_1's rmse: 3610.8\n",
      "[1060]\ttraining's rmse: 2533.34\tvalid_1's rmse: 3609.19\n",
      "[1070]\ttraining's rmse: 2527.42\tvalid_1's rmse: 3605.63\n",
      "[1080]\ttraining's rmse: 2521.95\tvalid_1's rmse: 3604.2\n",
      "[1090]\ttraining's rmse: 2517.32\tvalid_1's rmse: 3603.08\n",
      "[1100]\ttraining's rmse: 2512.07\tvalid_1's rmse: 3604.57\n",
      "[1110]\ttraining's rmse: 2505.11\tvalid_1's rmse: 3605.76\n",
      "[1120]\ttraining's rmse: 2499.99\tvalid_1's rmse: 3603.76\n",
      "[1130]\ttraining's rmse: 2494.22\tvalid_1's rmse: 3601.98\n",
      "[1140]\ttraining's rmse: 2489.06\tvalid_1's rmse: 3600.87\n",
      "[1150]\ttraining's rmse: 2484.24\tvalid_1's rmse: 3599.81\n",
      "[1160]\ttraining's rmse: 2479.84\tvalid_1's rmse: 3600.55\n",
      "[1170]\ttraining's rmse: 2474.61\tvalid_1's rmse: 3598.01\n",
      "[1180]\ttraining's rmse: 2469.54\tvalid_1's rmse: 3596.84\n",
      "[1190]\ttraining's rmse: 2464.12\tvalid_1's rmse: 3593.41\n",
      "[1200]\ttraining's rmse: 2458.96\tvalid_1's rmse: 3592.02\n",
      "[1210]\ttraining's rmse: 2455.05\tvalid_1's rmse: 3591.11\n",
      "[1220]\ttraining's rmse: 2450.42\tvalid_1's rmse: 3589.68\n",
      "[1230]\ttraining's rmse: 2444.64\tvalid_1's rmse: 3588.16\n",
      "[1240]\ttraining's rmse: 2439.83\tvalid_1's rmse: 3590.19\n",
      "[1250]\ttraining's rmse: 2434.96\tvalid_1's rmse: 3590.46\n",
      "[1260]\ttraining's rmse: 2430.53\tvalid_1's rmse: 3590.74\n",
      "[1270]\ttraining's rmse: 2425.92\tvalid_1's rmse: 3591.43\n",
      "[1280]\ttraining's rmse: 2421.24\tvalid_1's rmse: 3589.98\n",
      "[1290]\ttraining's rmse: 2417.22\tvalid_1's rmse: 3586.63\n",
      "[1300]\ttraining's rmse: 2412.9\tvalid_1's rmse: 3587.65\n",
      "[1310]\ttraining's rmse: 2408.78\tvalid_1's rmse: 3587.38\n",
      "[1320]\ttraining's rmse: 2404.05\tvalid_1's rmse: 3586.48\n",
      "[1330]\ttraining's rmse: 2399.71\tvalid_1's rmse: 3586.38\n",
      "[1340]\ttraining's rmse: 2395.7\tvalid_1's rmse: 3585.46\n",
      "[1350]\ttraining's rmse: 2391.67\tvalid_1's rmse: 3585.58\n",
      "[1360]\ttraining's rmse: 2387.5\tvalid_1's rmse: 3585.97\n",
      "[1370]\ttraining's rmse: 2384.19\tvalid_1's rmse: 3585.71\n",
      "[1380]\ttraining's rmse: 2379.33\tvalid_1's rmse: 3583.84\n",
      "[1390]\ttraining's rmse: 2374.96\tvalid_1's rmse: 3582.07\n",
      "[1400]\ttraining's rmse: 2370.76\tvalid_1's rmse: 3580.85\n",
      "[1410]\ttraining's rmse: 2367.03\tvalid_1's rmse: 3580.32\n",
      "[1420]\ttraining's rmse: 2362.45\tvalid_1's rmse: 3576.9\n",
      "[1430]\ttraining's rmse: 2358.78\tvalid_1's rmse: 3575.28\n",
      "[1440]\ttraining's rmse: 2354.87\tvalid_1's rmse: 3573.64\n",
      "[1450]\ttraining's rmse: 2350.42\tvalid_1's rmse: 3573.63\n",
      "[1460]\ttraining's rmse: 2346.44\tvalid_1's rmse: 3572.97\n",
      "[1470]\ttraining's rmse: 2342.67\tvalid_1's rmse: 3572.96\n",
      "[1480]\ttraining's rmse: 2338.81\tvalid_1's rmse: 3574.5\n",
      "[1490]\ttraining's rmse: 2334.88\tvalid_1's rmse: 3574.25\n",
      "[1500]\ttraining's rmse: 2331.13\tvalid_1's rmse: 3575.56\n",
      "[1510]\ttraining's rmse: 2326.44\tvalid_1's rmse: 3577.11\n",
      "[1520]\ttraining's rmse: 2322\tvalid_1's rmse: 3576.95\n",
      "Early stopping, best iteration is:\n",
      "[1468]\ttraining's rmse: 2343.42\tvalid_1's rmse: 3572.47\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000536 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1346\n",
      "[LightGBM] [Info] Number of data points in the train set: 19706, number of used features: 20\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 38320.271085\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[10]\ttraining's rmse: 7470.95\tvalid_1's rmse: 7495.99\n",
      "[20]\ttraining's rmse: 4588.53\tvalid_1's rmse: 4676.3\n",
      "[30]\ttraining's rmse: 3552.02\tvalid_1's rmse: 3686.78\n",
      "[40]\ttraining's rmse: 3040.39\tvalid_1's rmse: 3221.33\n",
      "[50]\ttraining's rmse: 2763.78\tvalid_1's rmse: 2965.63\n",
      "[60]\ttraining's rmse: 2589.11\tvalid_1's rmse: 2788.72\n",
      "[70]\ttraining's rmse: 2481.7\tvalid_1's rmse: 2689.75\n",
      "[80]\ttraining's rmse: 2392.6\tvalid_1's rmse: 2606.81\n",
      "[90]\ttraining's rmse: 2322.3\tvalid_1's rmse: 2546.27\n",
      "[100]\ttraining's rmse: 2272.49\tvalid_1's rmse: 2500.74\n",
      "[110]\ttraining's rmse: 2227.92\tvalid_1's rmse: 2472.43\n",
      "[120]\ttraining's rmse: 2186.47\tvalid_1's rmse: 2444.08\n",
      "[130]\ttraining's rmse: 2148.27\tvalid_1's rmse: 2414.72\n",
      "[140]\ttraining's rmse: 2116.97\tvalid_1's rmse: 2397.16\n",
      "[150]\ttraining's rmse: 2088.77\tvalid_1's rmse: 2384.51\n",
      "[160]\ttraining's rmse: 2063.77\tvalid_1's rmse: 2366.86\n",
      "[170]\ttraining's rmse: 2037.3\tvalid_1's rmse: 2348.65\n",
      "[180]\ttraining's rmse: 2011.75\tvalid_1's rmse: 2336.28\n",
      "[190]\ttraining's rmse: 1990.17\tvalid_1's rmse: 2323.56\n",
      "[200]\ttraining's rmse: 1971.5\tvalid_1's rmse: 2308.72\n",
      "[210]\ttraining's rmse: 1951.08\tvalid_1's rmse: 2304.05\n",
      "[220]\ttraining's rmse: 1932.6\tvalid_1's rmse: 2294.77\n",
      "[230]\ttraining's rmse: 1915.39\tvalid_1's rmse: 2284.68\n",
      "[240]\ttraining's rmse: 1899.36\tvalid_1's rmse: 2270.74\n",
      "[250]\ttraining's rmse: 1882.56\tvalid_1's rmse: 2260.69\n",
      "[260]\ttraining's rmse: 1868.42\tvalid_1's rmse: 2246.31\n",
      "[270]\ttraining's rmse: 1855.75\tvalid_1's rmse: 2243.87\n",
      "[280]\ttraining's rmse: 1841.92\tvalid_1's rmse: 2240.18\n",
      "[290]\ttraining's rmse: 1830.74\tvalid_1's rmse: 2238.22\n",
      "[300]\ttraining's rmse: 1818.02\tvalid_1's rmse: 2232.48\n",
      "[310]\ttraining's rmse: 1807.28\tvalid_1's rmse: 2227.54\n",
      "[320]\ttraining's rmse: 1797.78\tvalid_1's rmse: 2223.02\n",
      "[330]\ttraining's rmse: 1785.18\tvalid_1's rmse: 2214.85\n",
      "[340]\ttraining's rmse: 1775.07\tvalid_1's rmse: 2213.38\n",
      "[350]\ttraining's rmse: 1764.04\tvalid_1's rmse: 2211.58\n",
      "[360]\ttraining's rmse: 1754.02\tvalid_1's rmse: 2209.26\n",
      "[370]\ttraining's rmse: 1744.82\tvalid_1's rmse: 2206.65\n",
      "[380]\ttraining's rmse: 1734.56\tvalid_1's rmse: 2204.95\n",
      "[390]\ttraining's rmse: 1724.53\tvalid_1's rmse: 2201.68\n",
      "[400]\ttraining's rmse: 1715.36\tvalid_1's rmse: 2201.75\n",
      "[410]\ttraining's rmse: 1707.61\tvalid_1's rmse: 2198.38\n",
      "[420]\ttraining's rmse: 1699.27\tvalid_1's rmse: 2194.82\n",
      "[430]\ttraining's rmse: 1691.38\tvalid_1's rmse: 2195.13\n",
      "[440]\ttraining's rmse: 1682.15\tvalid_1's rmse: 2193.45\n",
      "[450]\ttraining's rmse: 1674.44\tvalid_1's rmse: 2192.27\n",
      "[460]\ttraining's rmse: 1666.38\tvalid_1's rmse: 2187.97\n",
      "[470]\ttraining's rmse: 1659.05\tvalid_1's rmse: 2188.46\n",
      "[480]\ttraining's rmse: 1652.89\tvalid_1's rmse: 2187.91\n",
      "[490]\ttraining's rmse: 1645.74\tvalid_1's rmse: 2186.92\n",
      "[500]\ttraining's rmse: 1637.98\tvalid_1's rmse: 2185.48\n",
      "[510]\ttraining's rmse: 1630.66\tvalid_1's rmse: 2185.9\n",
      "[520]\ttraining's rmse: 1624.03\tvalid_1's rmse: 2184.66\n",
      "[530]\ttraining's rmse: 1617.28\tvalid_1's rmse: 2183.59\n",
      "[540]\ttraining's rmse: 1611.91\tvalid_1's rmse: 2181.31\n",
      "[550]\ttraining's rmse: 1605.54\tvalid_1's rmse: 2181.92\n",
      "[560]\ttraining's rmse: 1599.31\tvalid_1's rmse: 2179.97\n",
      "[570]\ttraining's rmse: 1592.97\tvalid_1's rmse: 2178.96\n",
      "[580]\ttraining's rmse: 1586.38\tvalid_1's rmse: 2177.64\n",
      "[590]\ttraining's rmse: 1580.34\tvalid_1's rmse: 2174.95\n",
      "[600]\ttraining's rmse: 1575.3\tvalid_1's rmse: 2175.5\n",
      "[610]\ttraining's rmse: 1570.26\tvalid_1's rmse: 2176.82\n",
      "[620]\ttraining's rmse: 1564.03\tvalid_1's rmse: 2172.72\n",
      "[630]\ttraining's rmse: 1559.5\tvalid_1's rmse: 2170.81\n",
      "[640]\ttraining's rmse: 1553.87\tvalid_1's rmse: 2167.37\n",
      "[650]\ttraining's rmse: 1548\tvalid_1's rmse: 2167.03\n",
      "[660]\ttraining's rmse: 1542.07\tvalid_1's rmse: 2167.42\n",
      "[670]\ttraining's rmse: 1537.1\tvalid_1's rmse: 2166.03\n",
      "[680]\ttraining's rmse: 1531.74\tvalid_1's rmse: 2164.92\n",
      "[690]\ttraining's rmse: 1526.59\tvalid_1's rmse: 2163.99\n",
      "[700]\ttraining's rmse: 1521.93\tvalid_1's rmse: 2164.04\n",
      "[710]\ttraining's rmse: 1517.75\tvalid_1's rmse: 2166.29\n",
      "[720]\ttraining's rmse: 1512.91\tvalid_1's rmse: 2166.04\n",
      "[730]\ttraining's rmse: 1508.02\tvalid_1's rmse: 2165.28\n",
      "[740]\ttraining's rmse: 1503.58\tvalid_1's rmse: 2166.25\n",
      "[750]\ttraining's rmse: 1499.55\tvalid_1's rmse: 2166.52\n",
      "Early stopping, best iteration is:\n",
      "[693]\ttraining's rmse: 1525.34\tvalid_1's rmse: 2161.87\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1829\n",
      "[LightGBM] [Info] Number of data points in the train set: 59949, number of used features: 20\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 44219.244474\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[10]\ttraining's rmse: 11744.9\tvalid_1's rmse: 11694.8\n",
      "[20]\ttraining's rmse: 7838.42\tvalid_1's rmse: 7869.33\n",
      "[30]\ttraining's rmse: 6297.91\tvalid_1's rmse: 6377.05\n",
      "[40]\ttraining's rmse: 5491.99\tvalid_1's rmse: 5576.99\n",
      "[50]\ttraining's rmse: 4994.95\tvalid_1's rmse: 5121.5\n",
      "[60]\ttraining's rmse: 4641.52\tvalid_1's rmse: 4782.98\n",
      "[70]\ttraining's rmse: 4377.04\tvalid_1's rmse: 4542.59\n",
      "[80]\ttraining's rmse: 4177.27\tvalid_1's rmse: 4364.08\n",
      "[90]\ttraining's rmse: 4020.28\tvalid_1's rmse: 4231.16\n",
      "[100]\ttraining's rmse: 3881.35\tvalid_1's rmse: 4110.83\n",
      "[110]\ttraining's rmse: 3751.85\tvalid_1's rmse: 3993.5\n",
      "[120]\ttraining's rmse: 3651.06\tvalid_1's rmse: 3902.06\n",
      "[130]\ttraining's rmse: 3573.15\tvalid_1's rmse: 3835.77\n",
      "[140]\ttraining's rmse: 3497.75\tvalid_1's rmse: 3771.01\n",
      "[150]\ttraining's rmse: 3421.75\tvalid_1's rmse: 3701.68\n",
      "[160]\ttraining's rmse: 3358.37\tvalid_1's rmse: 3651.71\n",
      "[170]\ttraining's rmse: 3311.05\tvalid_1's rmse: 3614.93\n",
      "[180]\ttraining's rmse: 3262.32\tvalid_1's rmse: 3578.49\n",
      "[190]\ttraining's rmse: 3218.9\tvalid_1's rmse: 3544.68\n",
      "[200]\ttraining's rmse: 3171.28\tvalid_1's rmse: 3508.5\n",
      "[210]\ttraining's rmse: 3133.42\tvalid_1's rmse: 3475.08\n",
      "[220]\ttraining's rmse: 3097.93\tvalid_1's rmse: 3449.95\n",
      "[230]\ttraining's rmse: 3068.13\tvalid_1's rmse: 3425.1\n",
      "[240]\ttraining's rmse: 3034.9\tvalid_1's rmse: 3404.65\n",
      "[250]\ttraining's rmse: 3006.72\tvalid_1's rmse: 3387.66\n",
      "[260]\ttraining's rmse: 2971.6\tvalid_1's rmse: 3356.49\n",
      "[270]\ttraining's rmse: 2940.63\tvalid_1's rmse: 3335.67\n",
      "[280]\ttraining's rmse: 2915.12\tvalid_1's rmse: 3319.45\n",
      "[290]\ttraining's rmse: 2888.54\tvalid_1's rmse: 3303.58\n",
      "[300]\ttraining's rmse: 2866.05\tvalid_1's rmse: 3286.82\n",
      "[310]\ttraining's rmse: 2844.24\tvalid_1's rmse: 3276.71\n",
      "[320]\ttraining's rmse: 2822.25\tvalid_1's rmse: 3266.56\n",
      "[330]\ttraining's rmse: 2803.66\tvalid_1's rmse: 3253.56\n",
      "[340]\ttraining's rmse: 2782.56\tvalid_1's rmse: 3243.37\n",
      "[350]\ttraining's rmse: 2761.67\tvalid_1's rmse: 3230.67\n",
      "[360]\ttraining's rmse: 2744.31\tvalid_1's rmse: 3216.83\n",
      "[370]\ttraining's rmse: 2726.53\tvalid_1's rmse: 3205.22\n",
      "[380]\ttraining's rmse: 2709.08\tvalid_1's rmse: 3191.22\n",
      "[390]\ttraining's rmse: 2691.98\tvalid_1's rmse: 3181.04\n",
      "[400]\ttraining's rmse: 2676.42\tvalid_1's rmse: 3168.9\n",
      "[410]\ttraining's rmse: 2659.93\tvalid_1's rmse: 3159.05\n",
      "[420]\ttraining's rmse: 2647.8\tvalid_1's rmse: 3151.04\n",
      "[430]\ttraining's rmse: 2632.73\tvalid_1's rmse: 3145\n",
      "[440]\ttraining's rmse: 2618.43\tvalid_1's rmse: 3136.89\n",
      "[450]\ttraining's rmse: 2606.04\tvalid_1's rmse: 3130.16\n",
      "[460]\ttraining's rmse: 2594.88\tvalid_1's rmse: 3125.15\n",
      "[470]\ttraining's rmse: 2581.4\tvalid_1's rmse: 3117.97\n",
      "[480]\ttraining's rmse: 2568.74\tvalid_1's rmse: 3109.3\n",
      "[490]\ttraining's rmse: 2555.54\tvalid_1's rmse: 3101.55\n",
      "[500]\ttraining's rmse: 2544.83\tvalid_1's rmse: 3096.33\n",
      "[510]\ttraining's rmse: 2533.16\tvalid_1's rmse: 3092.49\n",
      "[520]\ttraining's rmse: 2522.63\tvalid_1's rmse: 3086.42\n",
      "[530]\ttraining's rmse: 2513.17\tvalid_1's rmse: 3082.8\n",
      "[540]\ttraining's rmse: 2502.51\tvalid_1's rmse: 3078.09\n",
      "[550]\ttraining's rmse: 2493.03\tvalid_1's rmse: 3072.09\n",
      "[560]\ttraining's rmse: 2482.73\tvalid_1's rmse: 3067.55\n",
      "[570]\ttraining's rmse: 2471.41\tvalid_1's rmse: 3062.91\n",
      "[580]\ttraining's rmse: 2461.17\tvalid_1's rmse: 3059.94\n",
      "[590]\ttraining's rmse: 2450.54\tvalid_1's rmse: 3054.82\n",
      "[600]\ttraining's rmse: 2442.39\tvalid_1's rmse: 3053.5\n",
      "[610]\ttraining's rmse: 2433.2\tvalid_1's rmse: 3049.76\n",
      "[620]\ttraining's rmse: 2423.46\tvalid_1's rmse: 3042.55\n",
      "[630]\ttraining's rmse: 2415.54\tvalid_1's rmse: 3039.16\n",
      "[640]\ttraining's rmse: 2407.04\tvalid_1's rmse: 3038.24\n",
      "[650]\ttraining's rmse: 2400.17\tvalid_1's rmse: 3034.89\n",
      "[660]\ttraining's rmse: 2392.01\tvalid_1's rmse: 3034.01\n",
      "[670]\ttraining's rmse: 2383.8\tvalid_1's rmse: 3030.22\n",
      "[680]\ttraining's rmse: 2376.31\tvalid_1's rmse: 3028.27\n",
      "[690]\ttraining's rmse: 2368.18\tvalid_1's rmse: 3028.08\n",
      "[700]\ttraining's rmse: 2359.63\tvalid_1's rmse: 3025.82\n",
      "[710]\ttraining's rmse: 2352.53\tvalid_1's rmse: 3023.56\n",
      "[720]\ttraining's rmse: 2345.71\tvalid_1's rmse: 3019.7\n",
      "[730]\ttraining's rmse: 2339.37\tvalid_1's rmse: 3021.3\n",
      "[740]\ttraining's rmse: 2332.08\tvalid_1's rmse: 3017.91\n",
      "[750]\ttraining's rmse: 2324.99\tvalid_1's rmse: 3013\n",
      "[760]\ttraining's rmse: 2318.6\tvalid_1's rmse: 3012.09\n",
      "[770]\ttraining's rmse: 2312.38\tvalid_1's rmse: 3010.69\n",
      "[780]\ttraining's rmse: 2305.43\tvalid_1's rmse: 3009.17\n",
      "[790]\ttraining's rmse: 2298.69\tvalid_1's rmse: 3004.42\n",
      "[800]\ttraining's rmse: 2292.9\tvalid_1's rmse: 3000.78\n",
      "[810]\ttraining's rmse: 2286.92\tvalid_1's rmse: 2998.26\n",
      "[820]\ttraining's rmse: 2280.28\tvalid_1's rmse: 2996.62\n",
      "[830]\ttraining's rmse: 2274.69\tvalid_1's rmse: 2995.54\n",
      "[840]\ttraining's rmse: 2268.34\tvalid_1's rmse: 2994.49\n",
      "[850]\ttraining's rmse: 2261.87\tvalid_1's rmse: 2993.1\n",
      "[860]\ttraining's rmse: 2256.39\tvalid_1's rmse: 2990.35\n",
      "[870]\ttraining's rmse: 2251.83\tvalid_1's rmse: 2989.44\n",
      "[880]\ttraining's rmse: 2246.5\tvalid_1's rmse: 2987.06\n",
      "[890]\ttraining's rmse: 2240.7\tvalid_1's rmse: 2984.99\n",
      "[900]\ttraining's rmse: 2235.31\tvalid_1's rmse: 2982.16\n",
      "[910]\ttraining's rmse: 2230.43\tvalid_1's rmse: 2979.55\n",
      "[920]\ttraining's rmse: 2224.41\tvalid_1's rmse: 2978.6\n",
      "[930]\ttraining's rmse: 2219.26\tvalid_1's rmse: 2977.11\n",
      "[940]\ttraining's rmse: 2213.49\tvalid_1's rmse: 2975.69\n",
      "[950]\ttraining's rmse: 2208.56\tvalid_1's rmse: 2974.5\n",
      "[960]\ttraining's rmse: 2202.98\tvalid_1's rmse: 2975.56\n",
      "[970]\ttraining's rmse: 2198.35\tvalid_1's rmse: 2974.3\n",
      "[980]\ttraining's rmse: 2193.82\tvalid_1's rmse: 2973.25\n",
      "[990]\ttraining's rmse: 2189.43\tvalid_1's rmse: 2972.88\n",
      "[1000]\ttraining's rmse: 2184.64\tvalid_1's rmse: 2971.07\n",
      "[1010]\ttraining's rmse: 2180.55\tvalid_1's rmse: 2972.31\n",
      "[1020]\ttraining's rmse: 2175.25\tvalid_1's rmse: 2969.98\n",
      "[1030]\ttraining's rmse: 2170.04\tvalid_1's rmse: 2964.73\n",
      "[1040]\ttraining's rmse: 2165.76\tvalid_1's rmse: 2964.4\n",
      "[1050]\ttraining's rmse: 2161.73\tvalid_1's rmse: 2964.3\n",
      "[1060]\ttraining's rmse: 2157.12\tvalid_1's rmse: 2963.51\n",
      "[1070]\ttraining's rmse: 2152.72\tvalid_1's rmse: 2962.85\n",
      "[1080]\ttraining's rmse: 2147.39\tvalid_1's rmse: 2962.35\n",
      "[1090]\ttraining's rmse: 2143.52\tvalid_1's rmse: 2961.96\n",
      "[1100]\ttraining's rmse: 2139.17\tvalid_1's rmse: 2961.71\n",
      "[1110]\ttraining's rmse: 2134.78\tvalid_1's rmse: 2959.61\n",
      "[1120]\ttraining's rmse: 2130.63\tvalid_1's rmse: 2957.76\n",
      "[1130]\ttraining's rmse: 2126.28\tvalid_1's rmse: 2956.85\n",
      "[1140]\ttraining's rmse: 2122.42\tvalid_1's rmse: 2956.96\n",
      "[1150]\ttraining's rmse: 2118.58\tvalid_1's rmse: 2956.84\n",
      "[1160]\ttraining's rmse: 2114.85\tvalid_1's rmse: 2957.59\n",
      "[1170]\ttraining's rmse: 2110.16\tvalid_1's rmse: 2957.14\n",
      "[1180]\ttraining's rmse: 2106.47\tvalid_1's rmse: 2956.17\n",
      "[1190]\ttraining's rmse: 2102.04\tvalid_1's rmse: 2955.05\n",
      "[1200]\ttraining's rmse: 2098.14\tvalid_1's rmse: 2954.04\n",
      "[1210]\ttraining's rmse: 2094.25\tvalid_1's rmse: 2952.52\n",
      "[1220]\ttraining's rmse: 2090.63\tvalid_1's rmse: 2952.03\n",
      "[1230]\ttraining's rmse: 2086.84\tvalid_1's rmse: 2951.42\n",
      "[1240]\ttraining's rmse: 2083.54\tvalid_1's rmse: 2951.2\n",
      "[1250]\ttraining's rmse: 2079.98\tvalid_1's rmse: 2949.01\n",
      "[1260]\ttraining's rmse: 2076.6\tvalid_1's rmse: 2950.32\n",
      "[1270]\ttraining's rmse: 2072.85\tvalid_1's rmse: 2950.43\n",
      "[1280]\ttraining's rmse: 2068.4\tvalid_1's rmse: 2951.22\n",
      "[1290]\ttraining's rmse: 2065.35\tvalid_1's rmse: 2949.94\n",
      "[1300]\ttraining's rmse: 2061.12\tvalid_1's rmse: 2949.11\n",
      "[1310]\ttraining's rmse: 2057.27\tvalid_1's rmse: 2946.93\n",
      "[1320]\ttraining's rmse: 2053.75\tvalid_1's rmse: 2947.53\n",
      "[1330]\ttraining's rmse: 2050.1\tvalid_1's rmse: 2945.58\n",
      "[1340]\ttraining's rmse: 2046.48\tvalid_1's rmse: 2944.95\n",
      "[1350]\ttraining's rmse: 2043.27\tvalid_1's rmse: 2944.84\n",
      "[1360]\ttraining's rmse: 2040.37\tvalid_1's rmse: 2944.55\n",
      "[1370]\ttraining's rmse: 2036.9\tvalid_1's rmse: 2944.55\n",
      "[1380]\ttraining's rmse: 2033.54\tvalid_1's rmse: 2944.86\n",
      "[1390]\ttraining's rmse: 2029.55\tvalid_1's rmse: 2944.05\n",
      "[1400]\ttraining's rmse: 2025.87\tvalid_1's rmse: 2944.33\n",
      "[1410]\ttraining's rmse: 2022.64\tvalid_1's rmse: 2943.72\n",
      "[1420]\ttraining's rmse: 2018.86\tvalid_1's rmse: 2942.57\n",
      "[1430]\ttraining's rmse: 2015.67\tvalid_1's rmse: 2942.61\n",
      "[1440]\ttraining's rmse: 2012.31\tvalid_1's rmse: 2942.05\n",
      "[1450]\ttraining's rmse: 2008.55\tvalid_1's rmse: 2939.75\n",
      "[1460]\ttraining's rmse: 2005.35\tvalid_1's rmse: 2940.77\n",
      "[1470]\ttraining's rmse: 2002.13\tvalid_1's rmse: 2941.39\n",
      "[1480]\ttraining's rmse: 1999.36\tvalid_1's rmse: 2942.59\n",
      "[1490]\ttraining's rmse: 1996.52\tvalid_1's rmse: 2943.99\n",
      "[1500]\ttraining's rmse: 1993.94\tvalid_1's rmse: 2942.28\n",
      "[1510]\ttraining's rmse: 1990.89\tvalid_1's rmse: 2941.34\n",
      "Early stopping, best iteration is:\n",
      "[1450]\ttraining's rmse: 2008.55\tvalid_1's rmse: 2939.75\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1675\n",
      "[LightGBM] [Info] Number of data points in the train set: 32370, number of used features: 20\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 41902.731325\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[10]\ttraining's rmse: 8791.56\tvalid_1's rmse: 9237.26\n",
      "[20]\ttraining's rmse: 5832.66\tvalid_1's rmse: 6125.15\n",
      "[30]\ttraining's rmse: 4749.26\tvalid_1's rmse: 4940.42\n",
      "[40]\ttraining's rmse: 4197.68\tvalid_1's rmse: 4359.31\n",
      "[50]\ttraining's rmse: 3822.38\tvalid_1's rmse: 3963.98\n",
      "[60]\ttraining's rmse: 3596.51\tvalid_1's rmse: 3736.32\n",
      "[70]\ttraining's rmse: 3431.32\tvalid_1's rmse: 3582.89\n",
      "[80]\ttraining's rmse: 3303.95\tvalid_1's rmse: 3464.8\n",
      "[90]\ttraining's rmse: 3199.77\tvalid_1's rmse: 3368.82\n",
      "[100]\ttraining's rmse: 3114.19\tvalid_1's rmse: 3286.93\n",
      "[110]\ttraining's rmse: 3049.22\tvalid_1's rmse: 3230.44\n",
      "[120]\ttraining's rmse: 2995.15\tvalid_1's rmse: 3194.34\n",
      "[130]\ttraining's rmse: 2932.36\tvalid_1's rmse: 3140.01\n",
      "[140]\ttraining's rmse: 2881.99\tvalid_1's rmse: 3105.43\n",
      "[150]\ttraining's rmse: 2838.44\tvalid_1's rmse: 3073.95\n",
      "[160]\ttraining's rmse: 2801.17\tvalid_1's rmse: 3050.1\n",
      "[170]\ttraining's rmse: 2766.57\tvalid_1's rmse: 3030.11\n",
      "[180]\ttraining's rmse: 2734.43\tvalid_1's rmse: 3010.22\n",
      "[190]\ttraining's rmse: 2701.14\tvalid_1's rmse: 2984.54\n",
      "[200]\ttraining's rmse: 2671.44\tvalid_1's rmse: 2963.6\n",
      "[210]\ttraining's rmse: 2642.51\tvalid_1's rmse: 2946.94\n",
      "[220]\ttraining's rmse: 2618.18\tvalid_1's rmse: 2931.38\n",
      "[230]\ttraining's rmse: 2597.67\tvalid_1's rmse: 2924.31\n",
      "[240]\ttraining's rmse: 2572.83\tvalid_1's rmse: 2912.25\n",
      "[250]\ttraining's rmse: 2552.44\tvalid_1's rmse: 2901.53\n",
      "[260]\ttraining's rmse: 2531.84\tvalid_1's rmse: 2893.3\n",
      "[270]\ttraining's rmse: 2509.74\tvalid_1's rmse: 2884.86\n",
      "[280]\ttraining's rmse: 2491.09\tvalid_1's rmse: 2880.59\n",
      "[290]\ttraining's rmse: 2472.84\tvalid_1's rmse: 2872.44\n",
      "[300]\ttraining's rmse: 2455\tvalid_1's rmse: 2866.44\n",
      "[310]\ttraining's rmse: 2437.8\tvalid_1's rmse: 2858.27\n",
      "[320]\ttraining's rmse: 2423.61\tvalid_1's rmse: 2853.37\n",
      "[330]\ttraining's rmse: 2406.1\tvalid_1's rmse: 2844.83\n",
      "[340]\ttraining's rmse: 2390.77\tvalid_1's rmse: 2835.67\n",
      "[350]\ttraining's rmse: 2375.86\tvalid_1's rmse: 2832.13\n",
      "[360]\ttraining's rmse: 2363.13\tvalid_1's rmse: 2824.6\n",
      "[370]\ttraining's rmse: 2348.88\tvalid_1's rmse: 2820.37\n",
      "[380]\ttraining's rmse: 2335.61\tvalid_1's rmse: 2816.9\n",
      "[390]\ttraining's rmse: 2323.5\tvalid_1's rmse: 2816.6\n",
      "[400]\ttraining's rmse: 2312.87\tvalid_1's rmse: 2816.85\n",
      "[410]\ttraining's rmse: 2301.79\tvalid_1's rmse: 2813.7\n",
      "[420]\ttraining's rmse: 2289.49\tvalid_1's rmse: 2807.9\n",
      "[430]\ttraining's rmse: 2277.06\tvalid_1's rmse: 2802.38\n",
      "[440]\ttraining's rmse: 2266.43\tvalid_1's rmse: 2793.65\n",
      "[450]\ttraining's rmse: 2254.24\tvalid_1's rmse: 2790.23\n",
      "[460]\ttraining's rmse: 2242.3\tvalid_1's rmse: 2787.3\n",
      "[470]\ttraining's rmse: 2232.11\tvalid_1's rmse: 2784.2\n",
      "[480]\ttraining's rmse: 2223.94\tvalid_1's rmse: 2781.95\n",
      "[490]\ttraining's rmse: 2214.41\tvalid_1's rmse: 2781.58\n",
      "[500]\ttraining's rmse: 2204.8\tvalid_1's rmse: 2779.5\n",
      "[510]\ttraining's rmse: 2196.78\tvalid_1's rmse: 2778.57\n",
      "[520]\ttraining's rmse: 2187.52\tvalid_1's rmse: 2775.68\n",
      "[530]\ttraining's rmse: 2178.3\tvalid_1's rmse: 2774.56\n",
      "[540]\ttraining's rmse: 2169.07\tvalid_1's rmse: 2775.06\n",
      "[550]\ttraining's rmse: 2160.58\tvalid_1's rmse: 2774.73\n",
      "[560]\ttraining's rmse: 2153.32\tvalid_1's rmse: 2775.01\n",
      "[570]\ttraining's rmse: 2145.32\tvalid_1's rmse: 2776\n",
      "[580]\ttraining's rmse: 2136.62\tvalid_1's rmse: 2777.08\n",
      "Early stopping, best iteration is:\n",
      "[526]\ttraining's rmse: 2181.65\tvalid_1's rmse: 2772.93\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1805\n",
      "[LightGBM] [Info] Number of data points in the train set: 19863, number of used features: 20\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 67243.384886\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[10]\ttraining's rmse: 17199.5\tvalid_1's rmse: 16723.5\n",
      "[20]\ttraining's rmse: 10878.9\tvalid_1's rmse: 10888.1\n",
      "[30]\ttraining's rmse: 8595.27\tvalid_1's rmse: 8942.32\n",
      "[40]\ttraining's rmse: 7449.32\tvalid_1's rmse: 7970.98\n",
      "[50]\ttraining's rmse: 6789.86\tvalid_1's rmse: 7376.51\n",
      "[60]\ttraining's rmse: 6363.68\tvalid_1's rmse: 7039.98\n",
      "[70]\ttraining's rmse: 6077.11\tvalid_1's rmse: 6832.01\n",
      "[80]\ttraining's rmse: 5858.07\tvalid_1's rmse: 6653.73\n",
      "[90]\ttraining's rmse: 5651.25\tvalid_1's rmse: 6522.89\n",
      "[100]\ttraining's rmse: 5495.8\tvalid_1's rmse: 6432.57\n",
      "[110]\ttraining's rmse: 5347.46\tvalid_1's rmse: 6349.23\n",
      "[120]\ttraining's rmse: 5237.28\tvalid_1's rmse: 6270.08\n",
      "[130]\ttraining's rmse: 5127.79\tvalid_1's rmse: 6215.17\n",
      "[140]\ttraining's rmse: 5028.14\tvalid_1's rmse: 6165.33\n",
      "[150]\ttraining's rmse: 4942.49\tvalid_1's rmse: 6116.51\n",
      "[160]\ttraining's rmse: 4862.75\tvalid_1's rmse: 6078.86\n",
      "[170]\ttraining's rmse: 4799.04\tvalid_1's rmse: 6051.26\n",
      "[180]\ttraining's rmse: 4726.59\tvalid_1's rmse: 6007.64\n",
      "[190]\ttraining's rmse: 4663.61\tvalid_1's rmse: 5993.64\n",
      "[200]\ttraining's rmse: 4608.09\tvalid_1's rmse: 5985.47\n",
      "[210]\ttraining's rmse: 4541.88\tvalid_1's rmse: 5964.65\n",
      "[220]\ttraining's rmse: 4490.7\tvalid_1's rmse: 5948.24\n",
      "[230]\ttraining's rmse: 4443.63\tvalid_1's rmse: 5926.19\n",
      "[240]\ttraining's rmse: 4396.8\tvalid_1's rmse: 5920.05\n",
      "[250]\ttraining's rmse: 4349.64\tvalid_1's rmse: 5910.77\n",
      "[260]\ttraining's rmse: 4308.4\tvalid_1's rmse: 5907.98\n",
      "[270]\ttraining's rmse: 4262.37\tvalid_1's rmse: 5874.61\n",
      "[280]\ttraining's rmse: 4217.26\tvalid_1's rmse: 5872.13\n",
      "[290]\ttraining's rmse: 4174.29\tvalid_1's rmse: 5869.31\n",
      "[300]\ttraining's rmse: 4143.3\tvalid_1's rmse: 5868.03\n",
      "[310]\ttraining's rmse: 4109.31\tvalid_1's rmse: 5862.32\n",
      "[320]\ttraining's rmse: 4072.6\tvalid_1's rmse: 5844.2\n",
      "[330]\ttraining's rmse: 4040.43\tvalid_1's rmse: 5843\n",
      "[340]\ttraining's rmse: 4013.12\tvalid_1's rmse: 5834.96\n",
      "[350]\ttraining's rmse: 3978.52\tvalid_1's rmse: 5841.83\n",
      "[360]\ttraining's rmse: 3949.79\tvalid_1's rmse: 5837.31\n",
      "[370]\ttraining's rmse: 3917.56\tvalid_1's rmse: 5829.66\n",
      "[380]\ttraining's rmse: 3887.08\tvalid_1's rmse: 5828.64\n",
      "[390]\ttraining's rmse: 3864.45\tvalid_1's rmse: 5820.92\n",
      "[400]\ttraining's rmse: 3836.71\tvalid_1's rmse: 5822.66\n",
      "[410]\ttraining's rmse: 3811.64\tvalid_1's rmse: 5818.3\n",
      "[420]\ttraining's rmse: 3784.62\tvalid_1's rmse: 5804.82\n",
      "[430]\ttraining's rmse: 3761.47\tvalid_1's rmse: 5797.52\n",
      "[440]\ttraining's rmse: 3736.99\tvalid_1's rmse: 5793.94\n",
      "[450]\ttraining's rmse: 3711.52\tvalid_1's rmse: 5784.52\n",
      "[460]\ttraining's rmse: 3691.01\tvalid_1's rmse: 5778\n",
      "[470]\ttraining's rmse: 3668.21\tvalid_1's rmse: 5781.26\n",
      "[480]\ttraining's rmse: 3646.22\tvalid_1's rmse: 5781.63\n",
      "[490]\ttraining's rmse: 3626.08\tvalid_1's rmse: 5784.58\n",
      "[500]\ttraining's rmse: 3607.42\tvalid_1's rmse: 5788.05\n",
      "[510]\ttraining's rmse: 3587.91\tvalid_1's rmse: 5782.24\n",
      "[520]\ttraining's rmse: 3569\tvalid_1's rmse: 5777.92\n",
      "[530]\ttraining's rmse: 3545.39\tvalid_1's rmse: 5778.99\n",
      "[540]\ttraining's rmse: 3527.58\tvalid_1's rmse: 5776.68\n",
      "[550]\ttraining's rmse: 3507.39\tvalid_1's rmse: 5773.84\n",
      "[560]\ttraining's rmse: 3489.66\tvalid_1's rmse: 5772.21\n",
      "[570]\ttraining's rmse: 3470.1\tvalid_1's rmse: 5768.16\n",
      "[580]\ttraining's rmse: 3452.41\tvalid_1's rmse: 5771.43\n",
      "[590]\ttraining's rmse: 3436.14\tvalid_1's rmse: 5763.31\n",
      "[600]\ttraining's rmse: 3418.2\tvalid_1's rmse: 5764.04\n",
      "[610]\ttraining's rmse: 3402.1\tvalid_1's rmse: 5766.46\n",
      "[620]\ttraining's rmse: 3386.37\tvalid_1's rmse: 5772.47\n",
      "[630]\ttraining's rmse: 3369.74\tvalid_1's rmse: 5774.13\n",
      "[640]\ttraining's rmse: 3352.83\tvalid_1's rmse: 5774.51\n",
      "[650]\ttraining's rmse: 3337.21\tvalid_1's rmse: 5775.55\n",
      "[660]\ttraining's rmse: 3322.06\tvalid_1's rmse: 5773.65\n",
      "Early stopping, best iteration is:\n",
      "[602]\ttraining's rmse: 3413.87\tvalid_1's rmse: 5760.11\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000925 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1818\n",
      "[LightGBM] [Info] Number of data points in the train set: 51843, number of used features: 21\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 38634.298652\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[10]\ttraining's rmse: 9987.3\tvalid_1's rmse: 9809.85\n",
      "[20]\ttraining's rmse: 6621.8\tvalid_1's rmse: 6589.5\n",
      "[30]\ttraining's rmse: 5155.07\tvalid_1's rmse: 5200.14\n",
      "[40]\ttraining's rmse: 4356.86\tvalid_1's rmse: 4426.11\n",
      "[50]\ttraining's rmse: 3919.88\tvalid_1's rmse: 3988.38\n",
      "[60]\ttraining's rmse: 3657.4\tvalid_1's rmse: 3735.9\n",
      "[70]\ttraining's rmse: 3469.82\tvalid_1's rmse: 3544.8\n",
      "[80]\ttraining's rmse: 3321.74\tvalid_1's rmse: 3395.61\n",
      "[90]\ttraining's rmse: 3202.24\tvalid_1's rmse: 3280.89\n",
      "[100]\ttraining's rmse: 3103.01\tvalid_1's rmse: 3184.06\n",
      "[110]\ttraining's rmse: 3018.93\tvalid_1's rmse: 3095.99\n",
      "[120]\ttraining's rmse: 2948.21\tvalid_1's rmse: 3035.54\n",
      "[130]\ttraining's rmse: 2880.74\tvalid_1's rmse: 2972.22\n",
      "[140]\ttraining's rmse: 2824.17\tvalid_1's rmse: 2926.96\n",
      "[150]\ttraining's rmse: 2779.16\tvalid_1's rmse: 2885.65\n",
      "[160]\ttraining's rmse: 2735.67\tvalid_1's rmse: 2847.84\n",
      "[170]\ttraining's rmse: 2696.68\tvalid_1's rmse: 2820.81\n",
      "[180]\ttraining's rmse: 2654.78\tvalid_1's rmse: 2783.68\n",
      "[190]\ttraining's rmse: 2621.02\tvalid_1's rmse: 2755.78\n",
      "[200]\ttraining's rmse: 2585.12\tvalid_1's rmse: 2730.12\n",
      "[210]\ttraining's rmse: 2553.31\tvalid_1's rmse: 2704.9\n",
      "[220]\ttraining's rmse: 2525.66\tvalid_1's rmse: 2680.2\n",
      "[230]\ttraining's rmse: 2501.38\tvalid_1's rmse: 2665.95\n",
      "[240]\ttraining's rmse: 2477.13\tvalid_1's rmse: 2646.95\n",
      "[250]\ttraining's rmse: 2453.73\tvalid_1's rmse: 2633.47\n",
      "[260]\ttraining's rmse: 2432.23\tvalid_1's rmse: 2616.49\n",
      "[270]\ttraining's rmse: 2409.22\tvalid_1's rmse: 2603.96\n",
      "[280]\ttraining's rmse: 2392.42\tvalid_1's rmse: 2591.59\n",
      "[290]\ttraining's rmse: 2374.29\tvalid_1's rmse: 2579\n",
      "[300]\ttraining's rmse: 2352.55\tvalid_1's rmse: 2565.35\n",
      "[310]\ttraining's rmse: 2337.61\tvalid_1's rmse: 2555.64\n",
      "[320]\ttraining's rmse: 2322.11\tvalid_1's rmse: 2545.72\n",
      "[330]\ttraining's rmse: 2305.01\tvalid_1's rmse: 2536.78\n",
      "[340]\ttraining's rmse: 2290.78\tvalid_1's rmse: 2526.65\n",
      "[350]\ttraining's rmse: 2274.79\tvalid_1's rmse: 2520.23\n",
      "[360]\ttraining's rmse: 2262.06\tvalid_1's rmse: 2513.24\n",
      "[370]\ttraining's rmse: 2249.88\tvalid_1's rmse: 2506.85\n",
      "[380]\ttraining's rmse: 2234.98\tvalid_1's rmse: 2496.34\n",
      "[390]\ttraining's rmse: 2222.57\tvalid_1's rmse: 2491.95\n",
      "[400]\ttraining's rmse: 2211.9\tvalid_1's rmse: 2486.01\n",
      "[410]\ttraining's rmse: 2200.41\tvalid_1's rmse: 2482.18\n",
      "[420]\ttraining's rmse: 2189.18\tvalid_1's rmse: 2474.87\n",
      "[430]\ttraining's rmse: 2177.13\tvalid_1's rmse: 2467.44\n",
      "[440]\ttraining's rmse: 2165.61\tvalid_1's rmse: 2461.77\n",
      "[450]\ttraining's rmse: 2154.23\tvalid_1's rmse: 2455.98\n",
      "[460]\ttraining's rmse: 2143.73\tvalid_1's rmse: 2451.39\n",
      "[470]\ttraining's rmse: 2134.86\tvalid_1's rmse: 2446.57\n",
      "[480]\ttraining's rmse: 2125.62\tvalid_1's rmse: 2441.11\n",
      "[490]\ttraining's rmse: 2115.53\tvalid_1's rmse: 2437.2\n",
      "[500]\ttraining's rmse: 2105.9\tvalid_1's rmse: 2432.15\n",
      "[510]\ttraining's rmse: 2095.9\tvalid_1's rmse: 2427.53\n",
      "[520]\ttraining's rmse: 2085.83\tvalid_1's rmse: 2424.58\n",
      "[530]\ttraining's rmse: 2077.96\tvalid_1's rmse: 2421.08\n",
      "[540]\ttraining's rmse: 2069.43\tvalid_1's rmse: 2418.59\n",
      "[550]\ttraining's rmse: 2062.21\tvalid_1's rmse: 2414.39\n",
      "[560]\ttraining's rmse: 2053.62\tvalid_1's rmse: 2410.87\n",
      "[570]\ttraining's rmse: 2046.57\tvalid_1's rmse: 2406.45\n",
      "[580]\ttraining's rmse: 2039.03\tvalid_1's rmse: 2401.39\n",
      "[590]\ttraining's rmse: 2030.83\tvalid_1's rmse: 2398.43\n",
      "[600]\ttraining's rmse: 2024.17\tvalid_1's rmse: 2397.5\n",
      "[610]\ttraining's rmse: 2016.25\tvalid_1's rmse: 2397.03\n",
      "[620]\ttraining's rmse: 2008.73\tvalid_1's rmse: 2395.48\n",
      "[630]\ttraining's rmse: 2001.99\tvalid_1's rmse: 2393.82\n",
      "[640]\ttraining's rmse: 1994.42\tvalid_1's rmse: 2390.58\n",
      "[650]\ttraining's rmse: 1987.66\tvalid_1's rmse: 2389.92\n",
      "[660]\ttraining's rmse: 1981.62\tvalid_1's rmse: 2390.25\n",
      "[670]\ttraining's rmse: 1974.44\tvalid_1's rmse: 2387.1\n",
      "[680]\ttraining's rmse: 1968.44\tvalid_1's rmse: 2384.66\n",
      "[690]\ttraining's rmse: 1961.62\tvalid_1's rmse: 2383.29\n",
      "[700]\ttraining's rmse: 1955.89\tvalid_1's rmse: 2380.62\n",
      "[710]\ttraining's rmse: 1949.44\tvalid_1's rmse: 2377.8\n",
      "[720]\ttraining's rmse: 1943.66\tvalid_1's rmse: 2377.8\n",
      "[730]\ttraining's rmse: 1937.62\tvalid_1's rmse: 2375.68\n",
      "[740]\ttraining's rmse: 1931.58\tvalid_1's rmse: 2374.17\n",
      "[750]\ttraining's rmse: 1925.81\tvalid_1's rmse: 2374.08\n",
      "[760]\ttraining's rmse: 1919.74\tvalid_1's rmse: 2374.6\n",
      "[770]\ttraining's rmse: 1913.9\tvalid_1's rmse: 2372.94\n",
      "[780]\ttraining's rmse: 1908.98\tvalid_1's rmse: 2369.02\n",
      "[790]\ttraining's rmse: 1902.95\tvalid_1's rmse: 2367.07\n",
      "[800]\ttraining's rmse: 1897.75\tvalid_1's rmse: 2364.99\n",
      "[810]\ttraining's rmse: 1892.96\tvalid_1's rmse: 2363.77\n",
      "[820]\ttraining's rmse: 1888.64\tvalid_1's rmse: 2361.92\n",
      "[830]\ttraining's rmse: 1882.7\tvalid_1's rmse: 2360.81\n",
      "[840]\ttraining's rmse: 1877.71\tvalid_1's rmse: 2359.92\n",
      "[850]\ttraining's rmse: 1872.47\tvalid_1's rmse: 2357.39\n",
      "[860]\ttraining's rmse: 1867.95\tvalid_1's rmse: 2356.05\n",
      "[870]\ttraining's rmse: 1863.08\tvalid_1's rmse: 2353.18\n",
      "[880]\ttraining's rmse: 1858.93\tvalid_1's rmse: 2353.06\n",
      "[890]\ttraining's rmse: 1854.41\tvalid_1's rmse: 2354.24\n",
      "[900]\ttraining's rmse: 1850.07\tvalid_1's rmse: 2353.59\n",
      "[910]\ttraining's rmse: 1845.16\tvalid_1's rmse: 2353.85\n",
      "[920]\ttraining's rmse: 1840.95\tvalid_1's rmse: 2352.27\n",
      "[930]\ttraining's rmse: 1836.55\tvalid_1's rmse: 2351.81\n",
      "[940]\ttraining's rmse: 1831.25\tvalid_1's rmse: 2352.04\n",
      "[950]\ttraining's rmse: 1827.07\tvalid_1's rmse: 2351.25\n",
      "[960]\ttraining's rmse: 1822.42\tvalid_1's rmse: 2349.16\n",
      "[970]\ttraining's rmse: 1818.64\tvalid_1's rmse: 2349.6\n",
      "[980]\ttraining's rmse: 1815.31\tvalid_1's rmse: 2349.05\n",
      "[990]\ttraining's rmse: 1811.37\tvalid_1's rmse: 2346.68\n",
      "[1000]\ttraining's rmse: 1807.69\tvalid_1's rmse: 2345.95\n",
      "[1010]\ttraining's rmse: 1803.99\tvalid_1's rmse: 2344.99\n",
      "[1020]\ttraining's rmse: 1800.16\tvalid_1's rmse: 2343.91\n",
      "[1030]\ttraining's rmse: 1795.85\tvalid_1's rmse: 2344.81\n",
      "[1040]\ttraining's rmse: 1792.69\tvalid_1's rmse: 2344.92\n",
      "[1050]\ttraining's rmse: 1788.82\tvalid_1's rmse: 2344.54\n",
      "[1060]\ttraining's rmse: 1784.92\tvalid_1's rmse: 2344.24\n",
      "[1070]\ttraining's rmse: 1781.24\tvalid_1's rmse: 2342.75\n",
      "[1080]\ttraining's rmse: 1777.43\tvalid_1's rmse: 2343.09\n",
      "[1090]\ttraining's rmse: 1773.86\tvalid_1's rmse: 2343.65\n",
      "[1100]\ttraining's rmse: 1770.64\tvalid_1's rmse: 2342.6\n",
      "[1110]\ttraining's rmse: 1767.02\tvalid_1's rmse: 2341.92\n",
      "[1120]\ttraining's rmse: 1763.29\tvalid_1's rmse: 2341.01\n",
      "[1130]\ttraining's rmse: 1759.85\tvalid_1's rmse: 2340.19\n",
      "[1140]\ttraining's rmse: 1755.72\tvalid_1's rmse: 2341.66\n",
      "[1150]\ttraining's rmse: 1752.58\tvalid_1's rmse: 2340.77\n",
      "[1160]\ttraining's rmse: 1748.86\tvalid_1's rmse: 2340.75\n",
      "[1170]\ttraining's rmse: 1745.92\tvalid_1's rmse: 2339.72\n",
      "[1180]\ttraining's rmse: 1742.49\tvalid_1's rmse: 2338.65\n",
      "[1190]\ttraining's rmse: 1738.97\tvalid_1's rmse: 2339.54\n",
      "[1200]\ttraining's rmse: 1735.35\tvalid_1's rmse: 2340.59\n",
      "[1210]\ttraining's rmse: 1731.96\tvalid_1's rmse: 2340.14\n",
      "[1220]\ttraining's rmse: 1728.62\tvalid_1's rmse: 2339.49\n",
      "[1230]\ttraining's rmse: 1725.15\tvalid_1's rmse: 2338.85\n",
      "[1240]\ttraining's rmse: 1721.85\tvalid_1's rmse: 2338.38\n",
      "[1250]\ttraining's rmse: 1718.94\tvalid_1's rmse: 2338.39\n",
      "[1260]\ttraining's rmse: 1715.68\tvalid_1's rmse: 2337.49\n",
      "[1270]\ttraining's rmse: 1712.55\tvalid_1's rmse: 2337.13\n",
      "[1280]\ttraining's rmse: 1709.14\tvalid_1's rmse: 2338.75\n",
      "[1290]\ttraining's rmse: 1706.08\tvalid_1's rmse: 2338.92\n",
      "[1300]\ttraining's rmse: 1702.62\tvalid_1's rmse: 2337.95\n",
      "[1310]\ttraining's rmse: 1699.4\tvalid_1's rmse: 2339.06\n",
      "[1320]\ttraining's rmse: 1696.23\tvalid_1's rmse: 2338.84\n",
      "[1330]\ttraining's rmse: 1693.27\tvalid_1's rmse: 2338.25\n",
      "Early stopping, best iteration is:\n",
      "[1270]\ttraining's rmse: 1712.55\tvalid_1's rmse: 2337.13\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000508 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1560\n",
      "[LightGBM] [Info] Number of data points in the train set: 17627, number of used features: 20\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 33736.373858\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[10]\ttraining's rmse: 7596.64\tvalid_1's rmse: 7378.76\n",
      "[20]\ttraining's rmse: 4592.19\tvalid_1's rmse: 4551.9\n",
      "[30]\ttraining's rmse: 3488.18\tvalid_1's rmse: 3566.9\n",
      "[40]\ttraining's rmse: 2998.22\tvalid_1's rmse: 3142.42\n",
      "[50]\ttraining's rmse: 2738.05\tvalid_1's rmse: 2915.88\n",
      "[60]\ttraining's rmse: 2574.32\tvalid_1's rmse: 2771.85\n",
      "[70]\ttraining's rmse: 2455.5\tvalid_1's rmse: 2676.41\n",
      "[80]\ttraining's rmse: 2365.94\tvalid_1's rmse: 2617.99\n",
      "[90]\ttraining's rmse: 2297\tvalid_1's rmse: 2575.07\n",
      "[100]\ttraining's rmse: 2239.68\tvalid_1's rmse: 2536.44\n",
      "[110]\ttraining's rmse: 2187.83\tvalid_1's rmse: 2507.35\n",
      "[120]\ttraining's rmse: 2136.56\tvalid_1's rmse: 2480.77\n",
      "[130]\ttraining's rmse: 2096.59\tvalid_1's rmse: 2464.97\n",
      "[140]\ttraining's rmse: 2056.01\tvalid_1's rmse: 2438.38\n",
      "[150]\ttraining's rmse: 2023.16\tvalid_1's rmse: 2419.09\n",
      "[160]\ttraining's rmse: 1991.42\tvalid_1's rmse: 2398.25\n",
      "[170]\ttraining's rmse: 1963.62\tvalid_1's rmse: 2384.98\n",
      "[180]\ttraining's rmse: 1940.02\tvalid_1's rmse: 2373.44\n",
      "[190]\ttraining's rmse: 1916.03\tvalid_1's rmse: 2359.38\n",
      "[200]\ttraining's rmse: 1894.47\tvalid_1's rmse: 2352.69\n",
      "[210]\ttraining's rmse: 1872.89\tvalid_1's rmse: 2341.63\n",
      "[220]\ttraining's rmse: 1851.88\tvalid_1's rmse: 2334.95\n",
      "[230]\ttraining's rmse: 1832.48\tvalid_1's rmse: 2326.44\n",
      "[240]\ttraining's rmse: 1814.74\tvalid_1's rmse: 2311.94\n",
      "[250]\ttraining's rmse: 1798.85\tvalid_1's rmse: 2306.6\n",
      "[260]\ttraining's rmse: 1782.29\tvalid_1's rmse: 2295.49\n",
      "[270]\ttraining's rmse: 1766.82\tvalid_1's rmse: 2291.7\n",
      "[280]\ttraining's rmse: 1752.25\tvalid_1's rmse: 2293.95\n",
      "[290]\ttraining's rmse: 1739.89\tvalid_1's rmse: 2294.02\n",
      "[300]\ttraining's rmse: 1725.59\tvalid_1's rmse: 2287.18\n",
      "[310]\ttraining's rmse: 1712.29\tvalid_1's rmse: 2284.94\n",
      "[320]\ttraining's rmse: 1700.37\tvalid_1's rmse: 2283\n",
      "[330]\ttraining's rmse: 1686.31\tvalid_1's rmse: 2283.12\n",
      "[340]\ttraining's rmse: 1673.48\tvalid_1's rmse: 2275.53\n",
      "[350]\ttraining's rmse: 1661.57\tvalid_1's rmse: 2268.59\n",
      "[360]\ttraining's rmse: 1650.24\tvalid_1's rmse: 2263.51\n",
      "[370]\ttraining's rmse: 1640.1\tvalid_1's rmse: 2265.38\n",
      "[380]\ttraining's rmse: 1629.89\tvalid_1's rmse: 2263.09\n",
      "[390]\ttraining's rmse: 1620.23\tvalid_1's rmse: 2262.61\n",
      "[400]\ttraining's rmse: 1610.49\tvalid_1's rmse: 2263.01\n",
      "[410]\ttraining's rmse: 1601.88\tvalid_1's rmse: 2260.54\n",
      "[420]\ttraining's rmse: 1592.89\tvalid_1's rmse: 2261.26\n",
      "[430]\ttraining's rmse: 1583.21\tvalid_1's rmse: 2254.54\n",
      "[440]\ttraining's rmse: 1574.63\tvalid_1's rmse: 2254.27\n",
      "[450]\ttraining's rmse: 1567.25\tvalid_1's rmse: 2250.65\n",
      "[460]\ttraining's rmse: 1558.81\tvalid_1's rmse: 2250.2\n",
      "[470]\ttraining's rmse: 1552.18\tvalid_1's rmse: 2248.37\n",
      "[480]\ttraining's rmse: 1545.13\tvalid_1's rmse: 2246.24\n",
      "[490]\ttraining's rmse: 1538.16\tvalid_1's rmse: 2248.17\n",
      "[500]\ttraining's rmse: 1529.74\tvalid_1's rmse: 2247.26\n",
      "[510]\ttraining's rmse: 1522.48\tvalid_1's rmse: 2242.71\n",
      "[520]\ttraining's rmse: 1515.6\tvalid_1's rmse: 2242.39\n",
      "[530]\ttraining's rmse: 1507.65\tvalid_1's rmse: 2242.55\n",
      "[540]\ttraining's rmse: 1498.67\tvalid_1's rmse: 2234.45\n",
      "[550]\ttraining's rmse: 1491.47\tvalid_1's rmse: 2229.8\n",
      "[560]\ttraining's rmse: 1484.6\tvalid_1's rmse: 2231.99\n",
      "[570]\ttraining's rmse: 1477.89\tvalid_1's rmse: 2231.34\n",
      "[580]\ttraining's rmse: 1471.66\tvalid_1's rmse: 2229.21\n",
      "[590]\ttraining's rmse: 1465.56\tvalid_1's rmse: 2228.11\n",
      "[600]\ttraining's rmse: 1459.12\tvalid_1's rmse: 2226.91\n",
      "[610]\ttraining's rmse: 1452.99\tvalid_1's rmse: 2227.41\n",
      "[620]\ttraining's rmse: 1446.59\tvalid_1's rmse: 2226.86\n",
      "[630]\ttraining's rmse: 1441.19\tvalid_1's rmse: 2225.26\n",
      "[640]\ttraining's rmse: 1435.48\tvalid_1's rmse: 2223.25\n",
      "[650]\ttraining's rmse: 1430.68\tvalid_1's rmse: 2224.09\n",
      "[660]\ttraining's rmse: 1425.22\tvalid_1's rmse: 2223.22\n",
      "[670]\ttraining's rmse: 1418.8\tvalid_1's rmse: 2223.42\n",
      "[680]\ttraining's rmse: 1413.84\tvalid_1's rmse: 2221.34\n",
      "[690]\ttraining's rmse: 1408.02\tvalid_1's rmse: 2223.43\n",
      "[700]\ttraining's rmse: 1402.01\tvalid_1's rmse: 2220.02\n",
      "[710]\ttraining's rmse: 1396.85\tvalid_1's rmse: 2218.16\n",
      "[720]\ttraining's rmse: 1392.17\tvalid_1's rmse: 2219.77\n",
      "[730]\ttraining's rmse: 1387.52\tvalid_1's rmse: 2222.28\n",
      "[740]\ttraining's rmse: 1381.73\tvalid_1's rmse: 2219.68\n",
      "[750]\ttraining's rmse: 1376.58\tvalid_1's rmse: 2217.87\n",
      "[760]\ttraining's rmse: 1372.11\tvalid_1's rmse: 2216.21\n",
      "[770]\ttraining's rmse: 1367.69\tvalid_1's rmse: 2216.72\n",
      "[780]\ttraining's rmse: 1363.29\tvalid_1's rmse: 2220.03\n",
      "[790]\ttraining's rmse: 1358.73\tvalid_1's rmse: 2222.04\n",
      "[800]\ttraining's rmse: 1353.11\tvalid_1's rmse: 2221.82\n",
      "[810]\ttraining's rmse: 1348.3\tvalid_1's rmse: 2222.21\n",
      "[820]\ttraining's rmse: 1343.26\tvalid_1's rmse: 2221.14\n",
      "Early stopping, best iteration is:\n",
      "[761]\ttraining's rmse: 1371.67\tvalid_1's rmse: 2215.88\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000511 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1678\n",
      "[LightGBM] [Info] Number of data points in the train set: 103589, number of used features: 21\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 33881.163183\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[10]\ttraining's rmse: 8334.57\tvalid_1's rmse: 8277.99\n",
      "[20]\ttraining's rmse: 5412.93\tvalid_1's rmse: 5509.1\n",
      "[30]\ttraining's rmse: 4275.78\tvalid_1's rmse: 4429.42\n",
      "[40]\ttraining's rmse: 3647.78\tvalid_1's rmse: 3826.92\n",
      "[50]\ttraining's rmse: 3275.92\tvalid_1's rmse: 3461.58\n",
      "[60]\ttraining's rmse: 3048.43\tvalid_1's rmse: 3237.44\n",
      "[70]\ttraining's rmse: 2888.29\tvalid_1's rmse: 3075.59\n",
      "[80]\ttraining's rmse: 2776.32\tvalid_1's rmse: 2959.46\n",
      "[90]\ttraining's rmse: 2684.95\tvalid_1's rmse: 2869.89\n",
      "[100]\ttraining's rmse: 2610.91\tvalid_1's rmse: 2797.5\n",
      "[110]\ttraining's rmse: 2550.12\tvalid_1's rmse: 2743.46\n",
      "[120]\ttraining's rmse: 2496.91\tvalid_1's rmse: 2696\n",
      "[130]\ttraining's rmse: 2446.29\tvalid_1's rmse: 2652.07\n",
      "[140]\ttraining's rmse: 2407.58\tvalid_1's rmse: 2617.47\n",
      "[150]\ttraining's rmse: 2376.39\tvalid_1's rmse: 2589.27\n",
      "[160]\ttraining's rmse: 2336.96\tvalid_1's rmse: 2551.65\n",
      "[170]\ttraining's rmse: 2307.64\tvalid_1's rmse: 2526.6\n",
      "[180]\ttraining's rmse: 2281.4\tvalid_1's rmse: 2501.27\n",
      "[190]\ttraining's rmse: 2256.52\tvalid_1's rmse: 2480.77\n",
      "[200]\ttraining's rmse: 2230.62\tvalid_1's rmse: 2459.49\n",
      "[210]\ttraining's rmse: 2208.87\tvalid_1's rmse: 2442.14\n",
      "[220]\ttraining's rmse: 2189.63\tvalid_1's rmse: 2426.86\n",
      "[230]\ttraining's rmse: 2173.03\tvalid_1's rmse: 2413.22\n",
      "[240]\ttraining's rmse: 2157.35\tvalid_1's rmse: 2401.35\n",
      "[250]\ttraining's rmse: 2141.55\tvalid_1's rmse: 2388.78\n",
      "[260]\ttraining's rmse: 2127.09\tvalid_1's rmse: 2377.38\n",
      "[270]\ttraining's rmse: 2111.27\tvalid_1's rmse: 2366.23\n",
      "[280]\ttraining's rmse: 2098.64\tvalid_1's rmse: 2359.08\n",
      "[290]\ttraining's rmse: 2084.68\tvalid_1's rmse: 2351.83\n",
      "[300]\ttraining's rmse: 2071.13\tvalid_1's rmse: 2343.06\n",
      "[310]\ttraining's rmse: 2059.65\tvalid_1's rmse: 2336\n",
      "[320]\ttraining's rmse: 2048.6\tvalid_1's rmse: 2328.6\n",
      "[330]\ttraining's rmse: 2039.52\tvalid_1's rmse: 2322.77\n",
      "[340]\ttraining's rmse: 2028.35\tvalid_1's rmse: 2316.94\n",
      "[350]\ttraining's rmse: 2019.45\tvalid_1's rmse: 2310.22\n",
      "[360]\ttraining's rmse: 2009.61\tvalid_1's rmse: 2304.48\n",
      "[370]\ttraining's rmse: 2000.49\tvalid_1's rmse: 2301.85\n",
      "[380]\ttraining's rmse: 1990.44\tvalid_1's rmse: 2294.73\n",
      "[390]\ttraining's rmse: 1982.53\tvalid_1's rmse: 2291.12\n",
      "[400]\ttraining's rmse: 1972.45\tvalid_1's rmse: 2285.51\n",
      "[410]\ttraining's rmse: 1964.75\tvalid_1's rmse: 2282.38\n",
      "[420]\ttraining's rmse: 1956.11\tvalid_1's rmse: 2276.83\n",
      "[430]\ttraining's rmse: 1948.93\tvalid_1's rmse: 2271.46\n",
      "[440]\ttraining's rmse: 1941.32\tvalid_1's rmse: 2267.18\n",
      "[450]\ttraining's rmse: 1934.39\tvalid_1's rmse: 2264.51\n",
      "[460]\ttraining's rmse: 1927.68\tvalid_1's rmse: 2261.46\n",
      "[470]\ttraining's rmse: 1920.71\tvalid_1's rmse: 2256.42\n",
      "[480]\ttraining's rmse: 1913.93\tvalid_1's rmse: 2253.15\n",
      "[490]\ttraining's rmse: 1907.16\tvalid_1's rmse: 2249.41\n",
      "[500]\ttraining's rmse: 1900.64\tvalid_1's rmse: 2247.66\n",
      "[510]\ttraining's rmse: 1894.1\tvalid_1's rmse: 2243.08\n",
      "[520]\ttraining's rmse: 1887.72\tvalid_1's rmse: 2239.97\n",
      "[530]\ttraining's rmse: 1882.24\tvalid_1's rmse: 2236.35\n",
      "[540]\ttraining's rmse: 1875.76\tvalid_1's rmse: 2232.88\n",
      "[550]\ttraining's rmse: 1870.28\tvalid_1's rmse: 2231.3\n",
      "[560]\ttraining's rmse: 1864.92\tvalid_1's rmse: 2229.42\n",
      "[570]\ttraining's rmse: 1859.43\tvalid_1's rmse: 2227.25\n",
      "[580]\ttraining's rmse: 1854.24\tvalid_1's rmse: 2225.02\n",
      "[590]\ttraining's rmse: 1849.05\tvalid_1's rmse: 2222.3\n",
      "[600]\ttraining's rmse: 1843.73\tvalid_1's rmse: 2219.09\n",
      "[610]\ttraining's rmse: 1838.68\tvalid_1's rmse: 2216.59\n",
      "[620]\ttraining's rmse: 1833.84\tvalid_1's rmse: 2214.79\n",
      "[630]\ttraining's rmse: 1829.91\tvalid_1's rmse: 2213.89\n",
      "[640]\ttraining's rmse: 1825.07\tvalid_1's rmse: 2211.29\n",
      "[650]\ttraining's rmse: 1819.82\tvalid_1's rmse: 2208\n",
      "[660]\ttraining's rmse: 1815.52\tvalid_1's rmse: 2206.52\n",
      "[670]\ttraining's rmse: 1810.65\tvalid_1's rmse: 2204.88\n",
      "[680]\ttraining's rmse: 1806.48\tvalid_1's rmse: 2203.82\n",
      "[690]\ttraining's rmse: 1802.22\tvalid_1's rmse: 2202.12\n",
      "[700]\ttraining's rmse: 1797.9\tvalid_1's rmse: 2201.07\n",
      "[710]\ttraining's rmse: 1793.96\tvalid_1's rmse: 2200.6\n",
      "[720]\ttraining's rmse: 1789.86\tvalid_1's rmse: 2198.92\n",
      "[730]\ttraining's rmse: 1785.57\tvalid_1's rmse: 2198.92\n",
      "[740]\ttraining's rmse: 1781.17\tvalid_1's rmse: 2197.51\n",
      "[750]\ttraining's rmse: 1777.04\tvalid_1's rmse: 2195.68\n",
      "[760]\ttraining's rmse: 1773.13\tvalid_1's rmse: 2194.26\n",
      "[770]\ttraining's rmse: 1769.26\tvalid_1's rmse: 2194.19\n",
      "[780]\ttraining's rmse: 1765.42\tvalid_1's rmse: 2193.49\n",
      "[790]\ttraining's rmse: 1762.27\tvalid_1's rmse: 2192.36\n",
      "[800]\ttraining's rmse: 1758.74\tvalid_1's rmse: 2191.56\n",
      "[810]\ttraining's rmse: 1755.39\tvalid_1's rmse: 2189.88\n",
      "[820]\ttraining's rmse: 1751.59\tvalid_1's rmse: 2188.07\n",
      "[830]\ttraining's rmse: 1747.52\tvalid_1's rmse: 2186.98\n",
      "[840]\ttraining's rmse: 1744.7\tvalid_1's rmse: 2186.38\n",
      "[850]\ttraining's rmse: 1741.54\tvalid_1's rmse: 2185.29\n",
      "[860]\ttraining's rmse: 1738.13\tvalid_1's rmse: 2184.6\n",
      "[870]\ttraining's rmse: 1734.62\tvalid_1's rmse: 2183.96\n",
      "[880]\ttraining's rmse: 1730.89\tvalid_1's rmse: 2183.7\n",
      "[890]\ttraining's rmse: 1728.28\tvalid_1's rmse: 2184.85\n",
      "[900]\ttraining's rmse: 1725.21\tvalid_1's rmse: 2184.11\n",
      "[910]\ttraining's rmse: 1721.88\tvalid_1's rmse: 2182.2\n",
      "[920]\ttraining's rmse: 1718.28\tvalid_1's rmse: 2181.49\n",
      "[930]\ttraining's rmse: 1715.09\tvalid_1's rmse: 2180.96\n",
      "[940]\ttraining's rmse: 1712.09\tvalid_1's rmse: 2180.04\n",
      "[950]\ttraining's rmse: 1708.77\tvalid_1's rmse: 2178.8\n",
      "[960]\ttraining's rmse: 1705.67\tvalid_1's rmse: 2177.44\n",
      "[970]\ttraining's rmse: 1702.41\tvalid_1's rmse: 2176.2\n",
      "[980]\ttraining's rmse: 1699.25\tvalid_1's rmse: 2175.85\n",
      "[990]\ttraining's rmse: 1695.95\tvalid_1's rmse: 2175.05\n",
      "[1000]\ttraining's rmse: 1693.08\tvalid_1's rmse: 2174.56\n",
      "[1010]\ttraining's rmse: 1690.36\tvalid_1's rmse: 2174.57\n",
      "[1020]\ttraining's rmse: 1687.27\tvalid_1's rmse: 2172.65\n",
      "[1030]\ttraining's rmse: 1684.44\tvalid_1's rmse: 2171.41\n",
      "[1040]\ttraining's rmse: 1681.53\tvalid_1's rmse: 2171.52\n",
      "[1050]\ttraining's rmse: 1678.89\tvalid_1's rmse: 2170.69\n",
      "[1060]\ttraining's rmse: 1676.06\tvalid_1's rmse: 2169.93\n",
      "[1070]\ttraining's rmse: 1673.58\tvalid_1's rmse: 2170.19\n",
      "[1080]\ttraining's rmse: 1670.97\tvalid_1's rmse: 2170.2\n",
      "[1090]\ttraining's rmse: 1668.48\tvalid_1's rmse: 2169.7\n",
      "[1100]\ttraining's rmse: 1665.94\tvalid_1's rmse: 2169.16\n",
      "[1110]\ttraining's rmse: 1663.83\tvalid_1's rmse: 2168.48\n",
      "[1120]\ttraining's rmse: 1661.31\tvalid_1's rmse: 2167.93\n",
      "[1130]\ttraining's rmse: 1658.96\tvalid_1's rmse: 2167.4\n",
      "[1140]\ttraining's rmse: 1656.64\tvalid_1's rmse: 2167.76\n",
      "[1150]\ttraining's rmse: 1653.95\tvalid_1's rmse: 2167.51\n",
      "[1160]\ttraining's rmse: 1651.07\tvalid_1's rmse: 2166.69\n",
      "[1170]\ttraining's rmse: 1648.47\tvalid_1's rmse: 2166.26\n",
      "[1180]\ttraining's rmse: 1646.18\tvalid_1's rmse: 2166.2\n",
      "[1190]\ttraining's rmse: 1643.78\tvalid_1's rmse: 2164.1\n",
      "[1200]\ttraining's rmse: 1641.25\tvalid_1's rmse: 2163.97\n",
      "[1210]\ttraining's rmse: 1638.97\tvalid_1's rmse: 2164.44\n",
      "[1220]\ttraining's rmse: 1636.75\tvalid_1's rmse: 2164.56\n",
      "[1230]\ttraining's rmse: 1634.16\tvalid_1's rmse: 2164.62\n",
      "[1240]\ttraining's rmse: 1631.75\tvalid_1's rmse: 2165.18\n",
      "[1250]\ttraining's rmse: 1628.98\tvalid_1's rmse: 2164.35\n",
      "[1260]\ttraining's rmse: 1626.68\tvalid_1's rmse: 2163.74\n",
      "[1270]\ttraining's rmse: 1624.52\tvalid_1's rmse: 2162.9\n",
      "[1280]\ttraining's rmse: 1622.45\tvalid_1's rmse: 2162.98\n",
      "[1290]\ttraining's rmse: 1620.43\tvalid_1's rmse: 2163.15\n",
      "[1300]\ttraining's rmse: 1618.16\tvalid_1's rmse: 2162.67\n",
      "[1310]\ttraining's rmse: 1615.9\tvalid_1's rmse: 2161.9\n",
      "[1320]\ttraining's rmse: 1613.94\tvalid_1's rmse: 2161.59\n",
      "[1330]\ttraining's rmse: 1611.54\tvalid_1's rmse: 2161.71\n",
      "[1340]\ttraining's rmse: 1609.45\tvalid_1's rmse: 2161.75\n",
      "[1350]\ttraining's rmse: 1607.45\tvalid_1's rmse: 2161.96\n",
      "[1360]\ttraining's rmse: 1605.24\tvalid_1's rmse: 2161.22\n",
      "[1370]\ttraining's rmse: 1603.37\tvalid_1's rmse: 2162.42\n",
      "[1380]\ttraining's rmse: 1601.35\tvalid_1's rmse: 2162.12\n",
      "Early stopping, best iteration is:\n",
      "[1329]\ttraining's rmse: 1611.87\tvalid_1's rmse: 2161.17\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1690\n",
      "[LightGBM] [Info] Number of data points in the train set: 47314, number of used features: 21\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 31950.140424\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[10]\ttraining's rmse: 7565.3\tvalid_1's rmse: 7337.99\n",
      "[20]\ttraining's rmse: 4778.84\tvalid_1's rmse: 4639.97\n",
      "[30]\ttraining's rmse: 3745.21\tvalid_1's rmse: 3648.29\n",
      "[40]\ttraining's rmse: 3229.45\tvalid_1's rmse: 3145.38\n",
      "[50]\ttraining's rmse: 2940.98\tvalid_1's rmse: 2868.05\n",
      "[60]\ttraining's rmse: 2760.41\tvalid_1's rmse: 2702.24\n",
      "[70]\ttraining's rmse: 2642.49\tvalid_1's rmse: 2607.66\n",
      "[80]\ttraining's rmse: 2540.36\tvalid_1's rmse: 2515.71\n",
      "[90]\ttraining's rmse: 2469.58\tvalid_1's rmse: 2454.27\n",
      "[100]\ttraining's rmse: 2417.55\tvalid_1's rmse: 2410.33\n",
      "[110]\ttraining's rmse: 2362.81\tvalid_1's rmse: 2368.13\n",
      "[120]\ttraining's rmse: 2320.88\tvalid_1's rmse: 2340.85\n",
      "[130]\ttraining's rmse: 2278.55\tvalid_1's rmse: 2306.28\n",
      "[140]\ttraining's rmse: 2241.35\tvalid_1's rmse: 2274.39\n",
      "[150]\ttraining's rmse: 2213.36\tvalid_1's rmse: 2260.19\n",
      "[160]\ttraining's rmse: 2184.24\tvalid_1's rmse: 2241.94\n",
      "[170]\ttraining's rmse: 2160.31\tvalid_1's rmse: 2225.93\n",
      "[180]\ttraining's rmse: 2135.97\tvalid_1's rmse: 2211.26\n",
      "[190]\ttraining's rmse: 2116.87\tvalid_1's rmse: 2200.44\n",
      "[200]\ttraining's rmse: 2097.85\tvalid_1's rmse: 2188.66\n",
      "[210]\ttraining's rmse: 2076.52\tvalid_1's rmse: 2177.01\n",
      "[220]\ttraining's rmse: 2057.8\tvalid_1's rmse: 2168.97\n",
      "[230]\ttraining's rmse: 2042.16\tvalid_1's rmse: 2161.08\n",
      "[240]\ttraining's rmse: 2025.2\tvalid_1's rmse: 2150.97\n",
      "[250]\ttraining's rmse: 2009.39\tvalid_1's rmse: 2144.27\n",
      "[260]\ttraining's rmse: 1996.2\tvalid_1's rmse: 2135.96\n",
      "[270]\ttraining's rmse: 1983.42\tvalid_1's rmse: 2128.23\n",
      "[280]\ttraining's rmse: 1969.42\tvalid_1's rmse: 2122.61\n",
      "[290]\ttraining's rmse: 1957.57\tvalid_1's rmse: 2119.81\n",
      "[300]\ttraining's rmse: 1947.2\tvalid_1's rmse: 2117.96\n",
      "[310]\ttraining's rmse: 1935.8\tvalid_1's rmse: 2111.89\n",
      "[320]\ttraining's rmse: 1925.25\tvalid_1's rmse: 2109.36\n",
      "[330]\ttraining's rmse: 1915.64\tvalid_1's rmse: 2107.7\n",
      "[340]\ttraining's rmse: 1905.93\tvalid_1's rmse: 2103.03\n",
      "[350]\ttraining's rmse: 1896.81\tvalid_1's rmse: 2098.78\n",
      "[360]\ttraining's rmse: 1888.86\tvalid_1's rmse: 2097.68\n",
      "[370]\ttraining's rmse: 1880.28\tvalid_1's rmse: 2095.18\n",
      "[380]\ttraining's rmse: 1870.16\tvalid_1's rmse: 2091.09\n",
      "[390]\ttraining's rmse: 1861.73\tvalid_1's rmse: 2087.98\n",
      "[400]\ttraining's rmse: 1854.1\tvalid_1's rmse: 2085.66\n",
      "[410]\ttraining's rmse: 1846.17\tvalid_1's rmse: 2084.05\n",
      "[420]\ttraining's rmse: 1837.99\tvalid_1's rmse: 2083.48\n",
      "[430]\ttraining's rmse: 1830.71\tvalid_1's rmse: 2080.98\n",
      "[440]\ttraining's rmse: 1823.5\tvalid_1's rmse: 2081.97\n",
      "[450]\ttraining's rmse: 1816.91\tvalid_1's rmse: 2079.8\n",
      "[460]\ttraining's rmse: 1809.26\tvalid_1's rmse: 2080.86\n",
      "[470]\ttraining's rmse: 1801.4\tvalid_1's rmse: 2078.68\n",
      "[480]\ttraining's rmse: 1794.37\tvalid_1's rmse: 2077.28\n",
      "[490]\ttraining's rmse: 1788.54\tvalid_1's rmse: 2075.89\n",
      "[500]\ttraining's rmse: 1781.89\tvalid_1's rmse: 2074.76\n",
      "[510]\ttraining's rmse: 1775.98\tvalid_1's rmse: 2073.35\n",
      "[520]\ttraining's rmse: 1770.19\tvalid_1's rmse: 2072.43\n",
      "[530]\ttraining's rmse: 1763.84\tvalid_1's rmse: 2070.7\n",
      "[540]\ttraining's rmse: 1758.72\tvalid_1's rmse: 2070.67\n",
      "[550]\ttraining's rmse: 1753.44\tvalid_1's rmse: 2070.7\n",
      "[560]\ttraining's rmse: 1748.02\tvalid_1's rmse: 2069.71\n",
      "[570]\ttraining's rmse: 1742.91\tvalid_1's rmse: 2068.7\n",
      "[580]\ttraining's rmse: 1738.29\tvalid_1's rmse: 2065.72\n",
      "[590]\ttraining's rmse: 1733.26\tvalid_1's rmse: 2065.46\n",
      "[600]\ttraining's rmse: 1727.89\tvalid_1's rmse: 2063.4\n",
      "[610]\ttraining's rmse: 1721.61\tvalid_1's rmse: 2061.65\n",
      "[620]\ttraining's rmse: 1716.88\tvalid_1's rmse: 2060.87\n",
      "[630]\ttraining's rmse: 1711.34\tvalid_1's rmse: 2059.86\n",
      "[640]\ttraining's rmse: 1706.94\tvalid_1's rmse: 2059.22\n",
      "[650]\ttraining's rmse: 1702.76\tvalid_1's rmse: 2057.52\n",
      "[660]\ttraining's rmse: 1698.75\tvalid_1's rmse: 2056.64\n",
      "[670]\ttraining's rmse: 1693.93\tvalid_1's rmse: 2057.46\n",
      "[680]\ttraining's rmse: 1689.95\tvalid_1's rmse: 2058.49\n",
      "[690]\ttraining's rmse: 1685.91\tvalid_1's rmse: 2058.7\n",
      "[700]\ttraining's rmse: 1681.62\tvalid_1's rmse: 2056.03\n",
      "[710]\ttraining's rmse: 1677.75\tvalid_1's rmse: 2056.85\n",
      "[720]\ttraining's rmse: 1674.08\tvalid_1's rmse: 2055.7\n",
      "[730]\ttraining's rmse: 1669.95\tvalid_1's rmse: 2054.53\n",
      "[740]\ttraining's rmse: 1665.34\tvalid_1's rmse: 2053.61\n",
      "[750]\ttraining's rmse: 1661.66\tvalid_1's rmse: 2053.14\n",
      "[760]\ttraining's rmse: 1656.65\tvalid_1's rmse: 2052.24\n",
      "[770]\ttraining's rmse: 1651.58\tvalid_1's rmse: 2052.34\n",
      "[780]\ttraining's rmse: 1647.3\tvalid_1's rmse: 2052.24\n",
      "[790]\ttraining's rmse: 1642.35\tvalid_1's rmse: 2052.51\n",
      "[800]\ttraining's rmse: 1638.55\tvalid_1's rmse: 2053.17\n",
      "[810]\ttraining's rmse: 1635.19\tvalid_1's rmse: 2053\n",
      "[820]\ttraining's rmse: 1631.05\tvalid_1's rmse: 2052.69\n",
      "Early stopping, best iteration is:\n",
      "[769]\ttraining's rmse: 1651.99\tvalid_1's rmse: 2051.87\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1719\n",
      "[LightGBM] [Info] Number of data points in the train set: 35723, number of used features: 24\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 45204.710075\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[10]\ttraining's rmse: 10713.1\tvalid_1's rmse: 10803.3\n",
      "[20]\ttraining's rmse: 6697.74\tvalid_1's rmse: 6817.42\n",
      "[30]\ttraining's rmse: 5199.39\tvalid_1's rmse: 5282.38\n",
      "[40]\ttraining's rmse: 4484.52\tvalid_1's rmse: 4574.26\n",
      "[50]\ttraining's rmse: 4060.45\tvalid_1's rmse: 4162.85\n",
      "[60]\ttraining's rmse: 3801.49\tvalid_1's rmse: 3930.2\n",
      "[70]\ttraining's rmse: 3608.6\tvalid_1's rmse: 3758.05\n",
      "[80]\ttraining's rmse: 3461.28\tvalid_1's rmse: 3632.75\n",
      "[90]\ttraining's rmse: 3329.54\tvalid_1's rmse: 3502.25\n",
      "[100]\ttraining's rmse: 3239.06\tvalid_1's rmse: 3422.25\n",
      "[110]\ttraining's rmse: 3166.88\tvalid_1's rmse: 3369.11\n",
      "[120]\ttraining's rmse: 3096.24\tvalid_1's rmse: 3310.34\n",
      "[130]\ttraining's rmse: 3034.12\tvalid_1's rmse: 3258.98\n",
      "[140]\ttraining's rmse: 2980.53\tvalid_1's rmse: 3218.92\n",
      "[150]\ttraining's rmse: 2924.18\tvalid_1's rmse: 3178.1\n",
      "[160]\ttraining's rmse: 2876.19\tvalid_1's rmse: 3138.83\n",
      "[170]\ttraining's rmse: 2832.66\tvalid_1's rmse: 3111.04\n",
      "[180]\ttraining's rmse: 2794.29\tvalid_1's rmse: 3080\n",
      "[190]\ttraining's rmse: 2757.93\tvalid_1's rmse: 3055.69\n",
      "[200]\ttraining's rmse: 2717.19\tvalid_1's rmse: 3028.84\n",
      "[210]\ttraining's rmse: 2687.34\tvalid_1's rmse: 3002.39\n",
      "[220]\ttraining's rmse: 2656.47\tvalid_1's rmse: 2986.15\n",
      "[230]\ttraining's rmse: 2628.31\tvalid_1's rmse: 2977.54\n",
      "[240]\ttraining's rmse: 2600.72\tvalid_1's rmse: 2962.22\n",
      "[250]\ttraining's rmse: 2574.89\tvalid_1's rmse: 2949.83\n",
      "[260]\ttraining's rmse: 2553.55\tvalid_1's rmse: 2938.39\n",
      "[270]\ttraining's rmse: 2532\tvalid_1's rmse: 2925.18\n",
      "[280]\ttraining's rmse: 2514.69\tvalid_1's rmse: 2913.75\n",
      "[290]\ttraining's rmse: 2492.47\tvalid_1's rmse: 2907.08\n",
      "[300]\ttraining's rmse: 2474.59\tvalid_1's rmse: 2900.21\n",
      "[310]\ttraining's rmse: 2455.35\tvalid_1's rmse: 2891\n",
      "[320]\ttraining's rmse: 2436.97\tvalid_1's rmse: 2880.52\n",
      "[330]\ttraining's rmse: 2420.3\tvalid_1's rmse: 2872.05\n",
      "[340]\ttraining's rmse: 2401.48\tvalid_1's rmse: 2864.48\n",
      "[350]\ttraining's rmse: 2384.8\tvalid_1's rmse: 2856.72\n",
      "[360]\ttraining's rmse: 2369.65\tvalid_1's rmse: 2850.75\n",
      "[370]\ttraining's rmse: 2353.95\tvalid_1's rmse: 2843.55\n",
      "[380]\ttraining's rmse: 2338.35\tvalid_1's rmse: 2837.24\n",
      "[390]\ttraining's rmse: 2324.68\tvalid_1's rmse: 2830.51\n",
      "[400]\ttraining's rmse: 2312.23\tvalid_1's rmse: 2824.62\n",
      "[410]\ttraining's rmse: 2298.95\tvalid_1's rmse: 2822.59\n",
      "[420]\ttraining's rmse: 2283.2\tvalid_1's rmse: 2817.09\n",
      "[430]\ttraining's rmse: 2269.53\tvalid_1's rmse: 2811.11\n",
      "[440]\ttraining's rmse: 2257.07\tvalid_1's rmse: 2805.83\n",
      "[450]\ttraining's rmse: 2246.55\tvalid_1's rmse: 2798.92\n",
      "[460]\ttraining's rmse: 2236.07\tvalid_1's rmse: 2793.1\n",
      "[470]\ttraining's rmse: 2225.18\tvalid_1's rmse: 2790.13\n",
      "[480]\ttraining's rmse: 2212.41\tvalid_1's rmse: 2784.41\n",
      "[490]\ttraining's rmse: 2199.92\tvalid_1's rmse: 2779.02\n",
      "[500]\ttraining's rmse: 2189.15\tvalid_1's rmse: 2776.21\n",
      "[510]\ttraining's rmse: 2179.71\tvalid_1's rmse: 2776.58\n",
      "[520]\ttraining's rmse: 2169.88\tvalid_1's rmse: 2771.42\n",
      "[530]\ttraining's rmse: 2161.94\tvalid_1's rmse: 2770.24\n",
      "[540]\ttraining's rmse: 2151.39\tvalid_1's rmse: 2766.91\n",
      "[550]\ttraining's rmse: 2141.76\tvalid_1's rmse: 2765.42\n",
      "[560]\ttraining's rmse: 2132.56\tvalid_1's rmse: 2761.73\n",
      "[570]\ttraining's rmse: 2123.9\tvalid_1's rmse: 2759.43\n",
      "[580]\ttraining's rmse: 2114.13\tvalid_1's rmse: 2755.34\n",
      "[590]\ttraining's rmse: 2105.81\tvalid_1's rmse: 2752.77\n",
      "[600]\ttraining's rmse: 2097.81\tvalid_1's rmse: 2749.17\n",
      "[610]\ttraining's rmse: 2089.91\tvalid_1's rmse: 2746.9\n",
      "[620]\ttraining's rmse: 2082.28\tvalid_1's rmse: 2745.7\n",
      "[630]\ttraining's rmse: 2075.16\tvalid_1's rmse: 2741.49\n",
      "[640]\ttraining's rmse: 2067.16\tvalid_1's rmse: 2739.12\n",
      "[650]\ttraining's rmse: 2059.45\tvalid_1's rmse: 2736.95\n",
      "[660]\ttraining's rmse: 2052.11\tvalid_1's rmse: 2736.27\n",
      "[670]\ttraining's rmse: 2043.67\tvalid_1's rmse: 2734.52\n",
      "[680]\ttraining's rmse: 2036.32\tvalid_1's rmse: 2734.1\n",
      "[690]\ttraining's rmse: 2029.17\tvalid_1's rmse: 2732.28\n",
      "[700]\ttraining's rmse: 2022.12\tvalid_1's rmse: 2729.89\n",
      "[710]\ttraining's rmse: 2015.91\tvalid_1's rmse: 2725.86\n",
      "[720]\ttraining's rmse: 2009.11\tvalid_1's rmse: 2724.2\n",
      "[730]\ttraining's rmse: 2001.87\tvalid_1's rmse: 2721.05\n",
      "[740]\ttraining's rmse: 1996.01\tvalid_1's rmse: 2721.44\n",
      "[750]\ttraining's rmse: 1989.35\tvalid_1's rmse: 2722.13\n",
      "[760]\ttraining's rmse: 1981.67\tvalid_1's rmse: 2722.26\n",
      "[770]\ttraining's rmse: 1975.68\tvalid_1's rmse: 2718.89\n",
      "[780]\ttraining's rmse: 1969.47\tvalid_1's rmse: 2717.44\n",
      "[790]\ttraining's rmse: 1963.31\tvalid_1's rmse: 2715.92\n",
      "[800]\ttraining's rmse: 1957.33\tvalid_1's rmse: 2712.84\n",
      "[810]\ttraining's rmse: 1950.57\tvalid_1's rmse: 2713.65\n",
      "[820]\ttraining's rmse: 1944.88\tvalid_1's rmse: 2715.73\n",
      "[830]\ttraining's rmse: 1939.35\tvalid_1's rmse: 2715.51\n",
      "[840]\ttraining's rmse: 1933.38\tvalid_1's rmse: 2715.4\n",
      "[850]\ttraining's rmse: 1927.5\tvalid_1's rmse: 2716.25\n",
      "[860]\ttraining's rmse: 1922.16\tvalid_1's rmse: 2715.33\n",
      "Early stopping, best iteration is:\n",
      "[802]\ttraining's rmse: 1955.77\tvalid_1's rmse: 2712.77\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000843 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1615\n",
      "[LightGBM] [Info] Number of data points in the train set: 36456, number of used features: 23\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 60903.114768\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[10]\ttraining's rmse: 14617\tvalid_1's rmse: 14751.5\n",
      "[20]\ttraining's rmse: 9814.08\tvalid_1's rmse: 10020.3\n",
      "[30]\ttraining's rmse: 7753.3\tvalid_1's rmse: 7959.02\n",
      "[40]\ttraining's rmse: 6590.8\tvalid_1's rmse: 6763.3\n",
      "[50]\ttraining's rmse: 5898.18\tvalid_1's rmse: 6072.86\n",
      "[60]\ttraining's rmse: 5399.44\tvalid_1's rmse: 5614.45\n",
      "[70]\ttraining's rmse: 5100.24\tvalid_1's rmse: 5371.68\n",
      "[80]\ttraining's rmse: 4881.31\tvalid_1's rmse: 5202.69\n",
      "[90]\ttraining's rmse: 4677.14\tvalid_1's rmse: 5031.74\n",
      "[100]\ttraining's rmse: 4538.3\tvalid_1's rmse: 4911.24\n",
      "[110]\ttraining's rmse: 4401.09\tvalid_1's rmse: 4816.25\n",
      "[120]\ttraining's rmse: 4305.77\tvalid_1's rmse: 4754.31\n",
      "[130]\ttraining's rmse: 4210.25\tvalid_1's rmse: 4688.36\n",
      "[140]\ttraining's rmse: 4134.34\tvalid_1's rmse: 4626.08\n",
      "[150]\ttraining's rmse: 4073.94\tvalid_1's rmse: 4585.23\n",
      "[160]\ttraining's rmse: 4010.72\tvalid_1's rmse: 4553.17\n",
      "[170]\ttraining's rmse: 3943.47\tvalid_1's rmse: 4505.36\n",
      "[180]\ttraining's rmse: 3882.53\tvalid_1's rmse: 4476.17\n",
      "[190]\ttraining's rmse: 3827.21\tvalid_1's rmse: 4450.85\n",
      "[200]\ttraining's rmse: 3775.69\tvalid_1's rmse: 4420.18\n",
      "[210]\ttraining's rmse: 3734.63\tvalid_1's rmse: 4390.49\n",
      "[220]\ttraining's rmse: 3688.23\tvalid_1's rmse: 4371.92\n",
      "[230]\ttraining's rmse: 3649.97\tvalid_1's rmse: 4346.85\n",
      "[240]\ttraining's rmse: 3615.04\tvalid_1's rmse: 4326.27\n",
      "[250]\ttraining's rmse: 3581.85\tvalid_1's rmse: 4301.59\n",
      "[260]\ttraining's rmse: 3549.8\tvalid_1's rmse: 4274.37\n",
      "[270]\ttraining's rmse: 3519.15\tvalid_1's rmse: 4255.23\n",
      "[280]\ttraining's rmse: 3486.84\tvalid_1's rmse: 4239.23\n",
      "[290]\ttraining's rmse: 3462.86\tvalid_1's rmse: 4227.13\n",
      "[300]\ttraining's rmse: 3436.38\tvalid_1's rmse: 4218.69\n",
      "[310]\ttraining's rmse: 3410.58\tvalid_1's rmse: 4209.66\n",
      "[320]\ttraining's rmse: 3386.2\tvalid_1's rmse: 4201.49\n",
      "[330]\ttraining's rmse: 3362.24\tvalid_1's rmse: 4187.19\n",
      "[340]\ttraining's rmse: 3338.84\tvalid_1's rmse: 4175.03\n",
      "[350]\ttraining's rmse: 3313.96\tvalid_1's rmse: 4162.93\n",
      "[360]\ttraining's rmse: 3291.9\tvalid_1's rmse: 4152.97\n",
      "[370]\ttraining's rmse: 3271.93\tvalid_1's rmse: 4142.04\n",
      "[380]\ttraining's rmse: 3254.45\tvalid_1's rmse: 4134.01\n",
      "[390]\ttraining's rmse: 3232.69\tvalid_1's rmse: 4127.53\n",
      "[400]\ttraining's rmse: 3217.48\tvalid_1's rmse: 4119.69\n",
      "[410]\ttraining's rmse: 3200.07\tvalid_1's rmse: 4109.53\n",
      "[420]\ttraining's rmse: 3183.67\tvalid_1's rmse: 4105.96\n",
      "[430]\ttraining's rmse: 3165.67\tvalid_1's rmse: 4101\n",
      "[440]\ttraining's rmse: 3151.02\tvalid_1's rmse: 4096.09\n",
      "[450]\ttraining's rmse: 3134.66\tvalid_1's rmse: 4089.4\n",
      "[460]\ttraining's rmse: 3118.5\tvalid_1's rmse: 4087.62\n",
      "[470]\ttraining's rmse: 3103.16\tvalid_1's rmse: 4084.1\n",
      "[480]\ttraining's rmse: 3086.78\tvalid_1's rmse: 4074.56\n",
      "[490]\ttraining's rmse: 3073.85\tvalid_1's rmse: 4073.53\n",
      "[500]\ttraining's rmse: 3059.65\tvalid_1's rmse: 4068.67\n",
      "[510]\ttraining's rmse: 3044.64\tvalid_1's rmse: 4068.11\n",
      "[520]\ttraining's rmse: 3028.99\tvalid_1's rmse: 4070.35\n",
      "[530]\ttraining's rmse: 3016.41\tvalid_1's rmse: 4066.18\n",
      "[540]\ttraining's rmse: 3002.56\tvalid_1's rmse: 4056.5\n",
      "[550]\ttraining's rmse: 2990.44\tvalid_1's rmse: 4055.94\n",
      "[560]\ttraining's rmse: 2978.79\tvalid_1's rmse: 4052.71\n",
      "[570]\ttraining's rmse: 2965.71\tvalid_1's rmse: 4049.14\n",
      "[580]\ttraining's rmse: 2953.73\tvalid_1's rmse: 4041.48\n",
      "[590]\ttraining's rmse: 2943.46\tvalid_1's rmse: 4039.5\n",
      "[600]\ttraining's rmse: 2932.3\tvalid_1's rmse: 4036.6\n",
      "[610]\ttraining's rmse: 2919.42\tvalid_1's rmse: 4032.67\n",
      "[620]\ttraining's rmse: 2908.26\tvalid_1's rmse: 4028.63\n",
      "[630]\ttraining's rmse: 2895.59\tvalid_1's rmse: 4025.38\n",
      "[640]\ttraining's rmse: 2885.57\tvalid_1's rmse: 4024.3\n",
      "[650]\ttraining's rmse: 2873.68\tvalid_1's rmse: 4022.81\n",
      "[660]\ttraining's rmse: 2862.03\tvalid_1's rmse: 4020.18\n",
      "[670]\ttraining's rmse: 2852.19\tvalid_1's rmse: 4016\n",
      "[680]\ttraining's rmse: 2841.77\tvalid_1's rmse: 4014.88\n",
      "[690]\ttraining's rmse: 2830.06\tvalid_1's rmse: 4008.29\n",
      "[700]\ttraining's rmse: 2820.11\tvalid_1's rmse: 4003.41\n",
      "[710]\ttraining's rmse: 2811.93\tvalid_1's rmse: 3998.61\n",
      "[720]\ttraining's rmse: 2801.1\tvalid_1's rmse: 3996.79\n",
      "[730]\ttraining's rmse: 2792.14\tvalid_1's rmse: 3995.18\n",
      "[740]\ttraining's rmse: 2783.78\tvalid_1's rmse: 3995.63\n",
      "[750]\ttraining's rmse: 2773.62\tvalid_1's rmse: 3993.97\n",
      "[760]\ttraining's rmse: 2764.47\tvalid_1's rmse: 3992.44\n",
      "[770]\ttraining's rmse: 2755.88\tvalid_1's rmse: 3993.58\n",
      "[780]\ttraining's rmse: 2747.08\tvalid_1's rmse: 3989.47\n",
      "[790]\ttraining's rmse: 2738.64\tvalid_1's rmse: 3988.91\n",
      "[800]\ttraining's rmse: 2730.62\tvalid_1's rmse: 3986.39\n",
      "[810]\ttraining's rmse: 2721.31\tvalid_1's rmse: 3983.42\n",
      "[820]\ttraining's rmse: 2714.98\tvalid_1's rmse: 3982.09\n",
      "[830]\ttraining's rmse: 2707.7\tvalid_1's rmse: 3981.35\n",
      "[840]\ttraining's rmse: 2699.78\tvalid_1's rmse: 3976.46\n",
      "[850]\ttraining's rmse: 2692.29\tvalid_1's rmse: 3975.07\n",
      "[860]\ttraining's rmse: 2685.17\tvalid_1's rmse: 3976.43\n",
      "[870]\ttraining's rmse: 2677.24\tvalid_1's rmse: 3974.78\n",
      "[880]\ttraining's rmse: 2669.41\tvalid_1's rmse: 3973.68\n",
      "[890]\ttraining's rmse: 2659.99\tvalid_1's rmse: 3969.32\n",
      "[900]\ttraining's rmse: 2653.64\tvalid_1's rmse: 3966.45\n",
      "[910]\ttraining's rmse: 2646.42\tvalid_1's rmse: 3965.45\n",
      "[920]\ttraining's rmse: 2638.72\tvalid_1's rmse: 3966.81\n",
      "[930]\ttraining's rmse: 2631.29\tvalid_1's rmse: 3964\n",
      "[940]\ttraining's rmse: 2624.78\tvalid_1's rmse: 3962.07\n",
      "[950]\ttraining's rmse: 2618.53\tvalid_1's rmse: 3962.93\n",
      "[960]\ttraining's rmse: 2611.54\tvalid_1's rmse: 3961.72\n",
      "[970]\ttraining's rmse: 2603.97\tvalid_1's rmse: 3965.57\n",
      "[980]\ttraining's rmse: 2597.78\tvalid_1's rmse: 3964.28\n",
      "[990]\ttraining's rmse: 2591.67\tvalid_1's rmse: 3962.5\n",
      "[1000]\ttraining's rmse: 2585.63\tvalid_1's rmse: 3965.09\n",
      "[1010]\ttraining's rmse: 2579.76\tvalid_1's rmse: 3965.48\n",
      "Early stopping, best iteration is:\n",
      "[954]\ttraining's rmse: 2616.1\tvalid_1's rmse: 3960.84\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000858 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1762\n",
      "[LightGBM] [Info] Number of data points in the train set: 36348, number of used features: 23\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 64424.253026\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[10]\ttraining's rmse: 16617\tvalid_1's rmse: 16458.4\n",
      "[20]\ttraining's rmse: 10512.4\tvalid_1's rmse: 10537.9\n",
      "[30]\ttraining's rmse: 8280.67\tvalid_1's rmse: 8400.98\n",
      "[40]\ttraining's rmse: 7149.15\tvalid_1's rmse: 7345.28\n",
      "[50]\ttraining's rmse: 6492.83\tvalid_1's rmse: 6734.75\n",
      "[60]\ttraining's rmse: 6076.97\tvalid_1's rmse: 6347.17\n",
      "[70]\ttraining's rmse: 5772.79\tvalid_1's rmse: 6073.93\n",
      "[80]\ttraining's rmse: 5542.72\tvalid_1's rmse: 5876.58\n",
      "[90]\ttraining's rmse: 5340.3\tvalid_1's rmse: 5694.87\n",
      "[100]\ttraining's rmse: 5174.53\tvalid_1's rmse: 5558.85\n",
      "[110]\ttraining's rmse: 5037.02\tvalid_1's rmse: 5449.66\n",
      "[120]\ttraining's rmse: 4905.04\tvalid_1's rmse: 5341.01\n",
      "[130]\ttraining's rmse: 4811.68\tvalid_1's rmse: 5273.92\n",
      "[140]\ttraining's rmse: 4717.98\tvalid_1's rmse: 5203.37\n",
      "[150]\ttraining's rmse: 4639.86\tvalid_1's rmse: 5145.44\n",
      "[160]\ttraining's rmse: 4566.64\tvalid_1's rmse: 5100.51\n",
      "[170]\ttraining's rmse: 4503.31\tvalid_1's rmse: 5050.66\n",
      "[180]\ttraining's rmse: 4434.21\tvalid_1's rmse: 5006.18\n",
      "[190]\ttraining's rmse: 4367.22\tvalid_1's rmse: 4968.9\n",
      "[200]\ttraining's rmse: 4309.77\tvalid_1's rmse: 4927.08\n",
      "[210]\ttraining's rmse: 4259.91\tvalid_1's rmse: 4905.72\n",
      "[220]\ttraining's rmse: 4208.6\tvalid_1's rmse: 4885.12\n",
      "[230]\ttraining's rmse: 4160.14\tvalid_1's rmse: 4867.08\n",
      "[240]\ttraining's rmse: 4118.4\tvalid_1's rmse: 4833.97\n",
      "[250]\ttraining's rmse: 4076.49\tvalid_1's rmse: 4818.53\n",
      "[260]\ttraining's rmse: 4034.16\tvalid_1's rmse: 4792.46\n",
      "[270]\ttraining's rmse: 3995.68\tvalid_1's rmse: 4773.12\n",
      "[280]\ttraining's rmse: 3959.67\tvalid_1's rmse: 4756.69\n",
      "[290]\ttraining's rmse: 3926.82\tvalid_1's rmse: 4737.19\n",
      "[300]\ttraining's rmse: 3894.6\tvalid_1's rmse: 4719.19\n",
      "[310]\ttraining's rmse: 3863.09\tvalid_1's rmse: 4708.76\n",
      "[320]\ttraining's rmse: 3828.41\tvalid_1's rmse: 4696.42\n",
      "[330]\ttraining's rmse: 3798.52\tvalid_1's rmse: 4678.94\n",
      "[340]\ttraining's rmse: 3771.54\tvalid_1's rmse: 4669.59\n",
      "[350]\ttraining's rmse: 3743.95\tvalid_1's rmse: 4651.11\n",
      "[360]\ttraining's rmse: 3722.04\tvalid_1's rmse: 4639.88\n",
      "[370]\ttraining's rmse: 3696.37\tvalid_1's rmse: 4631.15\n",
      "[380]\ttraining's rmse: 3669.59\tvalid_1's rmse: 4622.68\n",
      "[390]\ttraining's rmse: 3647.14\tvalid_1's rmse: 4609.09\n",
      "[400]\ttraining's rmse: 3623.49\tvalid_1's rmse: 4602.28\n",
      "[410]\ttraining's rmse: 3603.35\tvalid_1's rmse: 4594.07\n",
      "[420]\ttraining's rmse: 3580.62\tvalid_1's rmse: 4590.15\n",
      "[430]\ttraining's rmse: 3561.93\tvalid_1's rmse: 4583.04\n",
      "[440]\ttraining's rmse: 3542.58\tvalid_1's rmse: 4576.73\n",
      "[450]\ttraining's rmse: 3522.07\tvalid_1's rmse: 4570.84\n",
      "[460]\ttraining's rmse: 3501.47\tvalid_1's rmse: 4555.94\n",
      "[470]\ttraining's rmse: 3485.32\tvalid_1's rmse: 4548.39\n",
      "[480]\ttraining's rmse: 3467.64\tvalid_1's rmse: 4541.67\n",
      "[490]\ttraining's rmse: 3450.59\tvalid_1's rmse: 4534.71\n",
      "[500]\ttraining's rmse: 3432.49\tvalid_1's rmse: 4527.86\n",
      "[510]\ttraining's rmse: 3415.41\tvalid_1's rmse: 4520.69\n",
      "[520]\ttraining's rmse: 3401.47\tvalid_1's rmse: 4521.17\n",
      "[530]\ttraining's rmse: 3383.71\tvalid_1's rmse: 4517.74\n",
      "[540]\ttraining's rmse: 3367.49\tvalid_1's rmse: 4510.57\n",
      "[550]\ttraining's rmse: 3349.72\tvalid_1's rmse: 4501.47\n",
      "[560]\ttraining's rmse: 3334.4\tvalid_1's rmse: 4500.96\n",
      "[570]\ttraining's rmse: 3320.3\tvalid_1's rmse: 4498.06\n",
      "[580]\ttraining's rmse: 3307.6\tvalid_1's rmse: 4499.82\n",
      "[590]\ttraining's rmse: 3294.75\tvalid_1's rmse: 4496.29\n",
      "[600]\ttraining's rmse: 3280.69\tvalid_1's rmse: 4491.97\n",
      "[610]\ttraining's rmse: 3266.95\tvalid_1's rmse: 4486.26\n",
      "[620]\ttraining's rmse: 3254.44\tvalid_1's rmse: 4485.1\n",
      "[630]\ttraining's rmse: 3241.86\tvalid_1's rmse: 4483.05\n",
      "[640]\ttraining's rmse: 3230.77\tvalid_1's rmse: 4482.87\n",
      "[650]\ttraining's rmse: 3217.94\tvalid_1's rmse: 4480.26\n",
      "[660]\ttraining's rmse: 3206.09\tvalid_1's rmse: 4477.98\n",
      "[670]\ttraining's rmse: 3193.54\tvalid_1's rmse: 4474.38\n",
      "[680]\ttraining's rmse: 3182.89\tvalid_1's rmse: 4472.82\n",
      "[690]\ttraining's rmse: 3170.51\tvalid_1's rmse: 4474.19\n",
      "[700]\ttraining's rmse: 3156.77\tvalid_1's rmse: 4469.87\n",
      "[710]\ttraining's rmse: 3145.88\tvalid_1's rmse: 4470.99\n",
      "[720]\ttraining's rmse: 3134.61\tvalid_1's rmse: 4467.09\n",
      "[730]\ttraining's rmse: 3123.32\tvalid_1's rmse: 4462.52\n",
      "[740]\ttraining's rmse: 3113.69\tvalid_1's rmse: 4463.16\n",
      "[750]\ttraining's rmse: 3104.38\tvalid_1's rmse: 4461.81\n",
      "[760]\ttraining's rmse: 3093.48\tvalid_1's rmse: 4458.25\n",
      "[770]\ttraining's rmse: 3083.94\tvalid_1's rmse: 4455.41\n",
      "[780]\ttraining's rmse: 3072.44\tvalid_1's rmse: 4456.03\n",
      "[790]\ttraining's rmse: 3063.8\tvalid_1's rmse: 4454.09\n",
      "[800]\ttraining's rmse: 3054.18\tvalid_1's rmse: 4450.78\n",
      "[810]\ttraining's rmse: 3045.62\tvalid_1's rmse: 4446.7\n",
      "[820]\ttraining's rmse: 3036.62\tvalid_1's rmse: 4445.04\n",
      "[830]\ttraining's rmse: 3026.77\tvalid_1's rmse: 4442.23\n",
      "[840]\ttraining's rmse: 3018.64\tvalid_1's rmse: 4440.15\n",
      "[850]\ttraining's rmse: 3010.39\tvalid_1's rmse: 4439.43\n",
      "[860]\ttraining's rmse: 3001.3\tvalid_1's rmse: 4435.74\n",
      "[870]\ttraining's rmse: 2993.52\tvalid_1's rmse: 4434.06\n",
      "[880]\ttraining's rmse: 2985.88\tvalid_1's rmse: 4435.14\n",
      "[890]\ttraining's rmse: 2977.38\tvalid_1's rmse: 4429.86\n",
      "[900]\ttraining's rmse: 2968.19\tvalid_1's rmse: 4426.58\n",
      "[910]\ttraining's rmse: 2958.84\tvalid_1's rmse: 4429.77\n",
      "[920]\ttraining's rmse: 2950.57\tvalid_1's rmse: 4425.28\n",
      "[930]\ttraining's rmse: 2943.93\tvalid_1's rmse: 4425.37\n",
      "[940]\ttraining's rmse: 2935.66\tvalid_1's rmse: 4426.42\n",
      "[950]\ttraining's rmse: 2928.79\tvalid_1's rmse: 4426.32\n",
      "[960]\ttraining's rmse: 2921.91\tvalid_1's rmse: 4424.79\n",
      "[970]\ttraining's rmse: 2914.72\tvalid_1's rmse: 4424.93\n",
      "[980]\ttraining's rmse: 2907.02\tvalid_1's rmse: 4423.65\n",
      "[990]\ttraining's rmse: 2900.82\tvalid_1's rmse: 4424.33\n",
      "[1000]\ttraining's rmse: 2893.88\tvalid_1's rmse: 4423.6\n",
      "[1010]\ttraining's rmse: 2885.6\tvalid_1's rmse: 4424.04\n",
      "[1020]\ttraining's rmse: 2877.33\tvalid_1's rmse: 4424.85\n",
      "[1030]\ttraining's rmse: 2870.39\tvalid_1's rmse: 4422.22\n",
      "Early stopping, best iteration is:\n",
      "[975]\ttraining's rmse: 2911.33\tvalid_1's rmse: 4421.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1733\n",
      "[LightGBM] [Info] Number of data points in the train set: 29587, number of used features: 22\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 48997.481901\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[10]\ttraining's rmse: 12842.1\tvalid_1's rmse: 12634.5\n",
      "[20]\ttraining's rmse: 7950.31\tvalid_1's rmse: 7814.77\n",
      "[30]\ttraining's rmse: 6176.66\tvalid_1's rmse: 6120.35\n",
      "[40]\ttraining's rmse: 5372.71\tvalid_1's rmse: 5398.12\n",
      "[50]\ttraining's rmse: 4905.2\tvalid_1's rmse: 4984.47\n",
      "[60]\ttraining's rmse: 4602.08\tvalid_1's rmse: 4698.86\n",
      "[70]\ttraining's rmse: 4374.93\tvalid_1's rmse: 4555.92\n",
      "[80]\ttraining's rmse: 4198.56\tvalid_1's rmse: 4423.27\n",
      "[90]\ttraining's rmse: 4060.68\tvalid_1's rmse: 4359.19\n",
      "[100]\ttraining's rmse: 3936.96\tvalid_1's rmse: 4267.71\n",
      "[110]\ttraining's rmse: 3842.13\tvalid_1's rmse: 4196.46\n",
      "[120]\ttraining's rmse: 3761.19\tvalid_1's rmse: 4142.72\n",
      "[130]\ttraining's rmse: 3681.02\tvalid_1's rmse: 4095.85\n",
      "[140]\ttraining's rmse: 3615.71\tvalid_1's rmse: 4070.39\n",
      "[150]\ttraining's rmse: 3554\tvalid_1's rmse: 4026.11\n",
      "[160]\ttraining's rmse: 3501.47\tvalid_1's rmse: 4005.82\n",
      "[170]\ttraining's rmse: 3446.38\tvalid_1's rmse: 3978.43\n",
      "[180]\ttraining's rmse: 3399.1\tvalid_1's rmse: 3952.01\n",
      "[190]\ttraining's rmse: 3355.22\tvalid_1's rmse: 3945.86\n",
      "[200]\ttraining's rmse: 3307.77\tvalid_1's rmse: 3919.42\n",
      "[210]\ttraining's rmse: 3267.55\tvalid_1's rmse: 3908.52\n",
      "[220]\ttraining's rmse: 3235.13\tvalid_1's rmse: 3896.71\n",
      "[230]\ttraining's rmse: 3196.55\tvalid_1's rmse: 3876.66\n",
      "[240]\ttraining's rmse: 3164.13\tvalid_1's rmse: 3863.63\n",
      "[250]\ttraining's rmse: 3130.92\tvalid_1's rmse: 3858.41\n",
      "[260]\ttraining's rmse: 3103.06\tvalid_1's rmse: 3850.1\n",
      "[270]\ttraining's rmse: 3076.2\tvalid_1's rmse: 3835.16\n",
      "[280]\ttraining's rmse: 3049.35\tvalid_1's rmse: 3825.62\n",
      "[290]\ttraining's rmse: 3023.7\tvalid_1's rmse: 3812.28\n",
      "[300]\ttraining's rmse: 3001.33\tvalid_1's rmse: 3807.35\n",
      "[310]\ttraining's rmse: 2977.13\tvalid_1's rmse: 3801.52\n",
      "[320]\ttraining's rmse: 2953.66\tvalid_1's rmse: 3796.72\n",
      "[330]\ttraining's rmse: 2930.86\tvalid_1's rmse: 3786.26\n",
      "[340]\ttraining's rmse: 2909.2\tvalid_1's rmse: 3784.92\n",
      "[350]\ttraining's rmse: 2889.16\tvalid_1's rmse: 3776.61\n",
      "[360]\ttraining's rmse: 2869.81\tvalid_1's rmse: 3773.33\n",
      "[370]\ttraining's rmse: 2848.35\tvalid_1's rmse: 3777.35\n",
      "[380]\ttraining's rmse: 2830.4\tvalid_1's rmse: 3768.54\n",
      "[390]\ttraining's rmse: 2810.94\tvalid_1's rmse: 3768.41\n",
      "[400]\ttraining's rmse: 2792.78\tvalid_1's rmse: 3764.55\n",
      "[410]\ttraining's rmse: 2775.64\tvalid_1's rmse: 3753.27\n",
      "[420]\ttraining's rmse: 2760.47\tvalid_1's rmse: 3751.75\n",
      "[430]\ttraining's rmse: 2743.69\tvalid_1's rmse: 3752.13\n",
      "[440]\ttraining's rmse: 2728.52\tvalid_1's rmse: 3751.2\n",
      "[450]\ttraining's rmse: 2714.87\tvalid_1's rmse: 3749.72\n",
      "[460]\ttraining's rmse: 2698.85\tvalid_1's rmse: 3747.26\n",
      "[470]\ttraining's rmse: 2684.19\tvalid_1's rmse: 3744.17\n",
      "[480]\ttraining's rmse: 2670.33\tvalid_1's rmse: 3745.05\n",
      "[490]\ttraining's rmse: 2656.47\tvalid_1's rmse: 3741.36\n",
      "[500]\ttraining's rmse: 2643.61\tvalid_1's rmse: 3736.64\n",
      "[510]\ttraining's rmse: 2632.26\tvalid_1's rmse: 3732.01\n",
      "[520]\ttraining's rmse: 2619.01\tvalid_1's rmse: 3726.35\n",
      "[530]\ttraining's rmse: 2607.75\tvalid_1's rmse: 3722.88\n",
      "[540]\ttraining's rmse: 2597.19\tvalid_1's rmse: 3721.51\n",
      "[550]\ttraining's rmse: 2583.03\tvalid_1's rmse: 3716.3\n",
      "[560]\ttraining's rmse: 2571.18\tvalid_1's rmse: 3709.68\n",
      "[570]\ttraining's rmse: 2561.27\tvalid_1's rmse: 3706.51\n",
      "[580]\ttraining's rmse: 2551.62\tvalid_1's rmse: 3702.98\n",
      "[590]\ttraining's rmse: 2542.04\tvalid_1's rmse: 3706.86\n",
      "[600]\ttraining's rmse: 2531.59\tvalid_1's rmse: 3706.68\n",
      "[610]\ttraining's rmse: 2519.85\tvalid_1's rmse: 3704.23\n",
      "[620]\ttraining's rmse: 2508.59\tvalid_1's rmse: 3699.2\n",
      "[630]\ttraining's rmse: 2499.92\tvalid_1's rmse: 3698.32\n",
      "[640]\ttraining's rmse: 2490.03\tvalid_1's rmse: 3695.76\n",
      "[650]\ttraining's rmse: 2481.26\tvalid_1's rmse: 3692.33\n",
      "[660]\ttraining's rmse: 2470.51\tvalid_1's rmse: 3688.34\n",
      "[670]\ttraining's rmse: 2461.21\tvalid_1's rmse: 3688.27\n",
      "[680]\ttraining's rmse: 2452.17\tvalid_1's rmse: 3690.46\n",
      "[690]\ttraining's rmse: 2442.39\tvalid_1's rmse: 3684.78\n",
      "[700]\ttraining's rmse: 2434.14\tvalid_1's rmse: 3683.42\n",
      "[710]\ttraining's rmse: 2424.52\tvalid_1's rmse: 3683.96\n",
      "[720]\ttraining's rmse: 2415.9\tvalid_1's rmse: 3685.31\n",
      "[730]\ttraining's rmse: 2407.8\tvalid_1's rmse: 3688.28\n",
      "[740]\ttraining's rmse: 2400.04\tvalid_1's rmse: 3691.48\n",
      "[750]\ttraining's rmse: 2390.34\tvalid_1's rmse: 3686.34\n",
      "[760]\ttraining's rmse: 2382.2\tvalid_1's rmse: 3682.09\n",
      "[770]\ttraining's rmse: 2374.02\tvalid_1's rmse: 3681.04\n",
      "[780]\ttraining's rmse: 2365.09\tvalid_1's rmse: 3681.51\n",
      "[790]\ttraining's rmse: 2357.91\tvalid_1's rmse: 3682.5\n",
      "[800]\ttraining's rmse: 2350.37\tvalid_1's rmse: 3681.46\n",
      "[810]\ttraining's rmse: 2342.57\tvalid_1's rmse: 3676.47\n",
      "[820]\ttraining's rmse: 2335.79\tvalid_1's rmse: 3677.79\n",
      "[830]\ttraining's rmse: 2327.61\tvalid_1's rmse: 3678.86\n",
      "[840]\ttraining's rmse: 2320.14\tvalid_1's rmse: 3680.91\n",
      "[850]\ttraining's rmse: 2313.73\tvalid_1's rmse: 3678.67\n",
      "[860]\ttraining's rmse: 2306.35\tvalid_1's rmse: 3675.61\n",
      "[870]\ttraining's rmse: 2300.15\tvalid_1's rmse: 3674.68\n",
      "[880]\ttraining's rmse: 2293.49\tvalid_1's rmse: 3673.61\n",
      "[890]\ttraining's rmse: 2287.58\tvalid_1's rmse: 3672.37\n",
      "[900]\ttraining's rmse: 2280.77\tvalid_1's rmse: 3670.27\n",
      "[910]\ttraining's rmse: 2276.03\tvalid_1's rmse: 3672.66\n",
      "[920]\ttraining's rmse: 2269.16\tvalid_1's rmse: 3669.69\n",
      "[930]\ttraining's rmse: 2262.45\tvalid_1's rmse: 3672.12\n",
      "[940]\ttraining's rmse: 2256.05\tvalid_1's rmse: 3671.16\n",
      "[950]\ttraining's rmse: 2249.49\tvalid_1's rmse: 3669.57\n",
      "[960]\ttraining's rmse: 2242.94\tvalid_1's rmse: 3669.47\n",
      "[970]\ttraining's rmse: 2236.08\tvalid_1's rmse: 3669.14\n",
      "[980]\ttraining's rmse: 2230.08\tvalid_1's rmse: 3665.54\n",
      "[990]\ttraining's rmse: 2224.78\tvalid_1's rmse: 3665.83\n",
      "[1000]\ttraining's rmse: 2218.36\tvalid_1's rmse: 3667.83\n",
      "[1010]\ttraining's rmse: 2212.77\tvalid_1's rmse: 3669.48\n",
      "[1020]\ttraining's rmse: 2207.45\tvalid_1's rmse: 3670.2\n",
      "[1030]\ttraining's rmse: 2202.44\tvalid_1's rmse: 3668.85\n",
      "Early stopping, best iteration is:\n",
      "[976]\ttraining's rmse: 2232.34\tvalid_1's rmse: 3664.32\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000745 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1880\n",
      "[LightGBM] [Info] Number of data points in the train set: 47813, number of used features: 25\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 113593.137766\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[10]\ttraining's rmse: 36125.5\tvalid_1's rmse: 35163\n",
      "[20]\ttraining's rmse: 23581\tvalid_1's rmse: 22511.8\n",
      "[30]\ttraining's rmse: 18807.4\tvalid_1's rmse: 17970\n",
      "[40]\ttraining's rmse: 16618.3\tvalid_1's rmse: 15996.1\n",
      "[50]\ttraining's rmse: 15407.2\tvalid_1's rmse: 14931.7\n",
      "[60]\ttraining's rmse: 14476\tvalid_1's rmse: 14207.3\n",
      "[70]\ttraining's rmse: 13852.7\tvalid_1's rmse: 13734.5\n",
      "[80]\ttraining's rmse: 13304.3\tvalid_1's rmse: 13287.2\n",
      "[90]\ttraining's rmse: 12855.5\tvalid_1's rmse: 12997.3\n",
      "[100]\ttraining's rmse: 12504.3\tvalid_1's rmse: 12714.5\n",
      "[110]\ttraining's rmse: 12167.5\tvalid_1's rmse: 12490\n",
      "[120]\ttraining's rmse: 11860.2\tvalid_1's rmse: 12238.7\n",
      "[130]\ttraining's rmse: 11595.6\tvalid_1's rmse: 12072.9\n",
      "[140]\ttraining's rmse: 11373.4\tvalid_1's rmse: 11946.2\n",
      "[150]\ttraining's rmse: 11170.5\tvalid_1's rmse: 11784.4\n",
      "[160]\ttraining's rmse: 10969.1\tvalid_1's rmse: 11640.9\n",
      "[170]\ttraining's rmse: 10783.2\tvalid_1's rmse: 11534.2\n",
      "[180]\ttraining's rmse: 10618.7\tvalid_1's rmse: 11436\n",
      "[190]\ttraining's rmse: 10472\tvalid_1's rmse: 11352.7\n",
      "[200]\ttraining's rmse: 10344.5\tvalid_1's rmse: 11280.2\n",
      "[210]\ttraining's rmse: 10225.5\tvalid_1's rmse: 11200.3\n",
      "[220]\ttraining's rmse: 10099.5\tvalid_1's rmse: 11135.6\n",
      "[230]\ttraining's rmse: 9989.72\tvalid_1's rmse: 11069.9\n",
      "[240]\ttraining's rmse: 9883.79\tvalid_1's rmse: 11013.7\n",
      "[250]\ttraining's rmse: 9780.56\tvalid_1's rmse: 10954.2\n",
      "[260]\ttraining's rmse: 9669.81\tvalid_1's rmse: 10874.4\n",
      "[270]\ttraining's rmse: 9584.02\tvalid_1's rmse: 10833\n",
      "[280]\ttraining's rmse: 9496.02\tvalid_1's rmse: 10781.1\n",
      "[290]\ttraining's rmse: 9413.45\tvalid_1's rmse: 10741.6\n",
      "[300]\ttraining's rmse: 9322.42\tvalid_1's rmse: 10712.7\n",
      "[310]\ttraining's rmse: 9239.77\tvalid_1's rmse: 10660.3\n",
      "[320]\ttraining's rmse: 9160.79\tvalid_1's rmse: 10639.4\n",
      "[330]\ttraining's rmse: 9089.64\tvalid_1's rmse: 10597.7\n",
      "[340]\ttraining's rmse: 9019.14\tvalid_1's rmse: 10562.9\n",
      "[350]\ttraining's rmse: 8944.97\tvalid_1's rmse: 10520.8\n",
      "[360]\ttraining's rmse: 8866.7\tvalid_1's rmse: 10481\n",
      "[370]\ttraining's rmse: 8807.24\tvalid_1's rmse: 10448.3\n",
      "[380]\ttraining's rmse: 8746.38\tvalid_1's rmse: 10410.9\n",
      "[390]\ttraining's rmse: 8689.65\tvalid_1's rmse: 10397.5\n",
      "[400]\ttraining's rmse: 8637.17\tvalid_1's rmse: 10377.9\n",
      "[410]\ttraining's rmse: 8584.74\tvalid_1's rmse: 10365\n",
      "[420]\ttraining's rmse: 8528.5\tvalid_1's rmse: 10354.7\n",
      "[430]\ttraining's rmse: 8475.85\tvalid_1's rmse: 10332.1\n",
      "[440]\ttraining's rmse: 8428.04\tvalid_1's rmse: 10317.5\n",
      "[450]\ttraining's rmse: 8374.97\tvalid_1's rmse: 10310.9\n",
      "[460]\ttraining's rmse: 8327.46\tvalid_1's rmse: 10284.9\n",
      "[470]\ttraining's rmse: 8283.5\tvalid_1's rmse: 10262.4\n",
      "[480]\ttraining's rmse: 8241.91\tvalid_1's rmse: 10253.9\n",
      "[490]\ttraining's rmse: 8195.12\tvalid_1's rmse: 10235.6\n",
      "[500]\ttraining's rmse: 8147.67\tvalid_1's rmse: 10219.1\n",
      "[510]\ttraining's rmse: 8105.68\tvalid_1's rmse: 10218.9\n",
      "[520]\ttraining's rmse: 8069.86\tvalid_1's rmse: 10212.6\n",
      "[530]\ttraining's rmse: 8027.44\tvalid_1's rmse: 10195.2\n",
      "[540]\ttraining's rmse: 7984.54\tvalid_1's rmse: 10182.1\n",
      "[550]\ttraining's rmse: 7947.96\tvalid_1's rmse: 10163\n",
      "[560]\ttraining's rmse: 7913.33\tvalid_1's rmse: 10151.4\n",
      "[570]\ttraining's rmse: 7881.53\tvalid_1's rmse: 10146.1\n",
      "[580]\ttraining's rmse: 7843.14\tvalid_1's rmse: 10128.8\n",
      "[590]\ttraining's rmse: 7807.12\tvalid_1's rmse: 10115.2\n",
      "[600]\ttraining's rmse: 7767.17\tvalid_1's rmse: 10107\n",
      "[610]\ttraining's rmse: 7727.46\tvalid_1's rmse: 10100.2\n",
      "[620]\ttraining's rmse: 7696.3\tvalid_1's rmse: 10093.5\n",
      "[630]\ttraining's rmse: 7667.25\tvalid_1's rmse: 10087.7\n",
      "[640]\ttraining's rmse: 7637.92\tvalid_1's rmse: 10082.7\n",
      "[650]\ttraining's rmse: 7607.98\tvalid_1's rmse: 10074.6\n",
      "[660]\ttraining's rmse: 7576.24\tvalid_1's rmse: 10069\n",
      "[670]\ttraining's rmse: 7543.99\tvalid_1's rmse: 10054.8\n",
      "[680]\ttraining's rmse: 7509.64\tvalid_1's rmse: 10038.2\n",
      "[690]\ttraining's rmse: 7478.31\tvalid_1's rmse: 10039.7\n",
      "[700]\ttraining's rmse: 7448.86\tvalid_1's rmse: 10035.9\n",
      "[710]\ttraining's rmse: 7419.57\tvalid_1's rmse: 10031.6\n",
      "[720]\ttraining's rmse: 7395.9\tvalid_1's rmse: 10030.5\n",
      "[730]\ttraining's rmse: 7368.39\tvalid_1's rmse: 10024.6\n",
      "[740]\ttraining's rmse: 7336.58\tvalid_1's rmse: 10017.8\n",
      "[750]\ttraining's rmse: 7306.41\tvalid_1's rmse: 10014.8\n",
      "[760]\ttraining's rmse: 7279.68\tvalid_1's rmse: 9999.72\n",
      "[770]\ttraining's rmse: 7256\tvalid_1's rmse: 9993.65\n",
      "[780]\ttraining's rmse: 7229.92\tvalid_1's rmse: 9981.16\n",
      "[790]\ttraining's rmse: 7204.43\tvalid_1's rmse: 9977.32\n",
      "[800]\ttraining's rmse: 7180.12\tvalid_1's rmse: 9974.65\n",
      "[810]\ttraining's rmse: 7157.26\tvalid_1's rmse: 9968.86\n",
      "[820]\ttraining's rmse: 7134.82\tvalid_1's rmse: 9961.46\n",
      "[830]\ttraining's rmse: 7110.59\tvalid_1's rmse: 9957.6\n",
      "[840]\ttraining's rmse: 7086.52\tvalid_1's rmse: 9962.6\n",
      "[850]\ttraining's rmse: 7062.33\tvalid_1's rmse: 9957.19\n",
      "[860]\ttraining's rmse: 7036.82\tvalid_1's rmse: 9958.81\n",
      "[870]\ttraining's rmse: 7016.21\tvalid_1's rmse: 9957.33\n",
      "[880]\ttraining's rmse: 6996.48\tvalid_1's rmse: 9955.29\n",
      "[890]\ttraining's rmse: 6978.83\tvalid_1's rmse: 9956.73\n",
      "[900]\ttraining's rmse: 6958.68\tvalid_1's rmse: 9956.36\n",
      "[910]\ttraining's rmse: 6936.25\tvalid_1's rmse: 9963.33\n",
      "[920]\ttraining's rmse: 6917.89\tvalid_1's rmse: 9952.55\n",
      "[930]\ttraining's rmse: 6897.91\tvalid_1's rmse: 9943.92\n",
      "[940]\ttraining's rmse: 6876.8\tvalid_1's rmse: 9945.61\n",
      "[950]\ttraining's rmse: 6856.95\tvalid_1's rmse: 9941.35\n",
      "[960]\ttraining's rmse: 6837.13\tvalid_1's rmse: 9934\n",
      "[970]\ttraining's rmse: 6818.06\tvalid_1's rmse: 9928.36\n",
      "[980]\ttraining's rmse: 6801.99\tvalid_1's rmse: 9927.46\n",
      "[990]\ttraining's rmse: 6783.19\tvalid_1's rmse: 9924.29\n",
      "[1000]\ttraining's rmse: 6766.21\tvalid_1's rmse: 9919.04\n",
      "[1010]\ttraining's rmse: 6745.75\tvalid_1's rmse: 9917.23\n",
      "[1020]\ttraining's rmse: 6727.43\tvalid_1's rmse: 9914.35\n",
      "[1030]\ttraining's rmse: 6706.85\tvalid_1's rmse: 9917.44\n",
      "[1040]\ttraining's rmse: 6688.58\tvalid_1's rmse: 9911.87\n",
      "[1050]\ttraining's rmse: 6671.38\tvalid_1's rmse: 9919.94\n",
      "[1060]\ttraining's rmse: 6656\tvalid_1's rmse: 9923.94\n",
      "[1070]\ttraining's rmse: 6636.48\tvalid_1's rmse: 9919.36\n",
      "[1080]\ttraining's rmse: 6618.6\tvalid_1's rmse: 9915.95\n",
      "[1090]\ttraining's rmse: 6602.3\tvalid_1's rmse: 9916.12\n",
      "[1100]\ttraining's rmse: 6581.24\tvalid_1's rmse: 9921.3\n",
      "Early stopping, best iteration is:\n",
      "[1040]\ttraining's rmse: 6688.58\tvalid_1's rmse: 9911.87\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000893 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1557\n",
      "[LightGBM] [Info] Number of data points in the train set: 35422, number of used features: 23\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 68925.338518\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[10]\ttraining's rmse: 20509.9\tvalid_1's rmse: 19962.2\n",
      "[20]\ttraining's rmse: 12286.6\tvalid_1's rmse: 11818.4\n",
      "[30]\ttraining's rmse: 9400.99\tvalid_1's rmse: 8985.43\n",
      "[40]\ttraining's rmse: 8059.08\tvalid_1's rmse: 7615.82\n",
      "[50]\ttraining's rmse: 7333.43\tvalid_1's rmse: 6985.2\n",
      "[60]\ttraining's rmse: 6836.53\tvalid_1's rmse: 6616.18\n",
      "[70]\ttraining's rmse: 6476.66\tvalid_1's rmse: 6383.16\n",
      "[80]\ttraining's rmse: 6208.19\tvalid_1's rmse: 6229.37\n",
      "[90]\ttraining's rmse: 5984.75\tvalid_1's rmse: 6101.59\n",
      "[100]\ttraining's rmse: 5795.51\tvalid_1's rmse: 5981.11\n",
      "[110]\ttraining's rmse: 5636.98\tvalid_1's rmse: 5922.93\n",
      "[120]\ttraining's rmse: 5485.87\tvalid_1's rmse: 5846.48\n",
      "[130]\ttraining's rmse: 5355.47\tvalid_1's rmse: 5802.88\n",
      "[140]\ttraining's rmse: 5236.91\tvalid_1's rmse: 5735.17\n",
      "[150]\ttraining's rmse: 5137.13\tvalid_1's rmse: 5716.79\n",
      "[160]\ttraining's rmse: 5044.94\tvalid_1's rmse: 5677.19\n",
      "[170]\ttraining's rmse: 4954.81\tvalid_1's rmse: 5654.51\n",
      "[180]\ttraining's rmse: 4868.03\tvalid_1's rmse: 5619.03\n",
      "[190]\ttraining's rmse: 4798.92\tvalid_1's rmse: 5588.42\n",
      "[200]\ttraining's rmse: 4729.06\tvalid_1's rmse: 5563.68\n",
      "[210]\ttraining's rmse: 4672.34\tvalid_1's rmse: 5556.05\n",
      "[220]\ttraining's rmse: 4612.07\tvalid_1's rmse: 5544.94\n",
      "[230]\ttraining's rmse: 4553.58\tvalid_1's rmse: 5529.29\n",
      "[240]\ttraining's rmse: 4498.75\tvalid_1's rmse: 5515.19\n",
      "[250]\ttraining's rmse: 4451.57\tvalid_1's rmse: 5530.91\n",
      "[260]\ttraining's rmse: 4400.26\tvalid_1's rmse: 5516.72\n",
      "[270]\ttraining's rmse: 4346.2\tvalid_1's rmse: 5513.05\n",
      "[280]\ttraining's rmse: 4301.19\tvalid_1's rmse: 5504.89\n",
      "[290]\ttraining's rmse: 4260.99\tvalid_1's rmse: 5490.44\n",
      "[300]\ttraining's rmse: 4216.8\tvalid_1's rmse: 5477.8\n",
      "[310]\ttraining's rmse: 4181.91\tvalid_1's rmse: 5474.3\n",
      "[320]\ttraining's rmse: 4147.16\tvalid_1's rmse: 5468.76\n",
      "[330]\ttraining's rmse: 4114.16\tvalid_1's rmse: 5467.33\n",
      "[340]\ttraining's rmse: 4081.96\tvalid_1's rmse: 5465.1\n",
      "[350]\ttraining's rmse: 4047.66\tvalid_1's rmse: 5448.93\n",
      "[360]\ttraining's rmse: 4015.64\tvalid_1's rmse: 5439.3\n",
      "[370]\ttraining's rmse: 3985.91\tvalid_1's rmse: 5436.31\n",
      "[380]\ttraining's rmse: 3954.03\tvalid_1's rmse: 5431.2\n",
      "[390]\ttraining's rmse: 3926.56\tvalid_1's rmse: 5427.87\n",
      "[400]\ttraining's rmse: 3898.1\tvalid_1's rmse: 5432.12\n",
      "[410]\ttraining's rmse: 3869.41\tvalid_1's rmse: 5438.01\n",
      "[420]\ttraining's rmse: 3845.71\tvalid_1's rmse: 5435.7\n",
      "[430]\ttraining's rmse: 3821.71\tvalid_1's rmse: 5419.97\n",
      "[440]\ttraining's rmse: 3795.77\tvalid_1's rmse: 5429.83\n",
      "[450]\ttraining's rmse: 3772.53\tvalid_1's rmse: 5437.65\n",
      "[460]\ttraining's rmse: 3749.36\tvalid_1's rmse: 5439.43\n",
      "[470]\ttraining's rmse: 3721.97\tvalid_1's rmse: 5431.45\n",
      "[480]\ttraining's rmse: 3702.41\tvalid_1's rmse: 5426.21\n",
      "[490]\ttraining's rmse: 3681.37\tvalid_1's rmse: 5429.07\n",
      "Early stopping, best iteration is:\n",
      "[431]\ttraining's rmse: 3818.49\tvalid_1's rmse: 5419.02\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1649\n",
      "[LightGBM] [Info] Number of data points in the train set: 51007, number of used features: 22\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 45115.477385\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[10]\ttraining's rmse: 9644.73\tvalid_1's rmse: 9811.57\n",
      "[20]\ttraining's rmse: 6227.71\tvalid_1's rmse: 6445.48\n",
      "[30]\ttraining's rmse: 4939.95\tvalid_1's rmse: 5175.32\n",
      "[40]\ttraining's rmse: 4254.62\tvalid_1's rmse: 4485.48\n",
      "[50]\ttraining's rmse: 3822.04\tvalid_1's rmse: 4041.31\n",
      "[60]\ttraining's rmse: 3568.07\tvalid_1's rmse: 3788.71\n",
      "[70]\ttraining's rmse: 3394.1\tvalid_1's rmse: 3620.64\n",
      "[80]\ttraining's rmse: 3262.58\tvalid_1's rmse: 3501.6\n",
      "[90]\ttraining's rmse: 3157.68\tvalid_1's rmse: 3409.67\n",
      "[100]\ttraining's rmse: 3071.93\tvalid_1's rmse: 3331.25\n",
      "[110]\ttraining's rmse: 3003.73\tvalid_1's rmse: 3279.81\n",
      "[120]\ttraining's rmse: 2941.31\tvalid_1's rmse: 3227.95\n",
      "[130]\ttraining's rmse: 2889.18\tvalid_1's rmse: 3188.37\n",
      "[140]\ttraining's rmse: 2839.75\tvalid_1's rmse: 3149.27\n",
      "[150]\ttraining's rmse: 2795.61\tvalid_1's rmse: 3120.65\n",
      "[160]\ttraining's rmse: 2760.92\tvalid_1's rmse: 3099.4\n",
      "[170]\ttraining's rmse: 2725.29\tvalid_1's rmse: 3071.33\n",
      "[180]\ttraining's rmse: 2690.86\tvalid_1's rmse: 3049.88\n",
      "[190]\ttraining's rmse: 2662.98\tvalid_1's rmse: 3030.44\n",
      "[200]\ttraining's rmse: 2632.6\tvalid_1's rmse: 3015.59\n",
      "[210]\ttraining's rmse: 2609.03\tvalid_1's rmse: 3005.33\n",
      "[220]\ttraining's rmse: 2581.85\tvalid_1's rmse: 2988.55\n",
      "[230]\ttraining's rmse: 2558.11\tvalid_1's rmse: 2975.32\n",
      "[240]\ttraining's rmse: 2537.9\tvalid_1's rmse: 2962.53\n",
      "[250]\ttraining's rmse: 2520.16\tvalid_1's rmse: 2951.57\n",
      "[260]\ttraining's rmse: 2500.93\tvalid_1's rmse: 2939.06\n",
      "[270]\ttraining's rmse: 2482.28\tvalid_1's rmse: 2928.57\n",
      "[280]\ttraining's rmse: 2464.93\tvalid_1's rmse: 2919.56\n",
      "[290]\ttraining's rmse: 2449.47\tvalid_1's rmse: 2912.13\n",
      "[300]\ttraining's rmse: 2433.85\tvalid_1's rmse: 2903.03\n",
      "[310]\ttraining's rmse: 2420.1\tvalid_1's rmse: 2896.3\n",
      "[320]\ttraining's rmse: 2406.32\tvalid_1's rmse: 2887.69\n",
      "[330]\ttraining's rmse: 2392.44\tvalid_1's rmse: 2880.76\n",
      "[340]\ttraining's rmse: 2379.13\tvalid_1's rmse: 2875.47\n",
      "[350]\ttraining's rmse: 2366.66\tvalid_1's rmse: 2871.58\n",
      "[360]\ttraining's rmse: 2353.05\tvalid_1's rmse: 2869.55\n",
      "[370]\ttraining's rmse: 2340.49\tvalid_1's rmse: 2863.73\n",
      "[380]\ttraining's rmse: 2329.1\tvalid_1's rmse: 2861.5\n",
      "[390]\ttraining's rmse: 2317.22\tvalid_1's rmse: 2860.83\n",
      "[400]\ttraining's rmse: 2306.62\tvalid_1's rmse: 2856.44\n",
      "[410]\ttraining's rmse: 2296.49\tvalid_1's rmse: 2852.61\n",
      "[420]\ttraining's rmse: 2287.3\tvalid_1's rmse: 2850.87\n",
      "[430]\ttraining's rmse: 2277.45\tvalid_1's rmse: 2846.39\n",
      "[440]\ttraining's rmse: 2267.5\tvalid_1's rmse: 2843.16\n",
      "[450]\ttraining's rmse: 2259.56\tvalid_1's rmse: 2840.89\n",
      "[460]\ttraining's rmse: 2249.53\tvalid_1's rmse: 2836.66\n",
      "[470]\ttraining's rmse: 2240.82\tvalid_1's rmse: 2835.74\n",
      "[480]\ttraining's rmse: 2231.59\tvalid_1's rmse: 2833.23\n",
      "[490]\ttraining's rmse: 2222.25\tvalid_1's rmse: 2829.21\n",
      "[500]\ttraining's rmse: 2214.8\tvalid_1's rmse: 2825.15\n",
      "[510]\ttraining's rmse: 2206.61\tvalid_1's rmse: 2820.7\n",
      "[520]\ttraining's rmse: 2198.63\tvalid_1's rmse: 2817.3\n",
      "[530]\ttraining's rmse: 2190.18\tvalid_1's rmse: 2816.72\n",
      "[540]\ttraining's rmse: 2182.75\tvalid_1's rmse: 2817.34\n",
      "[550]\ttraining's rmse: 2175.11\tvalid_1's rmse: 2817.44\n",
      "[560]\ttraining's rmse: 2168.12\tvalid_1's rmse: 2819\n",
      "[570]\ttraining's rmse: 2161.78\tvalid_1's rmse: 2818.88\n",
      "[580]\ttraining's rmse: 2154.21\tvalid_1's rmse: 2818.53\n",
      "[590]\ttraining's rmse: 2147.66\tvalid_1's rmse: 2817.98\n",
      "Early stopping, best iteration is:\n",
      "[537]\ttraining's rmse: 2185.46\tvalid_1's rmse: 2815.72\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001018 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1739\n",
      "[LightGBM] [Info] Number of data points in the train set: 66406, number of used features: 22\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 83820.406349\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[10]\ttraining's rmse: 22944.4\tvalid_1's rmse: 23131.8\n",
      "[20]\ttraining's rmse: 14576.5\tvalid_1's rmse: 14821.4\n",
      "[30]\ttraining's rmse: 11398.1\tvalid_1's rmse: 11747.2\n",
      "[40]\ttraining's rmse: 9915.23\tvalid_1's rmse: 10279.5\n",
      "[50]\ttraining's rmse: 9051.78\tvalid_1's rmse: 9407.68\n",
      "[60]\ttraining's rmse: 8428.46\tvalid_1's rmse: 8807.53\n",
      "[70]\ttraining's rmse: 8028.73\tvalid_1's rmse: 8392.65\n",
      "[80]\ttraining's rmse: 7667.36\tvalid_1's rmse: 8057.15\n",
      "[90]\ttraining's rmse: 7412.22\tvalid_1's rmse: 7832.63\n",
      "[100]\ttraining's rmse: 7163.47\tvalid_1's rmse: 7608.01\n",
      "[110]\ttraining's rmse: 6964.46\tvalid_1's rmse: 7437.02\n",
      "[120]\ttraining's rmse: 6798.54\tvalid_1's rmse: 7278.07\n",
      "[130]\ttraining's rmse: 6658.45\tvalid_1's rmse: 7137.16\n",
      "[140]\ttraining's rmse: 6537.75\tvalid_1's rmse: 7046.26\n",
      "[150]\ttraining's rmse: 6448.9\tvalid_1's rmse: 6978.68\n",
      "[160]\ttraining's rmse: 6345.4\tvalid_1's rmse: 6881.76\n",
      "[170]\ttraining's rmse: 6249.69\tvalid_1's rmse: 6817.04\n",
      "[180]\ttraining's rmse: 6168.77\tvalid_1's rmse: 6758.59\n",
      "[190]\ttraining's rmse: 6100.36\tvalid_1's rmse: 6705.91\n",
      "[200]\ttraining's rmse: 6028.16\tvalid_1's rmse: 6654.49\n",
      "[210]\ttraining's rmse: 5964.42\tvalid_1's rmse: 6605.83\n",
      "[220]\ttraining's rmse: 5900.41\tvalid_1's rmse: 6567.45\n",
      "[230]\ttraining's rmse: 5846.88\tvalid_1's rmse: 6527.42\n",
      "[240]\ttraining's rmse: 5795.04\tvalid_1's rmse: 6496.25\n",
      "[250]\ttraining's rmse: 5743.97\tvalid_1's rmse: 6462.66\n",
      "[260]\ttraining's rmse: 5697.4\tvalid_1's rmse: 6434.11\n",
      "[270]\ttraining's rmse: 5654.45\tvalid_1's rmse: 6404.67\n",
      "[280]\ttraining's rmse: 5618.22\tvalid_1's rmse: 6384.11\n",
      "[290]\ttraining's rmse: 5580.31\tvalid_1's rmse: 6367.91\n",
      "[300]\ttraining's rmse: 5546.44\tvalid_1's rmse: 6347.62\n",
      "[310]\ttraining's rmse: 5504.78\tvalid_1's rmse: 6328.64\n",
      "[320]\ttraining's rmse: 5467.2\tvalid_1's rmse: 6300.49\n",
      "[330]\ttraining's rmse: 5434.99\tvalid_1's rmse: 6285.6\n",
      "[340]\ttraining's rmse: 5403\tvalid_1's rmse: 6276.25\n",
      "[350]\ttraining's rmse: 5375.86\tvalid_1's rmse: 6266.3\n",
      "[360]\ttraining's rmse: 5349.47\tvalid_1's rmse: 6254.9\n",
      "[370]\ttraining's rmse: 5321.78\tvalid_1's rmse: 6243.47\n",
      "[380]\ttraining's rmse: 5294.95\tvalid_1's rmse: 6229.66\n",
      "[390]\ttraining's rmse: 5269.4\tvalid_1's rmse: 6216.29\n",
      "[400]\ttraining's rmse: 5243\tvalid_1's rmse: 6197.98\n",
      "[410]\ttraining's rmse: 5218.63\tvalid_1's rmse: 6186.69\n",
      "[420]\ttraining's rmse: 5196.23\tvalid_1's rmse: 6173.51\n",
      "[430]\ttraining's rmse: 5173.25\tvalid_1's rmse: 6163.02\n",
      "[440]\ttraining's rmse: 5150.78\tvalid_1's rmse: 6151.56\n",
      "[450]\ttraining's rmse: 5131.2\tvalid_1's rmse: 6143.48\n",
      "[460]\ttraining's rmse: 5106.12\tvalid_1's rmse: 6136.86\n",
      "[470]\ttraining's rmse: 5087.44\tvalid_1's rmse: 6129.44\n",
      "[480]\ttraining's rmse: 5069.57\tvalid_1's rmse: 6123.69\n",
      "[490]\ttraining's rmse: 5047.55\tvalid_1's rmse: 6113.3\n",
      "[500]\ttraining's rmse: 5028.43\tvalid_1's rmse: 6105.42\n",
      "[510]\ttraining's rmse: 5006.78\tvalid_1's rmse: 6094.61\n",
      "[520]\ttraining's rmse: 4987.68\tvalid_1's rmse: 6086.53\n",
      "[530]\ttraining's rmse: 4967.77\tvalid_1's rmse: 6082.47\n",
      "[540]\ttraining's rmse: 4946.84\tvalid_1's rmse: 6079.27\n",
      "[550]\ttraining's rmse: 4930.56\tvalid_1's rmse: 6071.95\n",
      "[560]\ttraining's rmse: 4912.13\tvalid_1's rmse: 6062.06\n",
      "[570]\ttraining's rmse: 4895.9\tvalid_1's rmse: 6059.92\n",
      "[580]\ttraining's rmse: 4880.75\tvalid_1's rmse: 6054.11\n",
      "[590]\ttraining's rmse: 4865.66\tvalid_1's rmse: 6044.02\n",
      "[600]\ttraining's rmse: 4848.32\tvalid_1's rmse: 6039.71\n",
      "[610]\ttraining's rmse: 4832.85\tvalid_1's rmse: 6032.98\n",
      "[620]\ttraining's rmse: 4820.17\tvalid_1's rmse: 6032.56\n",
      "[630]\ttraining's rmse: 4804.16\tvalid_1's rmse: 6031.7\n",
      "[640]\ttraining's rmse: 4789.82\tvalid_1's rmse: 6024.41\n",
      "[650]\ttraining's rmse: 4775.24\tvalid_1's rmse: 6022.89\n",
      "[660]\ttraining's rmse: 4761.72\tvalid_1's rmse: 6020.21\n",
      "[670]\ttraining's rmse: 4746.74\tvalid_1's rmse: 6017.35\n",
      "[680]\ttraining's rmse: 4733.8\tvalid_1's rmse: 6014.57\n",
      "[690]\ttraining's rmse: 4721.77\tvalid_1's rmse: 6008\n",
      "[700]\ttraining's rmse: 4709.71\tvalid_1's rmse: 6006.2\n",
      "[710]\ttraining's rmse: 4698.66\tvalid_1's rmse: 6006.07\n",
      "[720]\ttraining's rmse: 4685.09\tvalid_1's rmse: 6006.43\n",
      "[730]\ttraining's rmse: 4672.8\tvalid_1's rmse: 6008.59\n",
      "[740]\ttraining's rmse: 4660.8\tvalid_1's rmse: 6005.53\n",
      "[750]\ttraining's rmse: 4649.22\tvalid_1's rmse: 6001.05\n",
      "[760]\ttraining's rmse: 4635.84\tvalid_1's rmse: 5994.38\n",
      "[770]\ttraining's rmse: 4625.33\tvalid_1's rmse: 5993.16\n",
      "[780]\ttraining's rmse: 4615.09\tvalid_1's rmse: 5988.51\n",
      "[790]\ttraining's rmse: 4603.94\tvalid_1's rmse: 5988.67\n",
      "[800]\ttraining's rmse: 4594.66\tvalid_1's rmse: 5985.58\n",
      "[810]\ttraining's rmse: 4584.54\tvalid_1's rmse: 5985.4\n",
      "[820]\ttraining's rmse: 4572.62\tvalid_1's rmse: 5982.71\n",
      "[830]\ttraining's rmse: 4563.44\tvalid_1's rmse: 5981.45\n",
      "[840]\ttraining's rmse: 4553.59\tvalid_1's rmse: 5974.89\n",
      "[850]\ttraining's rmse: 4544.29\tvalid_1's rmse: 5975.3\n",
      "[860]\ttraining's rmse: 4534.38\tvalid_1's rmse: 5979.69\n",
      "[870]\ttraining's rmse: 4525.18\tvalid_1's rmse: 5979.91\n",
      "[880]\ttraining's rmse: 4514.31\tvalid_1's rmse: 5977.6\n",
      "[890]\ttraining's rmse: 4505.55\tvalid_1's rmse: 5977.38\n",
      "[900]\ttraining's rmse: 4495.74\tvalid_1's rmse: 5977.53\n",
      "Early stopping, best iteration is:\n",
      "[848]\ttraining's rmse: 4545.85\tvalid_1's rmse: 5974.01\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000769 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1820\n",
      "[LightGBM] [Info] Number of data points in the train set: 48579, number of used features: 22\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 58929.193458\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[10]\ttraining's rmse: 18102.8\tvalid_1's rmse: 18870.1\n",
      "[20]\ttraining's rmse: 11292.9\tvalid_1's rmse: 11722.2\n",
      "[30]\ttraining's rmse: 8656.02\tvalid_1's rmse: 8979.61\n",
      "[40]\ttraining's rmse: 7424.36\tvalid_1's rmse: 7767.07\n",
      "[50]\ttraining's rmse: 6724.59\tvalid_1's rmse: 7090.35\n",
      "[60]\ttraining's rmse: 6217.89\tvalid_1's rmse: 6560.43\n",
      "[70]\ttraining's rmse: 5860.56\tvalid_1's rmse: 6226.02\n",
      "[80]\ttraining's rmse: 5575.59\tvalid_1's rmse: 5962.73\n",
      "[90]\ttraining's rmse: 5374.9\tvalid_1's rmse: 5778.42\n",
      "[100]\ttraining's rmse: 5193.67\tvalid_1's rmse: 5607.85\n",
      "[110]\ttraining's rmse: 5037.54\tvalid_1's rmse: 5463.91\n",
      "[120]\ttraining's rmse: 4915.93\tvalid_1's rmse: 5363.66\n",
      "[130]\ttraining's rmse: 4810.89\tvalid_1's rmse: 5277.98\n",
      "[140]\ttraining's rmse: 4710.65\tvalid_1's rmse: 5197.83\n",
      "[150]\ttraining's rmse: 4623.16\tvalid_1's rmse: 5126.23\n",
      "[160]\ttraining's rmse: 4537.77\tvalid_1's rmse: 5060.58\n",
      "[170]\ttraining's rmse: 4469.86\tvalid_1's rmse: 5006.21\n",
      "[180]\ttraining's rmse: 4401.72\tvalid_1's rmse: 4945.97\n",
      "[190]\ttraining's rmse: 4344.24\tvalid_1's rmse: 4903.59\n",
      "[200]\ttraining's rmse: 4297.16\tvalid_1's rmse: 4876.92\n",
      "[210]\ttraining's rmse: 4239.1\tvalid_1's rmse: 4826.2\n",
      "[220]\ttraining's rmse: 4180.61\tvalid_1's rmse: 4775.77\n",
      "[230]\ttraining's rmse: 4133.55\tvalid_1's rmse: 4741.02\n",
      "[240]\ttraining's rmse: 4090.27\tvalid_1's rmse: 4712.93\n",
      "[250]\ttraining's rmse: 4048.37\tvalid_1's rmse: 4686.64\n",
      "[260]\ttraining's rmse: 4011.82\tvalid_1's rmse: 4664.92\n",
      "[270]\ttraining's rmse: 3975.15\tvalid_1's rmse: 4643.6\n",
      "[280]\ttraining's rmse: 3942.4\tvalid_1's rmse: 4630.39\n",
      "[290]\ttraining's rmse: 3907.28\tvalid_1's rmse: 4607.25\n",
      "[300]\ttraining's rmse: 3872.14\tvalid_1's rmse: 4585.22\n",
      "[310]\ttraining's rmse: 3836.96\tvalid_1's rmse: 4567.55\n",
      "[320]\ttraining's rmse: 3804.77\tvalid_1's rmse: 4551.03\n",
      "[330]\ttraining's rmse: 3774.84\tvalid_1's rmse: 4533.82\n",
      "[340]\ttraining's rmse: 3745.6\tvalid_1's rmse: 4520.98\n",
      "[350]\ttraining's rmse: 3720.82\tvalid_1's rmse: 4509.06\n",
      "[360]\ttraining's rmse: 3695.44\tvalid_1's rmse: 4496.06\n",
      "[370]\ttraining's rmse: 3670.57\tvalid_1's rmse: 4486.45\n",
      "[380]\ttraining's rmse: 3647.55\tvalid_1's rmse: 4473.07\n",
      "[390]\ttraining's rmse: 3623.04\tvalid_1's rmse: 4465.88\n",
      "[400]\ttraining's rmse: 3604.43\tvalid_1's rmse: 4453.87\n",
      "[410]\ttraining's rmse: 3582.94\tvalid_1's rmse: 4448.36\n",
      "[420]\ttraining's rmse: 3564.2\tvalid_1's rmse: 4443.44\n",
      "[430]\ttraining's rmse: 3544.39\tvalid_1's rmse: 4436.38\n",
      "[440]\ttraining's rmse: 3525.93\tvalid_1's rmse: 4432.38\n",
      "[450]\ttraining's rmse: 3507.62\tvalid_1's rmse: 4424.86\n",
      "[460]\ttraining's rmse: 3489.87\tvalid_1's rmse: 4416.43\n",
      "[470]\ttraining's rmse: 3473.43\tvalid_1's rmse: 4412.84\n",
      "[480]\ttraining's rmse: 3456\tvalid_1's rmse: 4402.79\n",
      "[490]\ttraining's rmse: 3439.78\tvalid_1's rmse: 4396.53\n",
      "[500]\ttraining's rmse: 3425.17\tvalid_1's rmse: 4395.16\n",
      "[510]\ttraining's rmse: 3406.87\tvalid_1's rmse: 4388.12\n",
      "[520]\ttraining's rmse: 3391.76\tvalid_1's rmse: 4388.33\n",
      "[530]\ttraining's rmse: 3374\tvalid_1's rmse: 4382.88\n",
      "[540]\ttraining's rmse: 3357.52\tvalid_1's rmse: 4374.97\n",
      "[550]\ttraining's rmse: 3342.3\tvalid_1's rmse: 4367.25\n",
      "[560]\ttraining's rmse: 3327.75\tvalid_1's rmse: 4366.72\n",
      "[570]\ttraining's rmse: 3315.27\tvalid_1's rmse: 4361.6\n",
      "[580]\ttraining's rmse: 3302.65\tvalid_1's rmse: 4359.88\n",
      "[590]\ttraining's rmse: 3290.17\tvalid_1's rmse: 4355.41\n",
      "[600]\ttraining's rmse: 3275.95\tvalid_1's rmse: 4348.77\n",
      "[610]\ttraining's rmse: 3264.58\tvalid_1's rmse: 4343.8\n",
      "[620]\ttraining's rmse: 3250.71\tvalid_1's rmse: 4340.59\n",
      "[630]\ttraining's rmse: 3238.12\tvalid_1's rmse: 4334.34\n",
      "[640]\ttraining's rmse: 3226.02\tvalid_1's rmse: 4325.43\n",
      "[650]\ttraining's rmse: 3213.14\tvalid_1's rmse: 4323.5\n",
      "[660]\ttraining's rmse: 3201.34\tvalid_1's rmse: 4323.5\n",
      "[670]\ttraining's rmse: 3189.87\tvalid_1's rmse: 4319.27\n",
      "[680]\ttraining's rmse: 3179.5\tvalid_1's rmse: 4315.24\n",
      "[690]\ttraining's rmse: 3168.8\tvalid_1's rmse: 4313.99\n",
      "[700]\ttraining's rmse: 3158.19\tvalid_1's rmse: 4309.68\n",
      "[710]\ttraining's rmse: 3149.04\tvalid_1's rmse: 4306.22\n",
      "[720]\ttraining's rmse: 3138.74\tvalid_1's rmse: 4305.83\n",
      "[730]\ttraining's rmse: 3127.1\tvalid_1's rmse: 4300.27\n",
      "[740]\ttraining's rmse: 3117.24\tvalid_1's rmse: 4295.51\n",
      "[750]\ttraining's rmse: 3107.95\tvalid_1's rmse: 4293.54\n",
      "[760]\ttraining's rmse: 3099.59\tvalid_1's rmse: 4291.01\n",
      "[770]\ttraining's rmse: 3090.9\tvalid_1's rmse: 4288.25\n",
      "[780]\ttraining's rmse: 3081.92\tvalid_1's rmse: 4285.14\n",
      "[790]\ttraining's rmse: 3072.5\tvalid_1's rmse: 4284.63\n",
      "[800]\ttraining's rmse: 3063.77\tvalid_1's rmse: 4281.88\n",
      "[810]\ttraining's rmse: 3054.46\tvalid_1's rmse: 4280.61\n",
      "[820]\ttraining's rmse: 3043.2\tvalid_1's rmse: 4277.2\n",
      "[830]\ttraining's rmse: 3034.16\tvalid_1's rmse: 4276.08\n",
      "[840]\ttraining's rmse: 3025.75\tvalid_1's rmse: 4276.11\n",
      "[850]\ttraining's rmse: 3017.84\tvalid_1's rmse: 4276.53\n",
      "[860]\ttraining's rmse: 3009.6\tvalid_1's rmse: 4276.58\n",
      "[870]\ttraining's rmse: 3001.31\tvalid_1's rmse: 4271.73\n",
      "[880]\ttraining's rmse: 2992.36\tvalid_1's rmse: 4269.37\n",
      "[890]\ttraining's rmse: 2982.05\tvalid_1's rmse: 4264.18\n",
      "[900]\ttraining's rmse: 2974.31\tvalid_1's rmse: 4264.7\n",
      "[910]\ttraining's rmse: 2967.13\tvalid_1's rmse: 4261.6\n",
      "[920]\ttraining's rmse: 2959.58\tvalid_1's rmse: 4257.88\n",
      "[930]\ttraining's rmse: 2951.4\tvalid_1's rmse: 4253.94\n",
      "[940]\ttraining's rmse: 2944\tvalid_1's rmse: 4251.17\n",
      "[950]\ttraining's rmse: 2936.52\tvalid_1's rmse: 4248.06\n",
      "[960]\ttraining's rmse: 2929.31\tvalid_1's rmse: 4244.14\n",
      "[970]\ttraining's rmse: 2923.25\tvalid_1's rmse: 4241.64\n",
      "[980]\ttraining's rmse: 2915.56\tvalid_1's rmse: 4240.01\n",
      "[990]\ttraining's rmse: 2907.75\tvalid_1's rmse: 4238.91\n",
      "[1000]\ttraining's rmse: 2900.86\tvalid_1's rmse: 4236.92\n",
      "[1010]\ttraining's rmse: 2894.41\tvalid_1's rmse: 4234.11\n",
      "[1020]\ttraining's rmse: 2886.39\tvalid_1's rmse: 4231.92\n",
      "[1030]\ttraining's rmse: 2878.92\tvalid_1's rmse: 4232.78\n",
      "[1040]\ttraining's rmse: 2871.99\tvalid_1's rmse: 4230.72\n",
      "[1050]\ttraining's rmse: 2865.54\tvalid_1's rmse: 4229.6\n",
      "[1060]\ttraining's rmse: 2858.04\tvalid_1's rmse: 4228.59\n",
      "[1070]\ttraining's rmse: 2851.26\tvalid_1's rmse: 4228.76\n",
      "[1080]\ttraining's rmse: 2845.24\tvalid_1's rmse: 4229.26\n",
      "[1090]\ttraining's rmse: 2839.29\tvalid_1's rmse: 4229\n",
      "[1100]\ttraining's rmse: 2832.79\tvalid_1's rmse: 4225.71\n",
      "[1110]\ttraining's rmse: 2826.56\tvalid_1's rmse: 4227.4\n",
      "[1120]\ttraining's rmse: 2820.49\tvalid_1's rmse: 4226.07\n",
      "[1130]\ttraining's rmse: 2813.79\tvalid_1's rmse: 4224.56\n",
      "[1140]\ttraining's rmse: 2806.89\tvalid_1's rmse: 4222.55\n",
      "[1150]\ttraining's rmse: 2800.64\tvalid_1's rmse: 4221.4\n",
      "[1160]\ttraining's rmse: 2795.65\tvalid_1's rmse: 4219.89\n",
      "[1170]\ttraining's rmse: 2789.59\tvalid_1's rmse: 4217.78\n",
      "[1180]\ttraining's rmse: 2783.81\tvalid_1's rmse: 4218.16\n",
      "[1190]\ttraining's rmse: 2777.01\tvalid_1's rmse: 4217.94\n",
      "[1200]\ttraining's rmse: 2771.7\tvalid_1's rmse: 4215.43\n",
      "[1210]\ttraining's rmse: 2766.34\tvalid_1's rmse: 4214.89\n",
      "[1220]\ttraining's rmse: 2759.86\tvalid_1's rmse: 4216.37\n",
      "[1230]\ttraining's rmse: 2754.59\tvalid_1's rmse: 4214.27\n",
      "[1240]\ttraining's rmse: 2748.34\tvalid_1's rmse: 4212.85\n",
      "[1250]\ttraining's rmse: 2743.5\tvalid_1's rmse: 4215.09\n",
      "[1260]\ttraining's rmse: 2738.46\tvalid_1's rmse: 4212.93\n",
      "[1270]\ttraining's rmse: 2733.37\tvalid_1's rmse: 4209.33\n",
      "[1280]\ttraining's rmse: 2727.72\tvalid_1's rmse: 4209.53\n",
      "[1290]\ttraining's rmse: 2722.36\tvalid_1's rmse: 4206.99\n",
      "[1300]\ttraining's rmse: 2717.03\tvalid_1's rmse: 4209.49\n",
      "[1310]\ttraining's rmse: 2711.8\tvalid_1's rmse: 4207.63\n",
      "[1320]\ttraining's rmse: 2707.45\tvalid_1's rmse: 4204.44\n",
      "[1330]\ttraining's rmse: 2702.65\tvalid_1's rmse: 4202.78\n",
      "[1340]\ttraining's rmse: 2697.82\tvalid_1's rmse: 4201.33\n",
      "[1350]\ttraining's rmse: 2692.66\tvalid_1's rmse: 4203.75\n",
      "[1360]\ttraining's rmse: 2687.33\tvalid_1's rmse: 4204.4\n",
      "[1370]\ttraining's rmse: 2681.59\tvalid_1's rmse: 4204.32\n",
      "[1380]\ttraining's rmse: 2675.97\tvalid_1's rmse: 4205.21\n",
      "[1390]\ttraining's rmse: 2671.57\tvalid_1's rmse: 4203.57\n",
      "[1400]\ttraining's rmse: 2666.44\tvalid_1's rmse: 4202.05\n",
      "Early stopping, best iteration is:\n",
      "[1340]\ttraining's rmse: 2697.82\tvalid_1's rmse: 4201.33\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000407 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1735\n",
      "[LightGBM] [Info] Number of data points in the train set: 42876, number of used features: 23\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 56112.991837\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[10]\ttraining's rmse: 17352.4\tvalid_1's rmse: 17432.1\n",
      "[20]\ttraining's rmse: 10622.9\tvalid_1's rmse: 10911.2\n",
      "[30]\ttraining's rmse: 8120.52\tvalid_1's rmse: 8597.2\n",
      "[40]\ttraining's rmse: 6956.22\tvalid_1's rmse: 7574.1\n",
      "[50]\ttraining's rmse: 6262.02\tvalid_1's rmse: 6908.66\n",
      "[60]\ttraining's rmse: 5782.67\tvalid_1's rmse: 6474.54\n",
      "[70]\ttraining's rmse: 5443.09\tvalid_1's rmse: 6164.81\n",
      "[80]\ttraining's rmse: 5176.12\tvalid_1's rmse: 5935.78\n",
      "[90]\ttraining's rmse: 4995.56\tvalid_1's rmse: 5754.48\n",
      "[100]\ttraining's rmse: 4823.14\tvalid_1's rmse: 5594.18\n",
      "[110]\ttraining's rmse: 4686.92\tvalid_1's rmse: 5473.8\n",
      "[120]\ttraining's rmse: 4552.29\tvalid_1's rmse: 5375.61\n",
      "[130]\ttraining's rmse: 4452.61\tvalid_1's rmse: 5285.24\n",
      "[140]\ttraining's rmse: 4357.37\tvalid_1's rmse: 5229.38\n",
      "[150]\ttraining's rmse: 4266.13\tvalid_1's rmse: 5153.06\n",
      "[160]\ttraining's rmse: 4195.25\tvalid_1's rmse: 5106.55\n",
      "[170]\ttraining's rmse: 4129.33\tvalid_1's rmse: 5071.15\n",
      "[180]\ttraining's rmse: 4054.97\tvalid_1's rmse: 5014.55\n",
      "[190]\ttraining's rmse: 3993.21\tvalid_1's rmse: 4976.88\n",
      "[200]\ttraining's rmse: 3929.65\tvalid_1's rmse: 4939.58\n",
      "[210]\ttraining's rmse: 3878.45\tvalid_1's rmse: 4899.79\n",
      "[220]\ttraining's rmse: 3829.68\tvalid_1's rmse: 4881.5\n",
      "[230]\ttraining's rmse: 3786.62\tvalid_1's rmse: 4862.94\n",
      "[240]\ttraining's rmse: 3741.01\tvalid_1's rmse: 4836.3\n",
      "[250]\ttraining's rmse: 3699.77\tvalid_1's rmse: 4814.77\n",
      "[260]\ttraining's rmse: 3659.77\tvalid_1's rmse: 4785.27\n",
      "[270]\ttraining's rmse: 3623.83\tvalid_1's rmse: 4776.43\n",
      "[280]\ttraining's rmse: 3585.36\tvalid_1's rmse: 4754.69\n",
      "[290]\ttraining's rmse: 3548.21\tvalid_1's rmse: 4747.87\n",
      "[300]\ttraining's rmse: 3515.03\tvalid_1's rmse: 4726.29\n",
      "[310]\ttraining's rmse: 3486.22\tvalid_1's rmse: 4706.56\n",
      "[320]\ttraining's rmse: 3456.62\tvalid_1's rmse: 4696.06\n",
      "[330]\ttraining's rmse: 3428.9\tvalid_1's rmse: 4681.75\n",
      "[340]\ttraining's rmse: 3405.17\tvalid_1's rmse: 4673.23\n",
      "[350]\ttraining's rmse: 3380\tvalid_1's rmse: 4662.06\n",
      "[360]\ttraining's rmse: 3356.8\tvalid_1's rmse: 4653.4\n",
      "[370]\ttraining's rmse: 3332.02\tvalid_1's rmse: 4638.43\n",
      "[380]\ttraining's rmse: 3309.73\tvalid_1's rmse: 4638.8\n",
      "[390]\ttraining's rmse: 3283.75\tvalid_1's rmse: 4628.41\n",
      "[400]\ttraining's rmse: 3260.39\tvalid_1's rmse: 4616.37\n",
      "[410]\ttraining's rmse: 3237.85\tvalid_1's rmse: 4604.66\n",
      "[420]\ttraining's rmse: 3222.87\tvalid_1's rmse: 4596.08\n",
      "[430]\ttraining's rmse: 3201.76\tvalid_1's rmse: 4578.43\n",
      "[440]\ttraining's rmse: 3179.34\tvalid_1's rmse: 4577.57\n",
      "[450]\ttraining's rmse: 3158.85\tvalid_1's rmse: 4576.93\n",
      "[460]\ttraining's rmse: 3137.89\tvalid_1's rmse: 4568.46\n",
      "[470]\ttraining's rmse: 3118.68\tvalid_1's rmse: 4558.37\n",
      "[480]\ttraining's rmse: 3100.19\tvalid_1's rmse: 4555.93\n",
      "[490]\ttraining's rmse: 3080.64\tvalid_1's rmse: 4543.1\n",
      "[500]\ttraining's rmse: 3062.87\tvalid_1's rmse: 4531.38\n",
      "[510]\ttraining's rmse: 3049.06\tvalid_1's rmse: 4524.59\n",
      "[520]\ttraining's rmse: 3035.22\tvalid_1's rmse: 4518.92\n",
      "[530]\ttraining's rmse: 3016.22\tvalid_1's rmse: 4514.99\n",
      "[540]\ttraining's rmse: 3002.13\tvalid_1's rmse: 4513.61\n",
      "[550]\ttraining's rmse: 2987.68\tvalid_1's rmse: 4509.42\n",
      "[560]\ttraining's rmse: 2973.47\tvalid_1's rmse: 4504.37\n",
      "[570]\ttraining's rmse: 2959.74\tvalid_1's rmse: 4497.8\n",
      "[580]\ttraining's rmse: 2946.08\tvalid_1's rmse: 4491.88\n",
      "[590]\ttraining's rmse: 2932.53\tvalid_1's rmse: 4486.48\n",
      "[600]\ttraining's rmse: 2918.68\tvalid_1's rmse: 4480.81\n",
      "[610]\ttraining's rmse: 2906.14\tvalid_1's rmse: 4477.67\n",
      "[620]\ttraining's rmse: 2893.42\tvalid_1's rmse: 4478.61\n",
      "[630]\ttraining's rmse: 2880.53\tvalid_1's rmse: 4474.22\n",
      "[640]\ttraining's rmse: 2869.12\tvalid_1's rmse: 4471.5\n",
      "[650]\ttraining's rmse: 2858.07\tvalid_1's rmse: 4465.69\n",
      "[660]\ttraining's rmse: 2844.69\tvalid_1's rmse: 4462.17\n",
      "[670]\ttraining's rmse: 2833.94\tvalid_1's rmse: 4454.77\n",
      "[680]\ttraining's rmse: 2823.78\tvalid_1's rmse: 4452.24\n",
      "[690]\ttraining's rmse: 2812.5\tvalid_1's rmse: 4447.42\n",
      "[700]\ttraining's rmse: 2801.9\tvalid_1's rmse: 4444.17\n",
      "[710]\ttraining's rmse: 2791.33\tvalid_1's rmse: 4439.92\n",
      "[720]\ttraining's rmse: 2780.74\tvalid_1's rmse: 4438.07\n",
      "[730]\ttraining's rmse: 2769.16\tvalid_1's rmse: 4436.47\n",
      "[740]\ttraining's rmse: 2760.41\tvalid_1's rmse: 4433.95\n",
      "[750]\ttraining's rmse: 2750.92\tvalid_1's rmse: 4432.71\n",
      "[760]\ttraining's rmse: 2741.8\tvalid_1's rmse: 4427.69\n",
      "[770]\ttraining's rmse: 2732.19\tvalid_1's rmse: 4428.22\n",
      "[780]\ttraining's rmse: 2723.45\tvalid_1's rmse: 4424.41\n",
      "[790]\ttraining's rmse: 2714.6\tvalid_1's rmse: 4419.6\n",
      "[800]\ttraining's rmse: 2703.41\tvalid_1's rmse: 4417.69\n",
      "[810]\ttraining's rmse: 2693.48\tvalid_1's rmse: 4413.28\n",
      "[820]\ttraining's rmse: 2684.5\tvalid_1's rmse: 4411.31\n",
      "[830]\ttraining's rmse: 2677.34\tvalid_1's rmse: 4406.6\n",
      "[840]\ttraining's rmse: 2669.06\tvalid_1's rmse: 4407.71\n",
      "[850]\ttraining's rmse: 2658.39\tvalid_1's rmse: 4404.64\n",
      "[860]\ttraining's rmse: 2649.71\tvalid_1's rmse: 4403.69\n",
      "[870]\ttraining's rmse: 2639.68\tvalid_1's rmse: 4400.08\n",
      "[880]\ttraining's rmse: 2631.85\tvalid_1's rmse: 4391.41\n",
      "[890]\ttraining's rmse: 2624.11\tvalid_1's rmse: 4390.76\n",
      "[900]\ttraining's rmse: 2615.95\tvalid_1's rmse: 4389.98\n",
      "[910]\ttraining's rmse: 2608.36\tvalid_1's rmse: 4384.63\n",
      "[920]\ttraining's rmse: 2600.51\tvalid_1's rmse: 4384.47\n",
      "[930]\ttraining's rmse: 2593.77\tvalid_1's rmse: 4384.13\n",
      "[940]\ttraining's rmse: 2585.91\tvalid_1's rmse: 4382.09\n",
      "[950]\ttraining's rmse: 2577.31\tvalid_1's rmse: 4384.71\n",
      "[960]\ttraining's rmse: 2570.02\tvalid_1's rmse: 4379.1\n",
      "[970]\ttraining's rmse: 2561.13\tvalid_1's rmse: 4375.3\n",
      "[980]\ttraining's rmse: 2552.81\tvalid_1's rmse: 4376.79\n",
      "[990]\ttraining's rmse: 2546.46\tvalid_1's rmse: 4374.3\n",
      "[1000]\ttraining's rmse: 2540.11\tvalid_1's rmse: 4371.57\n",
      "[1010]\ttraining's rmse: 2532.95\tvalid_1's rmse: 4372.83\n",
      "[1020]\ttraining's rmse: 2526.18\tvalid_1's rmse: 4371.32\n",
      "[1030]\ttraining's rmse: 2519.18\tvalid_1's rmse: 4374.56\n",
      "[1040]\ttraining's rmse: 2512.14\tvalid_1's rmse: 4373.37\n",
      "[1050]\ttraining's rmse: 2505.07\tvalid_1's rmse: 4372.09\n",
      "[1060]\ttraining's rmse: 2499.84\tvalid_1's rmse: 4369.42\n",
      "[1070]\ttraining's rmse: 2492.17\tvalid_1's rmse: 4367.17\n",
      "[1080]\ttraining's rmse: 2484.43\tvalid_1's rmse: 4367.18\n",
      "[1090]\ttraining's rmse: 2478.66\tvalid_1's rmse: 4367.71\n",
      "[1100]\ttraining's rmse: 2471.98\tvalid_1's rmse: 4370.04\n",
      "[1110]\ttraining's rmse: 2465.66\tvalid_1's rmse: 4369.01\n",
      "[1120]\ttraining's rmse: 2458.65\tvalid_1's rmse: 4370.83\n",
      "[1130]\ttraining's rmse: 2453.57\tvalid_1's rmse: 4366.26\n",
      "[1140]\ttraining's rmse: 2447.55\tvalid_1's rmse: 4364.38\n",
      "[1150]\ttraining's rmse: 2441.07\tvalid_1's rmse: 4363.65\n",
      "[1160]\ttraining's rmse: 2435\tvalid_1's rmse: 4362.85\n",
      "[1170]\ttraining's rmse: 2429.25\tvalid_1's rmse: 4361.8\n",
      "[1180]\ttraining's rmse: 2422.89\tvalid_1's rmse: 4359.29\n",
      "[1190]\ttraining's rmse: 2417.3\tvalid_1's rmse: 4358.52\n",
      "[1200]\ttraining's rmse: 2411.48\tvalid_1's rmse: 4357.51\n",
      "[1210]\ttraining's rmse: 2405.98\tvalid_1's rmse: 4359.93\n",
      "[1220]\ttraining's rmse: 2400.87\tvalid_1's rmse: 4357.21\n",
      "[1230]\ttraining's rmse: 2393.9\tvalid_1's rmse: 4353.03\n",
      "[1240]\ttraining's rmse: 2388.6\tvalid_1's rmse: 4356.19\n",
      "[1250]\ttraining's rmse: 2382.35\tvalid_1's rmse: 4355.79\n",
      "[1260]\ttraining's rmse: 2377.4\tvalid_1's rmse: 4356.26\n",
      "[1270]\ttraining's rmse: 2373.07\tvalid_1's rmse: 4355.56\n",
      "[1280]\ttraining's rmse: 2368.26\tvalid_1's rmse: 4356.31\n",
      "[1290]\ttraining's rmse: 2362.98\tvalid_1's rmse: 4355.73\n",
      "Early stopping, best iteration is:\n",
      "[1230]\ttraining's rmse: 2393.9\tvalid_1's rmse: 4353.03\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1866\n",
      "[LightGBM] [Info] Number of data points in the train set: 18495, number of used features: 25\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 105682.523060\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[10]\ttraining's rmse: 39563.7\tvalid_1's rmse: 41520.5\n",
      "[20]\ttraining's rmse: 22220.8\tvalid_1's rmse: 25214.4\n",
      "[30]\ttraining's rmse: 16479.4\tvalid_1's rmse: 20634.9\n",
      "[40]\ttraining's rmse: 14265.8\tvalid_1's rmse: 19328.5\n",
      "[50]\ttraining's rmse: 13084.2\tvalid_1's rmse: 18757.1\n",
      "[60]\ttraining's rmse: 12294\tvalid_1's rmse: 18262.8\n",
      "[70]\ttraining's rmse: 11723.1\tvalid_1's rmse: 17861.1\n",
      "[80]\ttraining's rmse: 11194.6\tvalid_1's rmse: 17418.7\n",
      "[90]\ttraining's rmse: 10776.7\tvalid_1's rmse: 17122.9\n",
      "[100]\ttraining's rmse: 10387.5\tvalid_1's rmse: 16888.5\n",
      "[110]\ttraining's rmse: 10086.7\tvalid_1's rmse: 16769.4\n",
      "[120]\ttraining's rmse: 9838.55\tvalid_1's rmse: 16571.2\n",
      "[130]\ttraining's rmse: 9598.73\tvalid_1's rmse: 16444.8\n",
      "[140]\ttraining's rmse: 9388.22\tvalid_1's rmse: 16303.9\n",
      "[150]\ttraining's rmse: 9182.53\tvalid_1's rmse: 16114.6\n",
      "[160]\ttraining's rmse: 9021.74\tvalid_1's rmse: 16028.6\n",
      "[170]\ttraining's rmse: 8852.82\tvalid_1's rmse: 16018.7\n",
      "[180]\ttraining's rmse: 8693.18\tvalid_1's rmse: 15888.1\n",
      "[190]\ttraining's rmse: 8558.43\tvalid_1's rmse: 15836.7\n",
      "[200]\ttraining's rmse: 8419.6\tvalid_1's rmse: 15802.4\n",
      "[210]\ttraining's rmse: 8290.42\tvalid_1's rmse: 15677.3\n",
      "[220]\ttraining's rmse: 8168.02\tvalid_1's rmse: 15640.1\n",
      "[230]\ttraining's rmse: 8050.26\tvalid_1's rmse: 15562.3\n",
      "[240]\ttraining's rmse: 7947.73\tvalid_1's rmse: 15537.3\n",
      "[250]\ttraining's rmse: 7846.45\tvalid_1's rmse: 15488.6\n",
      "[260]\ttraining's rmse: 7751.7\tvalid_1's rmse: 15412.7\n",
      "[270]\ttraining's rmse: 7675.58\tvalid_1's rmse: 15379.6\n",
      "[280]\ttraining's rmse: 7595.21\tvalid_1's rmse: 15292.1\n",
      "[290]\ttraining's rmse: 7495.1\tvalid_1's rmse: 15237.9\n",
      "[300]\ttraining's rmse: 7421.47\tvalid_1's rmse: 15236.6\n",
      "[310]\ttraining's rmse: 7342.61\tvalid_1's rmse: 15197.2\n",
      "[320]\ttraining's rmse: 7269.89\tvalid_1's rmse: 15169\n",
      "[330]\ttraining's rmse: 7204.58\tvalid_1's rmse: 15112.5\n",
      "[340]\ttraining's rmse: 7135.38\tvalid_1's rmse: 15059.9\n",
      "[350]\ttraining's rmse: 7065.79\tvalid_1's rmse: 15013.7\n",
      "[360]\ttraining's rmse: 7010.5\tvalid_1's rmse: 15006.1\n",
      "[370]\ttraining's rmse: 6957.54\tvalid_1's rmse: 14981.6\n",
      "[380]\ttraining's rmse: 6897.47\tvalid_1's rmse: 14989.8\n",
      "[390]\ttraining's rmse: 6844.59\tvalid_1's rmse: 14986\n",
      "[400]\ttraining's rmse: 6777.14\tvalid_1's rmse: 14955.4\n",
      "[410]\ttraining's rmse: 6728.62\tvalid_1's rmse: 14941\n",
      "[420]\ttraining's rmse: 6677.5\tvalid_1's rmse: 14899.9\n",
      "[430]\ttraining's rmse: 6626.47\tvalid_1's rmse: 14878.4\n",
      "[440]\ttraining's rmse: 6580.76\tvalid_1's rmse: 14839.8\n",
      "[450]\ttraining's rmse: 6536.19\tvalid_1's rmse: 14842.1\n",
      "[460]\ttraining's rmse: 6489.78\tvalid_1's rmse: 14830.1\n",
      "[470]\ttraining's rmse: 6442.1\tvalid_1's rmse: 14785.5\n",
      "[480]\ttraining's rmse: 6400.71\tvalid_1's rmse: 14766.8\n",
      "[490]\ttraining's rmse: 6358.52\tvalid_1's rmse: 14756.1\n",
      "[500]\ttraining's rmse: 6312.76\tvalid_1's rmse: 14719.7\n",
      "[510]\ttraining's rmse: 6265.32\tvalid_1's rmse: 14690.9\n",
      "[520]\ttraining's rmse: 6227.78\tvalid_1's rmse: 14666.5\n",
      "[530]\ttraining's rmse: 6185.3\tvalid_1's rmse: 14655.3\n",
      "[540]\ttraining's rmse: 6142.61\tvalid_1's rmse: 14642.3\n",
      "[550]\ttraining's rmse: 6104.32\tvalid_1's rmse: 14633.8\n",
      "[560]\ttraining's rmse: 6069.96\tvalid_1's rmse: 14613.9\n",
      "[570]\ttraining's rmse: 6030.01\tvalid_1's rmse: 14592.2\n",
      "[580]\ttraining's rmse: 5995.32\tvalid_1's rmse: 14586.9\n",
      "[590]\ttraining's rmse: 5964.59\tvalid_1's rmse: 14564.2\n",
      "[600]\ttraining's rmse: 5929.96\tvalid_1's rmse: 14552.8\n",
      "[610]\ttraining's rmse: 5897.47\tvalid_1's rmse: 14534.6\n",
      "[620]\ttraining's rmse: 5863.88\tvalid_1's rmse: 14513.8\n",
      "[630]\ttraining's rmse: 5827.49\tvalid_1's rmse: 14522.6\n",
      "[640]\ttraining's rmse: 5795.07\tvalid_1's rmse: 14526.5\n",
      "[650]\ttraining's rmse: 5764.99\tvalid_1's rmse: 14516.4\n",
      "[660]\ttraining's rmse: 5733.73\tvalid_1's rmse: 14501.6\n",
      "[670]\ttraining's rmse: 5709.41\tvalid_1's rmse: 14480.2\n",
      "[680]\ttraining's rmse: 5683.42\tvalid_1's rmse: 14475\n",
      "[690]\ttraining's rmse: 5658.92\tvalid_1's rmse: 14484.4\n",
      "[700]\ttraining's rmse: 5628.78\tvalid_1's rmse: 14449.1\n",
      "[710]\ttraining's rmse: 5596.58\tvalid_1's rmse: 14440.5\n",
      "[720]\ttraining's rmse: 5571.26\tvalid_1's rmse: 14441.8\n",
      "[730]\ttraining's rmse: 5542.8\tvalid_1's rmse: 14453.8\n",
      "[740]\ttraining's rmse: 5522.54\tvalid_1's rmse: 14452.4\n",
      "[750]\ttraining's rmse: 5498.46\tvalid_1's rmse: 14430.2\n",
      "[760]\ttraining's rmse: 5472.7\tvalid_1's rmse: 14420.3\n",
      "[770]\ttraining's rmse: 5446.01\tvalid_1's rmse: 14417.7\n",
      "[780]\ttraining's rmse: 5422.52\tvalid_1's rmse: 14422.3\n",
      "[790]\ttraining's rmse: 5400.2\tvalid_1's rmse: 14420.3\n",
      "[800]\ttraining's rmse: 5375.43\tvalid_1's rmse: 14398.7\n",
      "[810]\ttraining's rmse: 5355.28\tvalid_1's rmse: 14386\n",
      "[820]\ttraining's rmse: 5333\tvalid_1's rmse: 14386.7\n",
      "[830]\ttraining's rmse: 5309.51\tvalid_1's rmse: 14381.1\n",
      "[840]\ttraining's rmse: 5288.83\tvalid_1's rmse: 14372.7\n",
      "[850]\ttraining's rmse: 5268.57\tvalid_1's rmse: 14362\n",
      "[860]\ttraining's rmse: 5248.76\tvalid_1's rmse: 14350.5\n",
      "[870]\ttraining's rmse: 5230.95\tvalid_1's rmse: 14328.9\n",
      "[880]\ttraining's rmse: 5212.11\tvalid_1's rmse: 14330.2\n",
      "[890]\ttraining's rmse: 5192.61\tvalid_1's rmse: 14338.4\n",
      "[900]\ttraining's rmse: 5170.81\tvalid_1's rmse: 14333.4\n",
      "[910]\ttraining's rmse: 5149\tvalid_1's rmse: 14331\n",
      "[920]\ttraining's rmse: 5128.53\tvalid_1's rmse: 14326.6\n",
      "[930]\ttraining's rmse: 5108.49\tvalid_1's rmse: 14321.8\n",
      "[940]\ttraining's rmse: 5090.74\tvalid_1's rmse: 14317.1\n",
      "[950]\ttraining's rmse: 5071.44\tvalid_1's rmse: 14318\n",
      "[960]\ttraining's rmse: 5054.33\tvalid_1's rmse: 14300.5\n",
      "[970]\ttraining's rmse: 5036.79\tvalid_1's rmse: 14296.2\n",
      "[980]\ttraining's rmse: 5015.92\tvalid_1's rmse: 14273.3\n",
      "[990]\ttraining's rmse: 4995.61\tvalid_1's rmse: 14263.4\n",
      "[1000]\ttraining's rmse: 4978.55\tvalid_1's rmse: 14262.7\n",
      "[1010]\ttraining's rmse: 4962.73\tvalid_1's rmse: 14253.9\n",
      "[1020]\ttraining's rmse: 4943.03\tvalid_1's rmse: 14252.2\n",
      "[1030]\ttraining's rmse: 4926.99\tvalid_1's rmse: 14245.1\n",
      "[1040]\ttraining's rmse: 4910.25\tvalid_1's rmse: 14253.8\n",
      "[1050]\ttraining's rmse: 4895.49\tvalid_1's rmse: 14262.1\n",
      "[1060]\ttraining's rmse: 4877.51\tvalid_1's rmse: 14261.9\n",
      "[1070]\ttraining's rmse: 4859.21\tvalid_1's rmse: 14259.7\n",
      "[1080]\ttraining's rmse: 4839.31\tvalid_1's rmse: 14248.4\n",
      "[1090]\ttraining's rmse: 4823.11\tvalid_1's rmse: 14230\n",
      "[1100]\ttraining's rmse: 4807.79\tvalid_1's rmse: 14241.1\n",
      "[1110]\ttraining's rmse: 4790.28\tvalid_1's rmse: 14217.8\n",
      "[1120]\ttraining's rmse: 4774.37\tvalid_1's rmse: 14216.9\n",
      "[1130]\ttraining's rmse: 4759.6\tvalid_1's rmse: 14222.9\n",
      "[1140]\ttraining's rmse: 4745.26\tvalid_1's rmse: 14213.5\n",
      "[1150]\ttraining's rmse: 4731.68\tvalid_1's rmse: 14218.7\n",
      "[1160]\ttraining's rmse: 4716.16\tvalid_1's rmse: 14209.5\n",
      "[1170]\ttraining's rmse: 4701.18\tvalid_1's rmse: 14200.7\n",
      "[1180]\ttraining's rmse: 4684.55\tvalid_1's rmse: 14195.5\n",
      "[1190]\ttraining's rmse: 4669.89\tvalid_1's rmse: 14182.7\n",
      "[1200]\ttraining's rmse: 4655.44\tvalid_1's rmse: 14172.1\n",
      "[1210]\ttraining's rmse: 4642.61\tvalid_1's rmse: 14167.4\n",
      "[1220]\ttraining's rmse: 4629.05\tvalid_1's rmse: 14163.9\n",
      "[1230]\ttraining's rmse: 4612.31\tvalid_1's rmse: 14167.1\n",
      "[1240]\ttraining's rmse: 4600.19\tvalid_1's rmse: 14161.5\n",
      "[1250]\ttraining's rmse: 4586.99\tvalid_1's rmse: 14166.5\n",
      "[1260]\ttraining's rmse: 4574.48\tvalid_1's rmse: 14177.4\n",
      "[1270]\ttraining's rmse: 4563.08\tvalid_1's rmse: 14160\n",
      "[1280]\ttraining's rmse: 4549.91\tvalid_1's rmse: 14160.3\n",
      "[1290]\ttraining's rmse: 4535.3\tvalid_1's rmse: 14146.8\n",
      "[1300]\ttraining's rmse: 4522.33\tvalid_1's rmse: 14151.4\n",
      "[1310]\ttraining's rmse: 4508.08\tvalid_1's rmse: 14160.8\n",
      "[1320]\ttraining's rmse: 4494.9\tvalid_1's rmse: 14150.5\n",
      "[1330]\ttraining's rmse: 4482.11\tvalid_1's rmse: 14146\n",
      "[1340]\ttraining's rmse: 4471.05\tvalid_1's rmse: 14134.2\n",
      "[1350]\ttraining's rmse: 4459.45\tvalid_1's rmse: 14133.2\n",
      "[1360]\ttraining's rmse: 4447.05\tvalid_1's rmse: 14139\n",
      "[1370]\ttraining's rmse: 4435.11\tvalid_1's rmse: 14144.5\n",
      "[1380]\ttraining's rmse: 4420\tvalid_1's rmse: 14142.5\n",
      "[1390]\ttraining's rmse: 4406.04\tvalid_1's rmse: 14137.8\n",
      "[1400]\ttraining's rmse: 4395.2\tvalid_1's rmse: 14141.5\n",
      "[1410]\ttraining's rmse: 4383.44\tvalid_1's rmse: 14119.1\n",
      "[1420]\ttraining's rmse: 4372.84\tvalid_1's rmse: 14128.2\n",
      "[1430]\ttraining's rmse: 4361.05\tvalid_1's rmse: 14137.3\n",
      "[1440]\ttraining's rmse: 4350.13\tvalid_1's rmse: 14126.7\n",
      "[1450]\ttraining's rmse: 4338.31\tvalid_1's rmse: 14116.5\n",
      "[1460]\ttraining's rmse: 4327.67\tvalid_1's rmse: 14108.4\n",
      "[1470]\ttraining's rmse: 4316.95\tvalid_1's rmse: 14116.3\n",
      "[1480]\ttraining's rmse: 4305.81\tvalid_1's rmse: 14119.7\n",
      "[1490]\ttraining's rmse: 4295.04\tvalid_1's rmse: 14115.9\n",
      "[1500]\ttraining's rmse: 4283.84\tvalid_1's rmse: 14104.6\n",
      "[1510]\ttraining's rmse: 4273.47\tvalid_1's rmse: 14114.8\n",
      "[1520]\ttraining's rmse: 4261.46\tvalid_1's rmse: 14110.6\n",
      "[1530]\ttraining's rmse: 4250.29\tvalid_1's rmse: 14125\n",
      "[1540]\ttraining's rmse: 4237.81\tvalid_1's rmse: 14123.3\n",
      "[1550]\ttraining's rmse: 4227.03\tvalid_1's rmse: 14126.3\n",
      "Early stopping, best iteration is:\n",
      "[1498]\ttraining's rmse: 4286.45\tvalid_1's rmse: 14102.2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1832\n",
      "[LightGBM] [Info] Number of data points in the train set: 34454, number of used features: 21\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 43801.387009\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[10]\ttraining's rmse: 10413.6\tvalid_1's rmse: 10154.1\n",
      "[20]\ttraining's rmse: 6848.47\tvalid_1's rmse: 6876.57\n",
      "[30]\ttraining's rmse: 5518.93\tvalid_1's rmse: 5697.72\n",
      "[40]\ttraining's rmse: 4930.41\tvalid_1's rmse: 5202.42\n",
      "[50]\ttraining's rmse: 4544.61\tvalid_1's rmse: 4872.24\n",
      "[60]\ttraining's rmse: 4283.53\tvalid_1's rmse: 4655.3\n",
      "[70]\ttraining's rmse: 4113.1\tvalid_1's rmse: 4516.35\n",
      "[80]\ttraining's rmse: 3974.26\tvalid_1's rmse: 4418.13\n",
      "[90]\ttraining's rmse: 3854.91\tvalid_1's rmse: 4328.65\n",
      "[100]\ttraining's rmse: 3755.92\tvalid_1's rmse: 4247.97\n",
      "[110]\ttraining's rmse: 3666.97\tvalid_1's rmse: 4186.89\n",
      "[120]\ttraining's rmse: 3593.22\tvalid_1's rmse: 4139.91\n",
      "[130]\ttraining's rmse: 3527.02\tvalid_1's rmse: 4105.65\n",
      "[140]\ttraining's rmse: 3464.83\tvalid_1's rmse: 4065.13\n",
      "[150]\ttraining's rmse: 3414.14\tvalid_1's rmse: 4035.95\n",
      "[160]\ttraining's rmse: 3362.98\tvalid_1's rmse: 4003.48\n",
      "[170]\ttraining's rmse: 3317.84\tvalid_1's rmse: 3979.49\n",
      "[180]\ttraining's rmse: 3270.69\tvalid_1's rmse: 3951.04\n",
      "[190]\ttraining's rmse: 3231.5\tvalid_1's rmse: 3924.12\n",
      "[200]\ttraining's rmse: 3194.11\tvalid_1's rmse: 3912.33\n",
      "[210]\ttraining's rmse: 3162.09\tvalid_1's rmse: 3892.78\n",
      "[220]\ttraining's rmse: 3133.11\tvalid_1's rmse: 3875.75\n",
      "[230]\ttraining's rmse: 3101.69\tvalid_1's rmse: 3859.9\n",
      "[240]\ttraining's rmse: 3071.39\tvalid_1's rmse: 3850.6\n",
      "[250]\ttraining's rmse: 3043.27\tvalid_1's rmse: 3843.97\n",
      "[260]\ttraining's rmse: 3014.87\tvalid_1's rmse: 3826.04\n",
      "[270]\ttraining's rmse: 2990.6\tvalid_1's rmse: 3818.14\n",
      "[280]\ttraining's rmse: 2966.19\tvalid_1's rmse: 3806.3\n",
      "[290]\ttraining's rmse: 2943.69\tvalid_1's rmse: 3793.48\n",
      "[300]\ttraining's rmse: 2920.27\tvalid_1's rmse: 3781.98\n",
      "[310]\ttraining's rmse: 2898.63\tvalid_1's rmse: 3773.9\n",
      "[320]\ttraining's rmse: 2879.75\tvalid_1's rmse: 3768.41\n",
      "[330]\ttraining's rmse: 2859.69\tvalid_1's rmse: 3762.61\n",
      "[340]\ttraining's rmse: 2842.04\tvalid_1's rmse: 3753.38\n",
      "[350]\ttraining's rmse: 2822.32\tvalid_1's rmse: 3744.59\n",
      "[360]\ttraining's rmse: 2800.95\tvalid_1's rmse: 3739.57\n",
      "[370]\ttraining's rmse: 2784.19\tvalid_1's rmse: 3733.15\n",
      "[380]\ttraining's rmse: 2764.44\tvalid_1's rmse: 3730.03\n",
      "[390]\ttraining's rmse: 2746.77\tvalid_1's rmse: 3725.71\n",
      "[400]\ttraining's rmse: 2731.62\tvalid_1's rmse: 3728.02\n",
      "[410]\ttraining's rmse: 2715.6\tvalid_1's rmse: 3723.09\n",
      "[420]\ttraining's rmse: 2700.15\tvalid_1's rmse: 3718.45\n",
      "[430]\ttraining's rmse: 2684.08\tvalid_1's rmse: 3706.38\n",
      "[440]\ttraining's rmse: 2667.89\tvalid_1's rmse: 3702.68\n",
      "[450]\ttraining's rmse: 2655.16\tvalid_1's rmse: 3700.01\n",
      "[460]\ttraining's rmse: 2641.02\tvalid_1's rmse: 3697.62\n",
      "[470]\ttraining's rmse: 2626.46\tvalid_1's rmse: 3693.73\n",
      "[480]\ttraining's rmse: 2613.61\tvalid_1's rmse: 3688.59\n",
      "[490]\ttraining's rmse: 2600.88\tvalid_1's rmse: 3687.27\n",
      "[500]\ttraining's rmse: 2589.32\tvalid_1's rmse: 3683.96\n",
      "[510]\ttraining's rmse: 2576.32\tvalid_1's rmse: 3679.37\n",
      "[520]\ttraining's rmse: 2564.68\tvalid_1's rmse: 3679.51\n",
      "[530]\ttraining's rmse: 2554.2\tvalid_1's rmse: 3678.95\n",
      "[540]\ttraining's rmse: 2542.38\tvalid_1's rmse: 3675.17\n",
      "[550]\ttraining's rmse: 2531.7\tvalid_1's rmse: 3671.54\n",
      "[560]\ttraining's rmse: 2521.62\tvalid_1's rmse: 3667.41\n",
      "[570]\ttraining's rmse: 2510.93\tvalid_1's rmse: 3663.88\n",
      "[580]\ttraining's rmse: 2499.63\tvalid_1's rmse: 3660.45\n",
      "[590]\ttraining's rmse: 2488.53\tvalid_1's rmse: 3661.88\n",
      "[600]\ttraining's rmse: 2477.88\tvalid_1's rmse: 3658.14\n",
      "[610]\ttraining's rmse: 2466.48\tvalid_1's rmse: 3655.69\n",
      "[620]\ttraining's rmse: 2456.44\tvalid_1's rmse: 3652.1\n",
      "[630]\ttraining's rmse: 2446.69\tvalid_1's rmse: 3648.29\n",
      "[640]\ttraining's rmse: 2436.97\tvalid_1's rmse: 3646.16\n",
      "[650]\ttraining's rmse: 2427.27\tvalid_1's rmse: 3645.44\n",
      "[660]\ttraining's rmse: 2418.05\tvalid_1's rmse: 3642.15\n",
      "[670]\ttraining's rmse: 2409.14\tvalid_1's rmse: 3642.35\n",
      "[680]\ttraining's rmse: 2400.18\tvalid_1's rmse: 3640.26\n",
      "[690]\ttraining's rmse: 2392.36\tvalid_1's rmse: 3640.04\n",
      "[700]\ttraining's rmse: 2382.67\tvalid_1's rmse: 3635.16\n",
      "[710]\ttraining's rmse: 2374.06\tvalid_1's rmse: 3632.73\n",
      "[720]\ttraining's rmse: 2366.55\tvalid_1's rmse: 3630.66\n",
      "[730]\ttraining's rmse: 2359.08\tvalid_1's rmse: 3628.37\n",
      "[740]\ttraining's rmse: 2347.97\tvalid_1's rmse: 3624.43\n",
      "[750]\ttraining's rmse: 2340.19\tvalid_1's rmse: 3624.28\n",
      "[760]\ttraining's rmse: 2333.06\tvalid_1's rmse: 3623.36\n",
      "[770]\ttraining's rmse: 2326\tvalid_1's rmse: 3624.14\n",
      "[780]\ttraining's rmse: 2317.26\tvalid_1's rmse: 3621.02\n",
      "[790]\ttraining's rmse: 2309.8\tvalid_1's rmse: 3619.85\n",
      "[800]\ttraining's rmse: 2302.07\tvalid_1's rmse: 3615.88\n",
      "[810]\ttraining's rmse: 2295.2\tvalid_1's rmse: 3615.12\n",
      "[820]\ttraining's rmse: 2288.56\tvalid_1's rmse: 3613.98\n",
      "[830]\ttraining's rmse: 2281.02\tvalid_1's rmse: 3610.53\n",
      "[840]\ttraining's rmse: 2274.39\tvalid_1's rmse: 3607.05\n",
      "[850]\ttraining's rmse: 2268.28\tvalid_1's rmse: 3604.29\n",
      "[860]\ttraining's rmse: 2261.57\tvalid_1's rmse: 3602.68\n",
      "[870]\ttraining's rmse: 2255.12\tvalid_1's rmse: 3599.56\n",
      "[880]\ttraining's rmse: 2247.96\tvalid_1's rmse: 3596.34\n",
      "[890]\ttraining's rmse: 2241.29\tvalid_1's rmse: 3594.4\n",
      "[900]\ttraining's rmse: 2234.86\tvalid_1's rmse: 3593.24\n",
      "[910]\ttraining's rmse: 2227.79\tvalid_1's rmse: 3593.93\n",
      "[920]\ttraining's rmse: 2221.64\tvalid_1's rmse: 3594.1\n",
      "[930]\ttraining's rmse: 2215.34\tvalid_1's rmse: 3594.58\n",
      "[940]\ttraining's rmse: 2209.63\tvalid_1's rmse: 3592.38\n",
      "[950]\ttraining's rmse: 2203.36\tvalid_1's rmse: 3590.18\n",
      "[960]\ttraining's rmse: 2197.78\tvalid_1's rmse: 3587.81\n",
      "[970]\ttraining's rmse: 2192.06\tvalid_1's rmse: 3584.85\n",
      "[980]\ttraining's rmse: 2186.17\tvalid_1's rmse: 3584.16\n",
      "[990]\ttraining's rmse: 2180.97\tvalid_1's rmse: 3584.3\n",
      "[1000]\ttraining's rmse: 2175.48\tvalid_1's rmse: 3584.45\n",
      "[1010]\ttraining's rmse: 2169.57\tvalid_1's rmse: 3582.17\n",
      "[1020]\ttraining's rmse: 2164.56\tvalid_1's rmse: 3579.91\n",
      "[1030]\ttraining's rmse: 2159.32\tvalid_1's rmse: 3580.29\n",
      "[1040]\ttraining's rmse: 2153.82\tvalid_1's rmse: 3580.72\n",
      "[1050]\ttraining's rmse: 2147.63\tvalid_1's rmse: 3580.82\n",
      "[1060]\ttraining's rmse: 2142.63\tvalid_1's rmse: 3581.51\n",
      "[1070]\ttraining's rmse: 2137.76\tvalid_1's rmse: 3577.99\n",
      "[1080]\ttraining's rmse: 2132.72\tvalid_1's rmse: 3576.35\n",
      "[1090]\ttraining's rmse: 2127.48\tvalid_1's rmse: 3574.71\n",
      "[1100]\ttraining's rmse: 2122.43\tvalid_1's rmse: 3572.68\n",
      "[1110]\ttraining's rmse: 2117.82\tvalid_1's rmse: 3571.29\n",
      "[1120]\ttraining's rmse: 2112.67\tvalid_1's rmse: 3571.29\n",
      "[1130]\ttraining's rmse: 2107.45\tvalid_1's rmse: 3571.82\n",
      "[1140]\ttraining's rmse: 2103.52\tvalid_1's rmse: 3570.1\n",
      "[1150]\ttraining's rmse: 2098.16\tvalid_1's rmse: 3572.04\n",
      "[1160]\ttraining's rmse: 2092.21\tvalid_1's rmse: 3571.91\n",
      "[1170]\ttraining's rmse: 2087.73\tvalid_1's rmse: 3571.96\n",
      "[1180]\ttraining's rmse: 2083.24\tvalid_1's rmse: 3572.96\n",
      "[1190]\ttraining's rmse: 2078.69\tvalid_1's rmse: 3573.08\n",
      "Early stopping, best iteration is:\n",
      "[1138]\ttraining's rmse: 2104.36\tvalid_1's rmse: 3569.16\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1421\n",
      "[LightGBM] [Info] Number of data points in the train set: 8190, number of used features: 24\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 57654.889866\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[10]\ttraining's rmse: 17540.2\tvalid_1's rmse: 17790.2\n",
      "[20]\ttraining's rmse: 9764.72\tvalid_1's rmse: 9669.09\n",
      "[30]\ttraining's rmse: 7335.79\tvalid_1's rmse: 7321.33\n",
      "[40]\ttraining's rmse: 6426.74\tvalid_1's rmse: 6630.8\n",
      "[50]\ttraining's rmse: 5910.05\tvalid_1's rmse: 6368.66\n",
      "[60]\ttraining's rmse: 5584.12\tvalid_1's rmse: 6148.63\n",
      "[70]\ttraining's rmse: 5314.19\tvalid_1's rmse: 5980.69\n",
      "[80]\ttraining's rmse: 5094.39\tvalid_1's rmse: 5883.13\n",
      "[90]\ttraining's rmse: 4910.41\tvalid_1's rmse: 5843.22\n",
      "[100]\ttraining's rmse: 4749.39\tvalid_1's rmse: 5789.18\n",
      "[110]\ttraining's rmse: 4613.68\tvalid_1's rmse: 5756.93\n",
      "[120]\ttraining's rmse: 4489.61\tvalid_1's rmse: 5737.99\n",
      "[130]\ttraining's rmse: 4378.82\tvalid_1's rmse: 5725.72\n",
      "[140]\ttraining's rmse: 4276.69\tvalid_1's rmse: 5693.4\n",
      "[150]\ttraining's rmse: 4188.11\tvalid_1's rmse: 5675.07\n",
      "[160]\ttraining's rmse: 4106.74\tvalid_1's rmse: 5670.08\n",
      "[170]\ttraining's rmse: 4027.12\tvalid_1's rmse: 5657.67\n",
      "[180]\ttraining's rmse: 3952.3\tvalid_1's rmse: 5643.21\n",
      "[190]\ttraining's rmse: 3882.15\tvalid_1's rmse: 5634.94\n",
      "[200]\ttraining's rmse: 3826.14\tvalid_1's rmse: 5625.51\n",
      "[210]\ttraining's rmse: 3761.84\tvalid_1's rmse: 5612.91\n",
      "[220]\ttraining's rmse: 3701.79\tvalid_1's rmse: 5597.49\n",
      "[230]\ttraining's rmse: 3638.3\tvalid_1's rmse: 5592.92\n",
      "[240]\ttraining's rmse: 3589.14\tvalid_1's rmse: 5590.16\n",
      "[250]\ttraining's rmse: 3529.28\tvalid_1's rmse: 5584.98\n",
      "[260]\ttraining's rmse: 3491.21\tvalid_1's rmse: 5567.63\n",
      "[270]\ttraining's rmse: 3442.78\tvalid_1's rmse: 5576.96\n",
      "[280]\ttraining's rmse: 3404.61\tvalid_1's rmse: 5549.67\n",
      "[290]\ttraining's rmse: 3359.13\tvalid_1's rmse: 5520.02\n",
      "[300]\ttraining's rmse: 3321.04\tvalid_1's rmse: 5522.36\n",
      "[310]\ttraining's rmse: 3280.58\tvalid_1's rmse: 5530.67\n",
      "[320]\ttraining's rmse: 3248.54\tvalid_1's rmse: 5530.39\n",
      "[330]\ttraining's rmse: 3212.32\tvalid_1's rmse: 5526.86\n",
      "[340]\ttraining's rmse: 3178.54\tvalid_1's rmse: 5527.13\n",
      "[350]\ttraining's rmse: 3147.07\tvalid_1's rmse: 5522.15\n",
      "[360]\ttraining's rmse: 3115.22\tvalid_1's rmse: 5507.36\n",
      "[370]\ttraining's rmse: 3082.38\tvalid_1's rmse: 5514.24\n",
      "[380]\ttraining's rmse: 3057.89\tvalid_1's rmse: 5520.95\n",
      "[390]\ttraining's rmse: 3030.17\tvalid_1's rmse: 5522.02\n",
      "[400]\ttraining's rmse: 3000.37\tvalid_1's rmse: 5527.99\n",
      "[410]\ttraining's rmse: 2972.89\tvalid_1's rmse: 5534.65\n",
      "[420]\ttraining's rmse: 2947.91\tvalid_1's rmse: 5540.56\n",
      "Early stopping, best iteration is:\n",
      "[364]\ttraining's rmse: 3102.65\tvalid_1's rmse: 5505.24\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1406\n",
      "[LightGBM] [Info] Number of data points in the train set: 12049, number of used features: 25\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 61919.559632\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[10]\ttraining's rmse: 16451.8\tvalid_1's rmse: 16167.9\n",
      "[20]\ttraining's rmse: 10088.1\tvalid_1's rmse: 10031.9\n",
      "[30]\ttraining's rmse: 7979.04\tvalid_1's rmse: 8221.23\n",
      "[40]\ttraining's rmse: 7021.23\tvalid_1's rmse: 7547.95\n",
      "[50]\ttraining's rmse: 6528.12\tvalid_1's rmse: 7268.89\n",
      "[60]\ttraining's rmse: 6206.25\tvalid_1's rmse: 7099.02\n",
      "[70]\ttraining's rmse: 5955.09\tvalid_1's rmse: 7038.76\n",
      "[80]\ttraining's rmse: 5762.31\tvalid_1's rmse: 6979.45\n",
      "[90]\ttraining's rmse: 5623.21\tvalid_1's rmse: 6938.7\n",
      "[100]\ttraining's rmse: 5481.37\tvalid_1's rmse: 6942.71\n",
      "[110]\ttraining's rmse: 5349.82\tvalid_1's rmse: 6950.27\n",
      "[120]\ttraining's rmse: 5247.62\tvalid_1's rmse: 6923.53\n",
      "[130]\ttraining's rmse: 5137.09\tvalid_1's rmse: 6940.76\n",
      "[140]\ttraining's rmse: 5037.23\tvalid_1's rmse: 6948.35\n",
      "[150]\ttraining's rmse: 4954.53\tvalid_1's rmse: 6959.15\n",
      "[160]\ttraining's rmse: 4870.28\tvalid_1's rmse: 6900.64\n",
      "[170]\ttraining's rmse: 4796.64\tvalid_1's rmse: 6894.36\n",
      "[180]\ttraining's rmse: 4727.45\tvalid_1's rmse: 6901.35\n",
      "[190]\ttraining's rmse: 4661.89\tvalid_1's rmse: 6900.33\n",
      "[200]\ttraining's rmse: 4598.63\tvalid_1's rmse: 6877.33\n",
      "[210]\ttraining's rmse: 4539.55\tvalid_1's rmse: 6868.99\n",
      "[220]\ttraining's rmse: 4474.78\tvalid_1's rmse: 6869.03\n",
      "[230]\ttraining's rmse: 4427.98\tvalid_1's rmse: 6852.47\n",
      "[240]\ttraining's rmse: 4380.03\tvalid_1's rmse: 6813.23\n",
      "[250]\ttraining's rmse: 4330.67\tvalid_1's rmse: 6788.3\n",
      "[260]\ttraining's rmse: 4282.47\tvalid_1's rmse: 6793.12\n",
      "[270]\ttraining's rmse: 4236.87\tvalid_1's rmse: 6768.55\n",
      "[280]\ttraining's rmse: 4194.23\tvalid_1's rmse: 6790.77\n",
      "[290]\ttraining's rmse: 4158.87\tvalid_1's rmse: 6793.71\n",
      "[300]\ttraining's rmse: 4122.3\tvalid_1's rmse: 6803.91\n",
      "[310]\ttraining's rmse: 4080.58\tvalid_1's rmse: 6814.88\n",
      "[320]\ttraining's rmse: 4043.47\tvalid_1's rmse: 6792.33\n",
      "[330]\ttraining's rmse: 4008.45\tvalid_1's rmse: 6794.21\n",
      "Early stopping, best iteration is:\n",
      "[270]\ttraining's rmse: 4236.87\tvalid_1's rmse: 6768.55\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1701\n",
      "[LightGBM] [Info] Number of data points in the train set: 33384, number of used features: 21\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 35175.150671\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[10]\ttraining's rmse: 7958.64\tvalid_1's rmse: 7762.94\n",
      "[20]\ttraining's rmse: 5126.05\tvalid_1's rmse: 5055\n",
      "[30]\ttraining's rmse: 4090.22\tvalid_1's rmse: 4097.24\n",
      "[40]\ttraining's rmse: 3515.83\tvalid_1's rmse: 3570.14\n",
      "[50]\ttraining's rmse: 3153.1\tvalid_1's rmse: 3226.21\n",
      "[60]\ttraining's rmse: 2935.91\tvalid_1's rmse: 3037.7\n",
      "[70]\ttraining's rmse: 2784.05\tvalid_1's rmse: 2896.5\n",
      "[80]\ttraining's rmse: 2671.62\tvalid_1's rmse: 2797.85\n",
      "[90]\ttraining's rmse: 2589.7\tvalid_1's rmse: 2738.05\n",
      "[100]\ttraining's rmse: 2516.61\tvalid_1's rmse: 2677.02\n",
      "[110]\ttraining's rmse: 2450.59\tvalid_1's rmse: 2629.66\n",
      "[120]\ttraining's rmse: 2395.62\tvalid_1's rmse: 2585.6\n",
      "[130]\ttraining's rmse: 2349.47\tvalid_1's rmse: 2558.26\n",
      "[140]\ttraining's rmse: 2306.19\tvalid_1's rmse: 2531\n",
      "[150]\ttraining's rmse: 2264.27\tvalid_1's rmse: 2511.65\n",
      "[160]\ttraining's rmse: 2229.68\tvalid_1's rmse: 2495.45\n",
      "[170]\ttraining's rmse: 2198.55\tvalid_1's rmse: 2484.6\n",
      "[180]\ttraining's rmse: 2171.04\tvalid_1's rmse: 2466.49\n",
      "[190]\ttraining's rmse: 2139.93\tvalid_1's rmse: 2450.5\n",
      "[200]\ttraining's rmse: 2113.57\tvalid_1's rmse: 2439.46\n",
      "[210]\ttraining's rmse: 2090.29\tvalid_1's rmse: 2430.05\n",
      "[220]\ttraining's rmse: 2067.89\tvalid_1's rmse: 2416.04\n",
      "[230]\ttraining's rmse: 2047.7\tvalid_1's rmse: 2408.03\n",
      "[240]\ttraining's rmse: 2027.2\tvalid_1's rmse: 2404.69\n",
      "[250]\ttraining's rmse: 2007.23\tvalid_1's rmse: 2400.74\n",
      "[260]\ttraining's rmse: 1988.96\tvalid_1's rmse: 2393.66\n",
      "[270]\ttraining's rmse: 1974.94\tvalid_1's rmse: 2391.01\n",
      "[280]\ttraining's rmse: 1960.55\tvalid_1's rmse: 2384.21\n",
      "[290]\ttraining's rmse: 1946.85\tvalid_1's rmse: 2377.49\n",
      "[300]\ttraining's rmse: 1931.98\tvalid_1's rmse: 2372.22\n",
      "[310]\ttraining's rmse: 1916.71\tvalid_1's rmse: 2367.42\n",
      "[320]\ttraining's rmse: 1902.15\tvalid_1's rmse: 2362.53\n",
      "[330]\ttraining's rmse: 1888.26\tvalid_1's rmse: 2357.53\n",
      "[340]\ttraining's rmse: 1874.72\tvalid_1's rmse: 2355.51\n",
      "[350]\ttraining's rmse: 1863.18\tvalid_1's rmse: 2352.34\n",
      "[360]\ttraining's rmse: 1852.77\tvalid_1's rmse: 2351.7\n",
      "[370]\ttraining's rmse: 1840.51\tvalid_1's rmse: 2345.72\n",
      "[380]\ttraining's rmse: 1831.42\tvalid_1's rmse: 2342.68\n",
      "[390]\ttraining's rmse: 1821.76\tvalid_1's rmse: 2338.34\n",
      "[400]\ttraining's rmse: 1811.37\tvalid_1's rmse: 2335.97\n",
      "[410]\ttraining's rmse: 1801.78\tvalid_1's rmse: 2333.56\n",
      "[420]\ttraining's rmse: 1792.16\tvalid_1's rmse: 2330.54\n",
      "[430]\ttraining's rmse: 1782.38\tvalid_1's rmse: 2330.06\n",
      "[440]\ttraining's rmse: 1773.08\tvalid_1's rmse: 2327.26\n",
      "[450]\ttraining's rmse: 1763.93\tvalid_1's rmse: 2324.93\n",
      "[460]\ttraining's rmse: 1755.4\tvalid_1's rmse: 2324.41\n",
      "[470]\ttraining's rmse: 1746.76\tvalid_1's rmse: 2322.79\n",
      "[480]\ttraining's rmse: 1738.23\tvalid_1's rmse: 2320.47\n",
      "[490]\ttraining's rmse: 1729.45\tvalid_1's rmse: 2317.94\n",
      "[500]\ttraining's rmse: 1721.65\tvalid_1's rmse: 2320.16\n",
      "[510]\ttraining's rmse: 1714.11\tvalid_1's rmse: 2318.44\n",
      "[520]\ttraining's rmse: 1705.71\tvalid_1's rmse: 2318.84\n",
      "[530]\ttraining's rmse: 1698.87\tvalid_1's rmse: 2317.14\n",
      "[540]\ttraining's rmse: 1691.07\tvalid_1's rmse: 2318.07\n",
      "[550]\ttraining's rmse: 1684.78\tvalid_1's rmse: 2317.12\n",
      "[560]\ttraining's rmse: 1677.41\tvalid_1's rmse: 2315.42\n",
      "[570]\ttraining's rmse: 1670.36\tvalid_1's rmse: 2315.64\n",
      "[580]\ttraining's rmse: 1662.2\tvalid_1's rmse: 2313.58\n",
      "[590]\ttraining's rmse: 1654.07\tvalid_1's rmse: 2313.65\n",
      "[600]\ttraining's rmse: 1648.14\tvalid_1's rmse: 2313.64\n",
      "[610]\ttraining's rmse: 1641.74\tvalid_1's rmse: 2314.5\n",
      "[620]\ttraining's rmse: 1634.73\tvalid_1's rmse: 2314.07\n",
      "[630]\ttraining's rmse: 1628.14\tvalid_1's rmse: 2313.03\n",
      "[640]\ttraining's rmse: 1621.35\tvalid_1's rmse: 2311.38\n",
      "[650]\ttraining's rmse: 1614.88\tvalid_1's rmse: 2310.38\n",
      "[660]\ttraining's rmse: 1608.87\tvalid_1's rmse: 2308.95\n",
      "[670]\ttraining's rmse: 1603.25\tvalid_1's rmse: 2308.63\n",
      "[680]\ttraining's rmse: 1597.88\tvalid_1's rmse: 2311.09\n",
      "[690]\ttraining's rmse: 1591.27\tvalid_1's rmse: 2311.56\n",
      "[700]\ttraining's rmse: 1586.05\tvalid_1's rmse: 2311.53\n",
      "[710]\ttraining's rmse: 1581.15\tvalid_1's rmse: 2311.03\n",
      "[720]\ttraining's rmse: 1575.62\tvalid_1's rmse: 2311.81\n",
      "[730]\ttraining's rmse: 1570.22\tvalid_1's rmse: 2308.47\n",
      "[740]\ttraining's rmse: 1564.72\tvalid_1's rmse: 2309.71\n",
      "[750]\ttraining's rmse: 1559.84\tvalid_1's rmse: 2309.58\n",
      "[760]\ttraining's rmse: 1554.3\tvalid_1's rmse: 2308.32\n",
      "[770]\ttraining's rmse: 1549.38\tvalid_1's rmse: 2306.55\n",
      "[780]\ttraining's rmse: 1544.58\tvalid_1's rmse: 2307.07\n",
      "[790]\ttraining's rmse: 1539.63\tvalid_1's rmse: 2306.76\n",
      "[800]\ttraining's rmse: 1534.73\tvalid_1's rmse: 2306.42\n",
      "[810]\ttraining's rmse: 1529.79\tvalid_1's rmse: 2305.45\n",
      "[820]\ttraining's rmse: 1525.4\tvalid_1's rmse: 2303.64\n",
      "[830]\ttraining's rmse: 1520.84\tvalid_1's rmse: 2303.1\n",
      "[840]\ttraining's rmse: 1515.84\tvalid_1's rmse: 2303.23\n",
      "[850]\ttraining's rmse: 1511.4\tvalid_1's rmse: 2304.13\n",
      "[860]\ttraining's rmse: 1507.34\tvalid_1's rmse: 2305.79\n",
      "[870]\ttraining's rmse: 1502.54\tvalid_1's rmse: 2305.22\n",
      "[880]\ttraining's rmse: 1497.69\tvalid_1's rmse: 2304.4\n",
      "[890]\ttraining's rmse: 1494.01\tvalid_1's rmse: 2303.14\n",
      "[900]\ttraining's rmse: 1490.15\tvalid_1's rmse: 2301.85\n",
      "[910]\ttraining's rmse: 1485.61\tvalid_1's rmse: 2300.92\n",
      "[920]\ttraining's rmse: 1480.8\tvalid_1's rmse: 2301.21\n",
      "[930]\ttraining's rmse: 1476.29\tvalid_1's rmse: 2300.37\n",
      "[940]\ttraining's rmse: 1472.44\tvalid_1's rmse: 2301.23\n",
      "[950]\ttraining's rmse: 1467.95\tvalid_1's rmse: 2300\n",
      "[960]\ttraining's rmse: 1463.94\tvalid_1's rmse: 2299.08\n",
      "[970]\ttraining's rmse: 1459.81\tvalid_1's rmse: 2298.93\n",
      "[980]\ttraining's rmse: 1455.96\tvalid_1's rmse: 2300.57\n",
      "[990]\ttraining's rmse: 1452.15\tvalid_1's rmse: 2300.97\n",
      "[1000]\ttraining's rmse: 1448.25\tvalid_1's rmse: 2301.17\n",
      "[1010]\ttraining's rmse: 1444.97\tvalid_1's rmse: 2300.56\n",
      "[1020]\ttraining's rmse: 1441.62\tvalid_1's rmse: 2300.57\n",
      "Early stopping, best iteration is:\n",
      "[961]\ttraining's rmse: 1463.56\tvalid_1's rmse: 2298.37\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "for i in range(25):\n",
    "    models.append(make_model(train_X_list[i].drop(['구'], axis=1), train_y_list[i], valid_X_list[i].drop(['구'], axis=1), valid_y_list[i], i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_325043/3600698321.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i].drop(['target'], axis=1, inplace=True)\n",
      "/tmp/ipykernel_325043/3600698321.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i].drop(['target'], axis=1, inplace=True)\n",
      "/tmp/ipykernel_325043/3600698321.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i].drop(['target'], axis=1, inplace=True)\n",
      "/tmp/ipykernel_325043/3600698321.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i].drop(['target'], axis=1, inplace=True)\n",
      "/tmp/ipykernel_325043/3600698321.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i].drop(['target'], axis=1, inplace=True)\n",
      "/tmp/ipykernel_325043/3600698321.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i].drop(['target'], axis=1, inplace=True)\n",
      "/tmp/ipykernel_325043/3600698321.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i].drop(['target'], axis=1, inplace=True)\n",
      "/tmp/ipykernel_325043/3600698321.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i].drop(['target'], axis=1, inplace=True)\n",
      "/tmp/ipykernel_325043/3600698321.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i].drop(['target'], axis=1, inplace=True)\n",
      "/tmp/ipykernel_325043/3600698321.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i].drop(['target'], axis=1, inplace=True)\n",
      "/tmp/ipykernel_325043/3600698321.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i].drop(['target'], axis=1, inplace=True)\n",
      "/tmp/ipykernel_325043/3600698321.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i].drop(['target'], axis=1, inplace=True)\n",
      "/tmp/ipykernel_325043/3600698321.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i].drop(['target'], axis=1, inplace=True)\n",
      "/tmp/ipykernel_325043/3600698321.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i].drop(['target'], axis=1, inplace=True)\n",
      "/tmp/ipykernel_325043/3600698321.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i].drop(['target'], axis=1, inplace=True)\n",
      "/tmp/ipykernel_325043/3600698321.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i].drop(['target'], axis=1, inplace=True)\n",
      "/tmp/ipykernel_325043/3600698321.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i].drop(['target'], axis=1, inplace=True)\n",
      "/tmp/ipykernel_325043/3600698321.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i].drop(['target'], axis=1, inplace=True)\n",
      "/tmp/ipykernel_325043/3600698321.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i].drop(['target'], axis=1, inplace=True)\n",
      "/tmp/ipykernel_325043/3600698321.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i].drop(['target'], axis=1, inplace=True)\n",
      "/tmp/ipykernel_325043/3600698321.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i].drop(['target'], axis=1, inplace=True)\n",
      "/tmp/ipykernel_325043/3600698321.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i].drop(['target'], axis=1, inplace=True)\n",
      "/tmp/ipykernel_325043/3600698321.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i].drop(['target'], axis=1, inplace=True)\n",
      "/tmp/ipykernel_325043/3600698321.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i].drop(['target'], axis=1, inplace=True)\n",
      "/tmp/ipykernel_325043/3600698321.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i].drop(['target'], axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "for i in range(25):\n",
    "    test_df_list[i].drop(['target'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_li = []\n",
    "\n",
    "for i in range(25):\n",
    "    preds_li.append(models[i].predict(test_df_list[i].drop(['구'], axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([183572.89340515, 295183.47928658, 332229.22505256, 284610.97097172,\n",
       "       231278.38782391, 236577.53599942, 242468.15896133, 230750.14921783,\n",
       "       178247.91946989, 408808.31304824, 267277.86376526, 258065.76479585,\n",
       "       265209.27270135, 188747.59287013, 261746.20262174, 256841.66768034,\n",
       "       193976.85156962, 269269.28175796, 257450.72648715, 268858.42053874,\n",
       "       326608.59369546, 341790.20561548, 168880.22988613, 305484.39836168,\n",
       "        41603.70206432,  43760.42306566, 165267.83017844, 207115.95859262,\n",
       "       147423.37537123, 157778.8775517 , 223937.87460924, 222109.41434162,\n",
       "       257182.4696818 , 224048.69848765, 268822.65525468, 269213.8085256 ,\n",
       "        96285.24083638, 393702.12023254, 265397.04908283, 397776.44142659,\n",
       "       268765.34175458, 184634.10888684, 186218.41600298, 260362.8841362 ,\n",
       "       195453.15732228, 198813.42920597, 344572.60478192, 318836.4688166 ,\n",
       "       193779.18430591, 209359.01910254, 352029.35845419, 190272.04157134,\n",
       "       203877.16862164, 276069.73731886, 192324.91318755, 276521.53295384,\n",
       "       259054.35697361, 210744.13978019, 188625.36299635, 177201.8426657 ,\n",
       "       177201.8426657 , 213863.0837958 , 211186.45871287, 222953.54114073,\n",
       "       177189.66683055, 177371.99039021, 406163.75167024, 239874.88292848,\n",
       "       269741.26350804, 176946.41853106, 241519.56039838, 242968.04381898,\n",
       "       237598.59299656, 176593.5928533 , 239582.05031768, 237655.650297  ,\n",
       "       234752.45300068, 211738.72613058, 178006.50218525, 273989.77411098,\n",
       "       273316.40593311, 203237.83724648, 271634.97793488, 208538.67095658,\n",
       "       234505.5008807 , 212334.64772107, 238784.0243194 , 213018.33474109,\n",
       "       226601.30173132, 237464.981909  , 204572.44886708, 209918.27863757,\n",
       "       237349.52525664, 212016.17216304, 215268.62804451, 208577.20532817,\n",
       "       232259.81646881, 232259.81646881, 215124.96637537, 215476.61732108,\n",
       "       241474.76820604, 208577.20532817, 205128.65797491, 241208.24436712,\n",
       "       232259.81646881, 241109.16894279, 227415.30651067, 237620.83074302,\n",
       "       211176.91603248, 214324.98453671, 217007.96620134, 216594.54992226,\n",
       "       211450.95119825, 217064.74494341, 220296.50122287, 221669.78806258,\n",
       "       176961.12910526, 224718.28357351, 276380.03212921, 271462.25037972,\n",
       "       220149.05509904, 221665.32620915, 305445.59844552, 280170.40269455,\n",
       "       206042.62636937, 207023.21851036, 278819.88756642, 279972.04392341,\n",
       "       209017.34070982, 360438.00664978, 212811.20346418, 259755.68823595,\n",
       "       212995.42862889, 121320.90669156, 107507.74287698, 141246.79920514,\n",
       "       124366.58287771, 108944.39749708, 124366.58287771, 109531.55925015,\n",
       "       110036.48847321, 106973.22624175,  93018.42802188,  93149.86535753,\n",
       "       124812.25504119, 124812.25504119,  94021.37549233, 126680.35190838,\n",
       "       110634.53827366, 105755.17748533, 128401.08219067, 108276.20795635,\n",
       "       108243.21805989,  94854.4777925 ,  94629.41090257,  95465.00860375,\n",
       "       128843.79187665, 110360.28045195,  94629.41090257, 110417.37874465,\n",
       "       217361.83978583, 221914.80519626, 212930.42962033, 223181.0670651 ,\n",
       "       277338.97770774,  35571.92367805, 199312.3593679 , 193568.4221841 ,\n",
       "       194100.26125214, 201729.98483683, 200552.39145775, 186949.30602131,\n",
       "        85954.60018939, 212943.67559304,  91764.7723093 ,  88446.18885879,\n",
       "        89666.87968618,  19266.07659843, 281710.62760289, 368066.75940741,\n",
       "       342819.78830877, 281029.35975489,  36118.29153742, 307633.1558966 ,\n",
       "       298949.49407858, 314735.41623525,  85076.93937737, 272093.04786642,\n",
       "       266227.11348797, 273305.26725958, 274330.61900452, 163625.04931402,\n",
       "       436214.22316038, 444393.24694172, 387868.52385906, 475440.35999016,\n",
       "       349391.14776067, 454134.79880711, 344421.64485189, 340867.9415713 ,\n",
       "       296513.53157386, 296394.67967644, 325683.67850697, 306867.61884347,\n",
       "       449795.55010754, 313056.55571323, 480221.78063705, 341254.54158074,\n",
       "       387980.40959259, 269536.27662207, 269536.27662207, 296531.6731552 ,\n",
       "       290744.35632267, 285575.59483822, 220044.42071831, 337240.0807174 ,\n",
       "       251351.05986449, 248472.25413527, 254010.47162727, 347034.91944389,\n",
       "       482258.74316219, 339186.78059774, 326876.66695356, 246680.10530448,\n",
       "       246680.10530448,  91472.36015004,  43248.96262934,  47616.35290424,\n",
       "       144852.7805352 , 304701.92267239, 301507.3077463 , 270820.63170925,\n",
       "        32176.87571467, 272011.30136676, 198928.88588221, 199105.37355476,\n",
       "       227601.12462609, 184701.44829496, 235956.79350761, 213228.19471356,\n",
       "       216327.02035442, 168707.39458354, 215353.20094675, 298607.22356942,\n",
       "       162285.73366151, 246832.99739514, 246363.85912489, 250615.09680354,\n",
       "       250003.80880744, 318623.34315018, 215542.6436615 ,  47687.02414478,\n",
       "       435902.28156716, 240276.24574038, 435098.36026822, 796372.06218069,\n",
       "       745421.40633385, 483654.5753189 , 375265.18184471, 370860.34614866,\n",
       "       381732.9038646 , 362490.29393292, 644415.57445222, 395164.66059433,\n",
       "       654940.45743167, 351605.74357573, 183637.33649209, 156801.82504304,\n",
       "       177011.64406975,  49094.02105445,  46664.21694543,  49625.76620062,\n",
       "       148221.37320259, 155303.66725744, 142847.50604289, 151594.53931616,\n",
       "       324115.32897287, 329765.31916279, 230612.18451588, 121332.49773815,\n",
       "       121133.79258621, 119141.37749231, 164732.72539921, 121972.33497351,\n",
       "       142579.00914949, 135922.26840853, 136640.37695072, 144482.95874011,\n",
       "       142412.71201609, 140957.65750945, 136783.29437013, 144910.64740563,\n",
       "       138503.21818253, 130947.2419404 , 169300.37252963, 194830.84679654,\n",
       "       170600.20515068, 134874.90928291, 218092.35431043, 240537.74534526,\n",
       "       227224.05504462, 174419.85130348, 177164.22264075, 175013.01695257,\n",
       "       177278.20855325, 232142.38799123, 222206.75784315, 176364.34854237,\n",
       "       227220.16474916, 325572.76042187, 180206.7219608 , 233639.77832768,\n",
       "       186001.63312964, 180470.11541495, 183534.91693175, 186001.63312964,\n",
       "       236321.73482983,  52061.52562062, 175657.49620125, 186731.15631374,\n",
       "       145860.4099867 , 178446.30232776, 179937.73649378, 178446.30232776,\n",
       "       183081.15530746, 111388.73068832, 132624.22792186, 117631.69102574,\n",
       "       124984.7180272 , 114904.11146156, 115076.38841213, 150234.18893404,\n",
       "       123590.60580993, 128622.86556064, 151866.43373562, 184178.45652858,\n",
       "       191072.03257712, 184080.34302314, 195843.39855688, 189135.23820579,\n",
       "       203182.21428207, 202427.36574363, 192818.32570099,  35740.03047009,\n",
       "        39836.04612622,  39188.69741252,  40876.4325859 , 187481.49802757,\n",
       "       207707.14526874, 274351.27902454, 409039.87299908, 276952.24677986,\n",
       "       236047.32782852, 216411.36411168, 323158.32493584, 248546.12323805,\n",
       "       252572.9271934 , 213689.25666213, 208043.87660648, 128439.10498527,\n",
       "       251766.18092059, 253848.57417059, 258520.45047337, 161511.3845886 ,\n",
       "       482886.41236742, 565827.07497107, 486306.35711911, 503961.99034383,\n",
       "       352299.95856574,  75645.95528229, 146776.66051796, 265550.7797106 ,\n",
       "       269176.35190834, 257554.08730261, 122175.4597822 , 121570.69303195,\n",
       "       121356.48965196, 343319.23486382, 283651.55954146,  75786.88371143,\n",
       "        84607.03614998, 109331.72205623,  80091.20222572, 110562.87856639,\n",
       "       110799.8349748 ,  79437.55582728,  79206.61110739, 115546.26708466,\n",
       "        82533.27789753,  81924.95999823,  93188.62448462,  92277.30333861,\n",
       "       112957.03988817, 112957.03988817, 114694.3973198 ,  83817.14518955,\n",
       "        81924.95999823,  92097.87252626,  83592.65356602, 116115.83351812,\n",
       "        92400.66370889, 157323.20262124, 169358.97525059, 169938.74566963,\n",
       "       176707.77848351, 171074.71730732, 178002.28960907, 129426.78043305,\n",
       "       112856.76320657, 111895.18264111, 111895.18264111, 109711.0485754 ,\n",
       "       111371.42983283, 112236.83598411,  94390.93699654,  96134.23684667,\n",
       "        96511.11344907, 110791.55373683, 111658.20374628,  87186.36729656,\n",
       "       110791.55373683, 154364.78256446, 555488.35596559,  77937.58342411,\n",
       "        89820.38074017, 547394.30631072, 476157.15017894, 365262.52437955,\n",
       "       364170.33610696, 357169.65531074, 373151.44599251, 398722.33327043,\n",
       "       626626.61268065, 555452.17985793, 584610.03819442, 521521.72336956,\n",
       "       521521.72336956, 563741.22959977, 514546.76236289, 362041.81024019,\n",
       "       350288.99767843, 237384.80700991, 237384.80700991, 324173.2351371 ,\n",
       "       267336.22463366, 448468.70790644, 437007.94662964, 362189.15672802,\n",
       "       432340.35191048, 303148.68880218, 450348.09153702, 324003.34621723,\n",
       "       377023.03309634, 334194.57310405, 560704.54873998, 311286.24450152,\n",
       "       302066.96890431, 302988.16818585, 470753.15853852, 478895.74432053,\n",
       "       343165.68775362, 343891.62633857, 501984.29744421, 183332.98386337,\n",
       "       236692.73648118, 187323.62502586, 188209.00377098, 189791.90094114,\n",
       "       115356.04998043,  22756.34755901, 273346.87717677, 308850.63594568,\n",
       "       325271.97449351, 187321.14932452, 311154.2823885 , 256178.11182298,\n",
       "        27241.78897026,  26387.68811589, 126030.03897828, 135560.74291528,\n",
       "        21577.43297203,  22238.00013576,  24275.98786171,  48534.95547424,\n",
       "        82356.48640998,  37835.03236347, 152191.59800271, 201527.64726179,\n",
       "       328896.48369009, 311063.30731528, 314481.96105073,  82055.09860447,\n",
       "        79597.15005245,  77465.95314753,  50291.59008833, 122036.25994631,\n",
       "        78132.80405734,  64824.80211358, 149626.8852984 , 121051.03856629,\n",
       "       257798.61819406, 275459.68017019, 281003.79125976,  42275.57516831,\n",
       "        42463.92194412,  39020.10336322,  31550.72786236, 179034.40820759,\n",
       "       182111.66599056, 191518.58790899, 242442.4106777 , 343238.21294717,\n",
       "       245492.73670762, 246294.06068914, 234025.5081876 , 183530.88665404,\n",
       "       201214.08301715, 169831.41346295, 239897.08774689, 245501.89594782,\n",
       "       339554.4481851 , 169120.13249001, 233063.94480979, 196120.55134021,\n",
       "       183810.04280177, 232273.31295133, 232632.70448224, 197324.15516025,\n",
       "        84830.35729051, 116651.02154153,  83206.39890885, 105192.00762366,\n",
       "       207074.45097297, 205457.03274764, 201429.51817086, 193441.22632259,\n",
       "       205138.20117967, 207141.62920415, 125951.98475935, 127950.35602618,\n",
       "       123731.41657127, 161893.13944504, 127349.70506297, 128563.96145122,\n",
       "       161115.78802405, 130585.95712882, 172691.20520928, 130064.93886639,\n",
       "        96175.97458447, 141727.80759369, 455829.11283003, 218722.1756557 ,\n",
       "       317504.69886122, 228541.75256457, 177189.26451729, 181300.92796466,\n",
       "       136198.45644507, 174751.74861966, 109747.96823392, 111579.42300568,\n",
       "       137584.11568861,  34743.39738441, 134167.76057239, 134167.76057239,\n",
       "       222704.55721342, 187731.27024339, 179808.16379569, 180959.02827275,\n",
       "       234303.36442037, 231864.69468448, 231770.23115994, 176078.29428017,\n",
       "       186570.18387587])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_li[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과 후처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(25):\n",
    "    preds_li[i] = np.round(preds_li[i]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_325043/2787385330.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i]['target'] = preds_li[i]\n",
      "/tmp/ipykernel_325043/2787385330.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i]['target'] = preds_li[i]\n",
      "/tmp/ipykernel_325043/2787385330.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i]['target'] = preds_li[i]\n",
      "/tmp/ipykernel_325043/2787385330.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i]['target'] = preds_li[i]\n",
      "/tmp/ipykernel_325043/2787385330.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i]['target'] = preds_li[i]\n",
      "/tmp/ipykernel_325043/2787385330.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i]['target'] = preds_li[i]\n",
      "/tmp/ipykernel_325043/2787385330.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i]['target'] = preds_li[i]\n",
      "/tmp/ipykernel_325043/2787385330.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i]['target'] = preds_li[i]\n",
      "/tmp/ipykernel_325043/2787385330.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i]['target'] = preds_li[i]\n",
      "/tmp/ipykernel_325043/2787385330.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i]['target'] = preds_li[i]\n",
      "/tmp/ipykernel_325043/2787385330.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i]['target'] = preds_li[i]\n",
      "/tmp/ipykernel_325043/2787385330.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i]['target'] = preds_li[i]\n",
      "/tmp/ipykernel_325043/2787385330.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i]['target'] = preds_li[i]\n",
      "/tmp/ipykernel_325043/2787385330.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i]['target'] = preds_li[i]\n",
      "/tmp/ipykernel_325043/2787385330.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i]['target'] = preds_li[i]\n",
      "/tmp/ipykernel_325043/2787385330.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i]['target'] = preds_li[i]\n",
      "/tmp/ipykernel_325043/2787385330.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i]['target'] = preds_li[i]\n",
      "/tmp/ipykernel_325043/2787385330.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i]['target'] = preds_li[i]\n",
      "/tmp/ipykernel_325043/2787385330.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i]['target'] = preds_li[i]\n",
      "/tmp/ipykernel_325043/2787385330.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i]['target'] = preds_li[i]\n",
      "/tmp/ipykernel_325043/2787385330.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i]['target'] = preds_li[i]\n",
      "/tmp/ipykernel_325043/2787385330.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i]['target'] = preds_li[i]\n",
      "/tmp/ipykernel_325043/2787385330.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i]['target'] = preds_li[i]\n",
      "/tmp/ipykernel_325043/2787385330.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i]['target'] = preds_li[i]\n",
      "/tmp/ipykernel_325043/2787385330.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_list[i]['target'] = preds_li[i]\n"
     ]
    }
   ],
   "source": [
    "for i in range(25):\n",
    "    test_df_list[i]['target'] = preds_li[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>전용면적</th>\n",
       "      <th>층</th>\n",
       "      <th>건축년도</th>\n",
       "      <th>좌표X</th>\n",
       "      <th>좌표Y</th>\n",
       "      <th>가장 가까운 거리</th>\n",
       "      <th>인근 지하철 역 개수</th>\n",
       "      <th>가장 가까운 버스 정류장 거리</th>\n",
       "      <th>인근 버스 정류장 개수</th>\n",
       "      <th>계약년</th>\n",
       "      <th>...</th>\n",
       "      <th>공항철도1호선</th>\n",
       "      <th>과천선</th>\n",
       "      <th>분당선</th>\n",
       "      <th>신림선</th>\n",
       "      <th>신분당선</th>\n",
       "      <th>신분당선(연장2)</th>\n",
       "      <th>우이신설선</th>\n",
       "      <th>일산선</th>\n",
       "      <th>중앙선</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1118822</th>\n",
       "      <td>0.168839</td>\n",
       "      <td>0.123288</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.678243</td>\n",
       "      <td>0.167126</td>\n",
       "      <td>0.353721</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.101599</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>183573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118823</th>\n",
       "      <td>0.236982</td>\n",
       "      <td>0.191781</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.676106</td>\n",
       "      <td>0.199219</td>\n",
       "      <td>0.092077</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.209173</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>295183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118824</th>\n",
       "      <td>0.364422</td>\n",
       "      <td>0.260274</td>\n",
       "      <td>0.370968</td>\n",
       "      <td>0.675047</td>\n",
       "      <td>0.195279</td>\n",
       "      <td>0.126138</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.163092</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>332229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118825</th>\n",
       "      <td>0.297948</td>\n",
       "      <td>0.246575</td>\n",
       "      <td>0.370968</td>\n",
       "      <td>0.675047</td>\n",
       "      <td>0.195279</td>\n",
       "      <td>0.126138</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.163092</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>284611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118826</th>\n",
       "      <td>0.227878</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.370968</td>\n",
       "      <td>0.675047</td>\n",
       "      <td>0.195279</td>\n",
       "      <td>0.126138</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.163092</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123928</th>\n",
       "      <td>0.180835</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.734501</td>\n",
       "      <td>0.220301</td>\n",
       "      <td>0.112839</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.319755</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>234303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123929</th>\n",
       "      <td>0.180835</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.734501</td>\n",
       "      <td>0.220301</td>\n",
       "      <td>0.112839</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.319755</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123930</th>\n",
       "      <td>0.180835</td>\n",
       "      <td>0.178082</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.734501</td>\n",
       "      <td>0.220301</td>\n",
       "      <td>0.112839</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.319755</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123931</th>\n",
       "      <td>0.155733</td>\n",
       "      <td>0.095890</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.740689</td>\n",
       "      <td>0.187216</td>\n",
       "      <td>0.108642</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.207077</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>176078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123932</th>\n",
       "      <td>0.180859</td>\n",
       "      <td>0.068493</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.740689</td>\n",
       "      <td>0.187216</td>\n",
       "      <td>0.108642</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.207077</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>186570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>573 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             전용면적         층      건축년도       좌표X       좌표Y  가장 가까운 거리  \\\n",
       "1118822  0.168839  0.123288  0.419355  0.678243  0.167126   0.353721   \n",
       "1118823  0.236982  0.191781  0.967742  0.676106  0.199219   0.092077   \n",
       "1118824  0.364422  0.260274  0.370968  0.675047  0.195279   0.126138   \n",
       "1118825  0.297948  0.246575  0.370968  0.675047  0.195279   0.126138   \n",
       "1118826  0.227878  0.136986  0.370968  0.675047  0.195279   0.126138   \n",
       "...           ...       ...       ...       ...       ...        ...   \n",
       "1123928  0.180835  0.150685  0.967742  0.734501  0.220301   0.112839   \n",
       "1123929  0.180835  0.136986  0.967742  0.734501  0.220301   0.112839   \n",
       "1123930  0.180835  0.178082  0.967742  0.734501  0.220301   0.112839   \n",
       "1123931  0.155733  0.095890  0.516129  0.740689  0.187216   0.108642   \n",
       "1123932  0.180859  0.068493  0.516129  0.740689  0.187216   0.108642   \n",
       "\n",
       "         인근 지하철 역 개수  가장 가까운 버스 정류장 거리  인근 버스 정류장 개수  계약년  ...  공항철도1호선  과천선  \\\n",
       "1118822     0.086957          0.101599      0.200000  1.0  ...      0.0  0.0   \n",
       "1118823     0.304348          0.209173      0.228571  1.0  ...      0.0  0.0   \n",
       "1118824     0.304348          0.163092      0.257143  1.0  ...      0.0  0.0   \n",
       "1118825     0.304348          0.163092      0.257143  1.0  ...      0.0  0.0   \n",
       "1118826     0.304348          0.163092      0.257143  1.0  ...      0.0  0.0   \n",
       "...              ...               ...           ...  ...  ...      ...  ...   \n",
       "1123928     0.260870          0.319755      0.171429  1.0  ...      0.0  0.0   \n",
       "1123929     0.260870          0.319755      0.171429  1.0  ...      0.0  0.0   \n",
       "1123930     0.260870          0.319755      0.171429  1.0  ...      0.0  0.0   \n",
       "1123931     0.130435          0.207077      0.114286  1.0  ...      0.0  0.0   \n",
       "1123932     0.130435          0.207077      0.114286  1.0  ...      0.0  0.0   \n",
       "\n",
       "         분당선  신림선 신분당선  신분당선(연장2)  우이신설선  일산선  중앙선  target  \n",
       "1118822  1.0  0.0  0.0        0.0    0.0  0.0  0.0  183573  \n",
       "1118823  1.0  0.0  0.0        0.0    0.0  0.0  0.0  295183  \n",
       "1118824  1.0  0.0  0.0        0.0    0.0  0.0  0.0  332229  \n",
       "1118825  1.0  0.0  0.0        0.0    0.0  0.0  0.0  284611  \n",
       "1118826  1.0  0.0  0.0        0.0    0.0  0.0  0.0  231278  \n",
       "...      ...  ...  ...        ...    ...  ...  ...     ...  \n",
       "1123928  0.0  0.0  0.0        0.0    0.0  0.0  0.0  234303  \n",
       "1123929  0.0  0.0  0.0        0.0    0.0  0.0  0.0  231865  \n",
       "1123930  0.0  0.0  0.0        0.0    0.0  0.0  0.0  231770  \n",
       "1123931  0.0  0.0  0.0        0.0    0.0  0.0  0.0  176078  \n",
       "1123932  0.0  0.0  0.0        0.0    0.0  0.0  0.0  186570  \n",
       "\n",
       "[573 rows x 43 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 병합\n",
    "\n",
    "re = pd.concat([preds for preds in test_df_list]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "re[['target']].reset_index(drop=True).to_csv('../preds/14.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
