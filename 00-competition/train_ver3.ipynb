{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings;warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "fe = fm.FontEntry(\n",
    "    fname=r'/usr/share/fonts/truetype/nanum/NanumGothic.ttf', # ttf 파일이 저장되어 있는 경로\n",
    "    name='NanumBarunGothic')                        # 이 폰트의 원하는 이름 설정\n",
    "fm.fontManager.ttflist.insert(0, fe)              # Matplotlib에 폰트 추가\n",
    "plt.rcParams.update({'font.size': 10, 'font.family': 'NanumBarunGothic'}) # 폰트 설정\n",
    "plt.rc('font', family='NanumBarunGothic')\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, QuantileTransformer, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data'\n",
    "train_path = f'{data_path}/new/new_train_ver3.csv'\n",
    "test_path  = f'{data_path}/new/new_test_ver3.csv'\n",
    "\n",
    "train_data = pd.read_csv(train_path)\n",
    "test_data = pd.read_csv(test_path)\n",
    "print('Train data shape : ', train_data.shape, 'Test data shape : ', test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test 구분을 위한 칼럼 생성.\n",
    "train_data['is_test'] = 0\n",
    "test_data['is_test'] = 1\n",
    "data = pd.concat([train_data, test_data]) # 하나의 데이터로 합친다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gus = list(data['구'].unique())\n",
    "print(gus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['아파트명', '계약년월','k-건설사(시공사)', 'k-시행사', '경비비관리형태', '세대전기계약방법', '청소비관리형태', '건축년도',\n",
    "                          'k-복도유형', 'k-난방방식', 'k-전체동수', 'k-전체세대수', 'k-주거전용면적', 'k-관리비부과면적', '부동산유형', '분양형태', 'k-관리방식'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 범주형 변수 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_encode = ['구', '동', '분양형태', '부동산유형', 'k-관리방식', 'k-난방방식', 'k-복도유형']\n",
    "columns_to_encode = ['구', '동']\n",
    "for column in columns_to_encode:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 수치형 변수 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['전용면적'] = np.log(data['전용면적'])\n",
    "\n",
    "private_area_scaler = MinMaxScaler()\n",
    "data['전용면적_minmax'] = private_area_scaler.fit_transform(data['전용면적'].values.reshape(-1, 1))\n",
    "\n",
    "plt.hist(data['전용면적_minmax'], bins=10, edgecolor='k', alpha=0.7)\n",
    "plt.title('Distribution of 전용면적_minmax')\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_gap_scaler = MinMaxScaler()\n",
    "\n",
    "data['건축년도-계약년도'] = year_gap_scaler .fit_transform(data[['건축년도-계약년도']])\n",
    "print(data['건축년도-계약년도'].min(), data['건축년도-계약년도'].max())\n",
    "\n",
    "plt.hist(data['건축년도-계약년도'], bins=10, edgecolor='k', alpha=0.7)\n",
    "plt.title('Distribution')\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt = QuantileTransformer(output_distribution='normal')\n",
    "data['층_qt'] = qt.fit_transform(data[['층']])\n",
    "print(data['층_qt'].min(), data['층_qt'].max())\n",
    "\n",
    "plt.hist(data['층_qt'], bins=10, edgecolor='k', alpha=0.7)\n",
    "plt.title('Distribution of 층 (Quantile Transformed)')\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "data['좌표X'] = scaler.fit_transform(data[['좌표X']])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data['좌표Y'] = scaler.fit_transform(data[['좌표Y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data[data['is_test'] == 0]\n",
    "test_df = data[data['is_test'] == 1]\n",
    "\n",
    "train_df = train_df.drop(columns=['is_test'])\n",
    "test_df = test_df.drop(columns=['is_test', 'target'])\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "gu_groups = train_df.groupby('구')\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'metric': 'rmse',\n",
    "    'subsample': 0.8, \n",
    "    'num_leaves': 127, \n",
    "    'n_estimators': 1000, \n",
    "    'min_child_samples': 30, \n",
    "    'learning_rate': 0.1, \n",
    "    'feature_fraction': 0.7, \n",
    "    'colsample_bytree': 0.7, \n",
    "    'bagging_freq': 1, \n",
    "    'bagging_fraction': 0.7,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "num_boost_round = 100000\n",
    "for gu, group_data in gu_groups:\n",
    "    print(f\"Training model for '구': {gus[gu]}\")\n",
    "    \n",
    "    X = group_data.drop(columns=['target', '구'])\n",
    "    y = np.log(group_data['target'])\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    train_dataset = lgb.Dataset(X_train, label=y_train)\n",
    "    val_dataset = lgb.Dataset(X_val, label=y_val, reference=train_dataset)\n",
    "    \n",
    "    model = lgb.train(params, \n",
    "                      train_dataset, \n",
    "                      valid_sets=[train_dataset, val_dataset],\n",
    "                      num_boost_round=num_boost_round,\n",
    "                      callbacks=[lgb.early_stopping(stopping_rounds=10), lgb.log_evaluation(period=10)])\n",
    "    \n",
    "    models[gu] = model\n",
    "\n",
    "print(\"All models trained successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증 단계\n",
    "total_val_rmse = 0\n",
    "for gu, group_data in gu_groups:\n",
    "    X = group_data.drop(columns=['target', '구'])\n",
    "    y = (group_data['target'])\n",
    "    \n",
    "    _, X_val, _, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model = models[gu]\n",
    "    y_pred_log = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "    y_pred = np.exp(y_pred_log)  # 로그 변환을 원래 값으로 복원\n",
    "    \n",
    "    rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "    total_val_rmse += rmse\n",
    "    print(f\"Validation RMSE for '구' {gus[gu]}: {rmse}\")\n",
    "\n",
    "average_val_rmse = total_val_rmse / len(gu_groups)\n",
    "print(f\"Average Validation RMSE: {average_val_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 단계\n",
    "test_preds = []\n",
    "for gu, model in models.items():\n",
    "    test_group = test_df[test_df['구'] == gu]\n",
    "    if not test_group.empty:\n",
    "        X_test = test_group.drop(columns=['구'])\n",
    "        test_pred_log = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "        test_pred = np.exp(test_pred_log)  # 로그 변환을 원래 값으로 복원\n",
    "        test_preds.extend(test_pred)\n",
    "\n",
    "test_pred_df = pd.DataFrame({'target': test_preds})\n",
    "test_pred_df['target'] = test_pred_df['target'].round().astype(int)\n",
    "\n",
    "print(test_pred_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 저장 (필요 시)\n",
    "test_pred_df.to_csv('./my_submission.csv', index=True)\n",
    "print('Predictions saved.')\n",
    "\n",
    "output_path = './output.csv'\n",
    "output_df = pd.read_csv(output_path)\n",
    "\n",
    "# 비교할 예측값 가져오기\n",
    "output_pred = output_df['target']\n",
    "\n",
    "# 두 예측값 간의 RMSE 계산\n",
    "comparison_rmse = mean_squared_error(output_pred, test_pred_df['target'], squared=False)\n",
    "print(f'Comparison RMSE: {comparison_rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
