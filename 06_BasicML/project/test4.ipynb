{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import duckdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import DataStructs, Descriptors, rdFingerprintGenerator\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/pervinco/Datasets/leash-bio\"\n",
    "save_dir = f\"{data_dir}/split_sets\"\n",
    "\n",
    "train_csv = f\"{data_dir}/train.csv\"\n",
    "test_csv = f\"{data_dir}/test.csv\"\n",
    "\n",
    "train_parquet = f\"{data_dir}/train.parquet\"\n",
    "test_parquet = f'{data_dir}/test.parquet'\n",
    "\n",
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect()\n",
    "data = con.query(f\"\"\"(SELECT *\n",
    "                      FROM parquet_scan('{train_parquet}')\n",
    "                      WHERE binds = 0\n",
    "                      ORDER BY random()\n",
    "                      LIMIT 100000)\n",
    "                      UNION ALL\n",
    "                      (SELECT *\n",
    "                      FROM parquet_scan('{train_parquet}')\n",
    "                      WHERE binds = 1\n",
    "                      ORDER BY random()\n",
    "                      LIMIT 100000)\"\"\").df()\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['molecule'] = data['molecule_smiles'].apply(Chem.MolFromSmiles) ## 문자열 화학식을 rdkit 객체로 변환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpg = rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=2048)\n",
    "\n",
    "def compute_fingerprint(mol):\n",
    "    if mol is None:\n",
    "        return None\n",
    "    return fpg.GetFingerprint(mol)\n",
    "\n",
    "data['fingerprints'] = data['molecule'].apply(compute_fingerprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_features(mol):\n",
    "    features = {}\n",
    "    features['MolWeight'] = Descriptors.ExactMolWt(mol)\n",
    "    features['LogP'] = Descriptors.MolLogP(mol)\n",
    "    features['HBondDonor'] = Descriptors.NumHDonors(mol)\n",
    "    features['HBondAcceptor'] = Descriptors.NumHAcceptors(mol)\n",
    "    features['RotatableBonds'] = Descriptors.NumRotatableBonds(mol)\n",
    "    features['TPSA'] = Descriptors.TPSA(mol)\n",
    "    features['AromaticRings'] = Descriptors.NumAromaticRings(mol)\n",
    "    features['HeteroAtoms'] = Descriptors.NumHeteroatoms(mol)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['features'] = data['molecule'].apply(calculate_features)\n",
    "features_df = data['features'].apply(pd.Series)\n",
    "data = pd.concat([data, features_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "feature_columns = ['MolWeight', 'LogP', 'HBondDonor', 'HBondAcceptor', 'RotatableBonds', 'TPSA', 'AromaticRings', 'HeteroAtoms']\n",
    "feature_data = data[feature_columns].dropna().values\n",
    "scaler.fit(feature_data)\n",
    "normalized_features = scaler.transform(feature_data)\n",
    "\n",
    "for i, col in enumerate(feature_columns):\n",
    "    data[col] = normalized_features[:, i]\n",
    "\n",
    "def combine_features(row):\n",
    "    fingerprint = row['fingerprints']\n",
    "    additional_features = row[feature_columns].values\n",
    "    if fingerprint is None or additional_features is None:\n",
    "        return None\n",
    "    \n",
    "    fingerprint_array = np.array(fingerprint)\n",
    "    combined_features = np.concatenate((fingerprint_array, additional_features))\n",
    "\n",
    "    return combined_features\n",
    "\n",
    "data['combined_features'] = data.apply(combine_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "protein_encoded = onehot_encoder.fit_transform(data['protein_name'].values.reshape(-1, 1)).astype(np.uint8)\n",
    "protein_columns = onehot_encoder.get_feature_names_out(['protein'])\n",
    "protein_encoded_df = pd.DataFrame(protein_encoded, columns=protein_columns)\n",
    "data = pd.concat([data, protein_encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"./train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = data.dropna(subset=['combined_features', 'binds'])\n",
    "X = np.stack(data_clean['combined_features'].values)\n",
    "y = data_clean['binds'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_numpy_array(explicit_bit_vect):\n",
    "    arr = np.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(explicit_bit_vect, arr)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def calculate_features(mol):\n",
    "    features = {}\n",
    "    features['MolWeight'] = Descriptors.ExactMolWt(mol)\n",
    "    features['LogP'] = Descriptors.MolLogP(mol)\n",
    "    features['HBondDonor'] = Descriptors.NumHDonors(mol)\n",
    "    features['HBondAcceptor'] = Descriptors.NumHAcceptors(mol)\n",
    "    features['RotatableBonds'] = Descriptors.NumRotatableBonds(mol)\n",
    "    features['TPSA'] = Descriptors.TPSA(mol)\n",
    "    features['AromaticRings'] = Descriptors.NumAromaticRings(mol)\n",
    "    features['HeteroAtoms'] = Descriptors.NumHeteroatoms(mol)\n",
    "    return features\n",
    "\n",
    "\n",
    "def compute_fingerprint(mol):\n",
    "    if mol is None:\n",
    "        return None\n",
    "    return fpg.GetFingerprint(mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 1000\n",
    "submission_chunks = []\n",
    "fpg = rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=2048)\n",
    "\n",
    "for chunk in pd.read_csv(test_csv, chunksize=chunk_size):\n",
    "    chunk['molecule'] = chunk['molecule_smiles'].apply(Chem.MolFromSmiles)\n",
    "    chunk['fingerprints'] = chunk['molecule'].apply(compute_fingerprint)\n",
    "    chunk['features'] = chunk['molecule'].apply(calculate_features)\n",
    "    \n",
    "    features_df = chunk['features'].apply(pd.Series)\n",
    "    chunk = pd.concat([chunk, features_df], axis=1)    \n",
    "    normalized_features = scaler.transform(chunk[feature_columns])\n",
    "    \n",
    "    for i, col in enumerate(feature_columns):\n",
    "        chunk[col] = normalized_features[:, i]\n",
    "    \n",
    "    def combine_features(row):\n",
    "        fingerprint = row['fingerprints']\n",
    "        additional_features = row[feature_columns].values\n",
    "        if fingerprint is None or additional_features is None:\n",
    "            return None\n",
    "        fingerprint_array = np.array(fingerprint)\n",
    "        combined_features = np.concatenate((fingerprint_array, additional_features))\n",
    "        return combined_features\n",
    "\n",
    "    chunk['combined_features'] = chunk.apply(combine_features, axis=1)\n",
    "    \n",
    "    chunk = chunk.dropna(subset=['combined_features'])\n",
    "    X_test_final = np.stack(chunk['combined_features'].values)\n",
    "    \n",
    "    y_test_pred = model.predict(X_test_final)\n",
    "    chunk['binds_pred'] = y_test_pred\n",
    "    \n",
    "    submission_chunks.append(chunk[['id', 'binds_pred']])\n",
    "\n",
    "submission = pd.concat(submission_chunks, axis=0)\n",
    "submission.to_csv('./submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
