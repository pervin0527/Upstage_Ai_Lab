{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/clovaai/CRAFT-pytorch.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import easyocr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_coordinates_from_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return [line.strip() for line in file if line.strip()]\n",
    "\n",
    "def crop_text_regions(image_path, coordinates):\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    cropped_images = []\n",
    "    for i, coord in enumerate(coordinates):\n",
    "        coord = [int(x) for x in coord.split(',')]\n",
    "        \n",
    "        left = min(coord[0], coord[6])\n",
    "        top = min(coord[1], coord[3])\n",
    "        right = max(coord[2], coord[4])\n",
    "        bottom = max(coord[5], coord[7])\n",
    "        \n",
    "        cropped = image.crop((left, top, right, bottom))\n",
    "        cropped_images.append(cropped)\n",
    "    \n",
    "    return cropped_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = TrOCRProcessor.from_pretrained(\"team-lucid/trocr-small-korean\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"team-lucid/trocr-small-korean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"/home/pervinco/upstage-cv-classification-cv7/dataset/train/0a4adccbb7fe73e0.jpg\"\n",
    "coordinates_file_path = \"/home/pervinco/upstage-cv-classification-cv7/dataset/train_with_bbox/res_0a4adccbb7fe73e0.txt\"\n",
    "\n",
    "coordinates = read_coordinates_from_file(coordinates_file_path)\n",
    "cropped_images = crop_text_regions(image_path, coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pervinco/miniconda3/envs/cls-project/lib/python3.9/site-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'임신'이(가) 추출된 텍스트에 포함되어 있습니다.\n",
      "결합된 텍스트: 환자등록번호 건강보험 임신 진료비 지원 신청 및 임신서 출산 주민등록번호 수진지 《잉부》 전화번호 자 택 휴대전화: 이헤일 요양기관 확인란[ 2016 임신확인 2016 뿐만여정일 다태아구분 □ 삼 태 아 일 태 아 □ 다 태 이 □ 쌍 태아 이상 위에 기록한 사창이 사실임을  확인함 2016 03 년 31 요양문화 미즈메디병원 < 1 1 1 담당의사[면허] 국민건강보험법 시행령 의하여 신청합니다 제 23조에 임신 출산 진료 2016 03 년 31 1 신청인 <세영 또는  인) 전화번호 수진자(잉신부)와의  관계 국민건강보험공단  이사장  귀하 구비세류 수진파【임신부】와의 관계를 입 중 할 수 있는 서류[가족애 신참한 김우이 반 중1 ' 주민등록표등본 가족관계증명서\n"
     ]
    }
   ],
   "source": [
    "extracted_texts = []\n",
    "for i, cropped_image in enumerate(cropped_images):\n",
    "    pixel_values = processor(cropped_image, return_tensors=\"pt\").pixel_values\n",
    "    \n",
    "    generated_ids = model.generate(pixel_values)\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    \n",
    "    # print(f\"텍스트 영역 {i + 1}: {generated_text}\")\n",
    "    # plt.figure()\n",
    "    # plt.imshow(cropped_image)\n",
    "    # plt.show()\n",
    "    \n",
    "    extracted_texts.append(generated_text)\n",
    "\n",
    "combined_text = \" \".join(extracted_texts)\n",
    "\n",
    "search_word = \"임신\"\n",
    "if search_word in combined_text:\n",
    "    print(f\"'{search_word}'이(가) 추출된 텍스트에 포함되어 있습니다.\")\n",
    "else:\n",
    "    print(f\"'{search_word}'이(가) 추출된 텍스트에 포함되어 있지 않습니다.\")\n",
    "\n",
    "print(f\"결합된 텍스트: {combined_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def augment_text_regions(image_path, coordinate_path, output_path, num_augmentations=1):\n",
    "#     image = cv2.imread(image_path)\n",
    "#     coords = read_coordinates_from_file(coordinate_path)\n",
    "\n",
    "#     for i in range(num_augmentations):\n",
    "#         # 랜덤한 회색 배경 생성 (흰색 - 회색 범위)\n",
    "#         background_color = np.random.randint(128, 256)  # 128(회색)에서 255(흰색) 사이의 랜덤 값\n",
    "#         background = np.full(image.shape, background_color, dtype=np.uint8)\n",
    "        \n",
    "#         for coord in coords:\n",
    "#             x1, y1, x2, y2, x3, y3, x4, y4 = map(int, coord.split(','))\n",
    "            \n",
    "#             # 다각형 마스크 생성\n",
    "#             pts = np.array([[x1,y1], [x2,y2], [x3,y3], [x4,y4]], np.int32)\n",
    "#             pts = pts.reshape((-1,1,2))\n",
    "#             mask = np.zeros(image.shape[:2], np.uint8)\n",
    "#             cv2.fillPoly(mask, [pts], (255))\n",
    "\n",
    "#             # 마스크를 사용하여 원본 이미지에서 텍스트 영역 추출\n",
    "#             text_region = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "#             # 배경에 텍스트 영역 붙여넣기\n",
    "#             background = cv2.add(background, text_region)\n",
    "\n",
    "#         output_file = os.path.join(output_path, f\"augmented_{i}.png\")\n",
    "#         cv2.imwrite(output_file, background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment_text_regions(image_path, coordinates_file_path, \"./\", num_augmentations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def augment_text_regions(image_path, coordinate_path, output_path, num_augmentations=1):\n",
    "#     image = cv2.imread(image_path)\n",
    "#     coords = read_coordinates_from_file(coordinate_path)\n",
    "\n",
    "#     for i in range(num_augmentations):\n",
    "#         avg_color = np.mean(image, axis=(0, 1)).astype(int)\n",
    "#         background_color = avg_color + np.random.randint(-20, 21, 3) \n",
    "#         background_color = np.clip(background_color, 0, 255)\n",
    "        \n",
    "#         h, w = image.shape[:2]\n",
    "#         background = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "#         for c in range(3):\n",
    "#             background[:, :, c] = np.linspace(background_color[c] - 30, background_color[c] + 30, w)\n",
    "        \n",
    "#         mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "#         for coord in coords:\n",
    "#             x1, y1, x2, y2, x3, y3, x4, y4 = map(int, coord.split(','))\n",
    "            \n",
    "#             pts = np.array([[x1,y1], [x2,y2], [x3,y3], [x4,y4]], np.int32)\n",
    "#             pts = pts.reshape((-1,1,2))\n",
    "#             cv2.fillPoly(mask, [pts], (255))\n",
    "\n",
    "#         blurred_mask = cv2.GaussianBlur(mask, (21, 21), 0)\n",
    "#         blurred_mask = blurred_mask.reshape(h, w, 1) / 255.0\n",
    "\n",
    "#         text_regions = image * blurred_mask\n",
    "#         background = background * (1 - blurred_mask)\n",
    "#         result = text_regions + background\n",
    "\n",
    "#         output_file = os.path.join(output_path, f\"augmented_{i}.png\")\n",
    "#         cv2.imwrite(output_file, result.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment_text_regions(image_path, coordinates_file_path, \"./\", num_augmentations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
