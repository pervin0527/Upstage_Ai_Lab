{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습 목차\n",
    "* 1. Seq2seq with Attention 구현\n",
    "  * 1-1. 학습 전처리 코드 구현\n",
    "  * 1-2. Encoder 구현\n",
    "  * 1-3. Decoder 구현\n",
    "* 2. Seq2seq 번역 학습\n",
    "* 3. 학습된 Seq2seq 번역 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 번역 데이터셋 다운로드\n",
    "# !echo \"download machine translation dataset from http://www.manythings.org/anki/...\"\n",
    "\n",
    "# !curl -o \"fra-eng.zip\" \"http://www.manythings.org/anki/fra-eng.zip\"\n",
    "\n",
    "# !unzip './fra-eng.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir \"/home/pervinco/Datasets/fra-eng\"\n",
    "# !mv \"fra-eng.zip\" \"/home/pervinco/Datasets/fra-eng/\"\n",
    "# !mv \"fra.txt\" \"/home/pervinco/Datasets/fra-eng/\"\n",
    "# !mv \"_about.txt\" \"/home/pervinco/Datasets/fra-eng/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232736\n",
      "Go.\tVa !\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"/home/pervinco/Datasets/fra-eng/fra.txt\") as f:\n",
    "    lines = f.readlines() \n",
    "\n",
    "\n",
    "print(len(lines))\n",
    "print(lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 import\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import torch\n",
    "import random\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from copy import deepcopy\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from collections import Counter, OrderedDict\n",
    "from torch.nn.utils.rnn import PackedSequence, pack_padded_sequence\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "random.seed(7)\n",
    "%matplotlib inline\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 설정\n",
    "USE_CUDA = torch.cuda.is_available() # 현재 환경에서 CUDA를 사용할 수 있는지 확인\n",
    "\n",
    "# CUDA를 사용할 수 있으면 CUDA tensor를, 그렇지 않으면 CPU tensor를 사용\n",
    "FloatTensor = torch.cuda.FloatTensor if USE_CUDA else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if USE_CUDA else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if USE_CUDA else torch.ByteTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터셋 전처리 코드 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### getBatch 함수 구현\n",
    "\n",
    "`getBatch` 함수는 주어진 `train_data`에서 무작위로 선택된 배치 (batch)를 생성하는 역할을 합니다. 이 함수는 다음과 같은 과정을 거쳐 배치를 생성합니다:\n",
    "\n",
    "- `train_data`를 무작위로 섞습니다\n",
    "- `sindex`와 `eindex` 변수를 사용하여 `train_data`에서 배치를 추출합니다. `sindex`는 시작 인덱스를 나타내고, `eindex`는 끝 인덱스를 나타냅니다\n",
    "- `eindex`를 `batch_size`만큼 증가시키고, `sindex`를 이전 `eindex` 값으로 업데이트합니다\n",
    "- `eindex`가 `train_data`의 길이보다 작은 동안 위 과정을 반복하며 배치를 생성합니다\n",
    "- `eindex`가 `train_data`의 길이보다 크거나 같아지면, 남은 데이터를 마지막 배치로 생성합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치 데이터를 가져오는 함수\n",
    "def getBatch(batch_size, train_data):\n",
    "    random.shuffle(train_data) # 데이터를 무작위로 섞음\n",
    "    sindex = 0 # 시작 인덱스\n",
    "    eindex = batch_size # 끝 인덱스\n",
    "    while eindex < len(train_data): # 끝 인덱스가 데이터의 길이보다 작을 동안\n",
    "        batch = train_data[sindex: eindex] # 배치 데이터를 가져옴\n",
    "        temp = eindex\n",
    "        eindex = eindex + batch_size # 끝 인덱스를 배치 크기만큼 증가\n",
    "        sindex = temp # 시작 인덱스를 이전 끝 인덱스로 업데이트\n",
    "        yield batch # 배치 데이터 반환\n",
    "\n",
    "    if eindex >= len(train_data): # 끝 인덱스가 데이터의 길이보다 크거나 같으면\n",
    "        batch = train_data[sindex:] # 남은 데이터를 배치로 만듦\n",
    "        yield batch # 배치 데이터 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### pad_to_batch 함수 구현\n",
    "\n",
    "이 함수는 주어진 배치에 패딩을 적용하여 입력 시퀀스와 타겟 시퀀스를 동일한 길이로 만듭니다. 이를 통해 배치 처리를 수행할 수 있습니다\n",
    "\n",
    "함수는 다음 단계를 수행합니다:\n",
    "\n",
    "1. 배치를 길이에 따라 정렬\n",
    "2. 입력 시퀀스와 타겟 시퀀스의 최대 길이를 계산\n",
    "3. 각 시퀀스에 패딩을 적용하여 동일한 길이로 변환\n",
    "4. 입력 변수와 타겟 변수를 생성하고, 각 시퀀스의 실제 길이를 계산\n",
    "5. 입력 변수, 타겟 변수, 입력 길이, 타겟 길이를 반환\n",
    "\n",
    "이 함수를 사용하면, 입력 시퀀스와 타겟 시퀀스를 동일한 길이로 만들어 배치 처리를 수행할 수 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시퀀스를 배치로 변환하는 함수\n",
    "def pad_to_batch(batch, x_to_ix, y_to_ix):\n",
    "    sorted_batch =  sorted(batch, key=lambda b:b[0].size(1), reverse=True) # 길이에 따라 배치를 정렬\n",
    "    x,y = list(zip(*sorted_batch)) # 입력과 출력을 분리\n",
    "    max_x = max([s.size(1) for s in x]) # 입력의 최대 길이\n",
    "    max_y = max([s.size(1) for s in y]) # 출력의 최대 길이\n",
    "    x_p, y_p = [], [] # 패딩을 적용할 입력과 출력 리스트\n",
    "\n",
    "    for i in range(len(batch)):\n",
    "        if x[i].size(1) < max_x: # 입력의 길이가 최대 길이보다 작으면\n",
    "            # 패딩 토큰을 추가하여 최대 길이에 맞춤\n",
    "            x_p.append(torch.cat([x[i], Variable(LongTensor([x_to_ix['<PAD>']] * (max_x - x[i].size(1)))).view(1, -1)], 1))\n",
    "        else:\n",
    "            x_p.append(x[i]) # 그렇지 않으면 그대로 사용\n",
    "        if y[i].size(1) < max_y: # 출력의 길이가 최대 길이보다 작으면\n",
    "            # 패딩 토큰을 추가하여 최대 길이에 맞춤\n",
    "            y_p.append(torch.cat([y[i], Variable(LongTensor([y_to_ix['<PAD>']] * (max_y - y[i].size(1)))).view(1, -1)], 1))\n",
    "        else:\n",
    "            y_p.append(y[i]) # 그렇지 않으면 그대로 사용\n",
    "\n",
    "    input_var = torch.cat(x_p) # 입력 변수\n",
    "    target_var = torch.cat(y_p) # 목표 변수\n",
    "    input_len = [list(map(lambda s: s ==0, t.data)).count(False) for t in input_var] # 입력의 실제 길이\n",
    "    target_len = [list(map(lambda s: s ==0, t.data)).count(False) for t in target_var] # 출력의 실제 길이\n",
    "\n",
    "    return input_var, target_var, input_len, target_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 데이터셋 load 및 preprocess 코드 구현\n",
    "\n",
    "이 코드에서는 문자열을 처리하고 정규화하는 두 가지 함수를 구현합니다.\n",
    "\n",
    "1. `unicode_to_ascii` 함수는 유니코드 문자열을 ASCII 문자열로 변환합니다. 이 함수는 주어진 유니코드 문자열에서 각 문자를 순회하며, 해당 문자가 비수치형(non-mark)인 경우에만 ASCII 문자열에 추가합니다. 이를 통해 유니코드 문자열이 ASCII 문자열로 변환됩니다\n",
    "\n",
    "<br>\n",
    "\n",
    "2. `normalize_string` 함수는 문자열을 소문자로 변환하고, 공백을 제거하며, 영문자와 구두점 이외의 문자를 제거합니다. 이 함수는 다음과 같은 순서로 작동합니다:\n",
    "* 문자열을 소문자로 변환하고 양쪽 공백을 제거\n",
    "* 구두점 앞뒤에 공백을 추가하여 구두점과 단어가 구분되도록 함\n",
    "* 영문자, 구두점 이외의 문자를 제거\n",
    "* 연속된 공백을 하나의 공백으로 치환하고, 문자열의 앞뒤 공백을 제거\n",
    "\n",
    "이 두 함수를 사용하여 문자열을 처리하고 정규화할 수 있습니다. 정규화된 데이터는 모델의 입력 데이터를 적절한 형태로 사용됩니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유니코드 문자열을 아스키 문자열로 변환하는 함수\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# 문자열을 정규화하는 함수\n",
    "def normalize_string(s):\n",
    "    s = unicode_to_ascii(s.lower().strip())\n",
    "    s = re.sub(r\"([,.!?])\", r\" \\1 \", s)\n",
    "    s = re.sub(r\"[^a-zA-Z,.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 데이터 전처리 및 필터링\n",
    "\n",
    "이 코드에서는 기계 번역을 위한 데이터 전처리와 필터링을 수행합니다\n",
    "\n",
    "먼저, 최소 및 최대 길이를 설정합니다. 이를 통해 너무 짧거나 너무 긴 문장을 제외할 수 있습니다\n",
    "\n",
    "- `MIN_LENGTH` : 문장의 최소 길이를 지정합니다. 여기서는 3으로 설정했습니다\n",
    "- `MAX_LENGTH` : 문장의 최대 길이를 지정합니다. 여기서는 25로 설정했습니다\n",
    "\n",
    "그런 다음 빈 리스트 `X_r`와 `y_r`을 생성합니다. 이 리스트들은 각각 원문(source)과 번역문(target)의 문장을 저장할 것입니다\n",
    "\n",
    "`corpus`의 각 문장에 대해 다음 작업을 수행합니다:\n",
    "\n",
    "1. 원문(source)과 번역문(target)을 분리합니다. 이 경우에는 탭(\\t)으로 구분되어 있습니다\n",
    "2. 원문과 번역문이 비어 있지 않은지 확인합니다. 비어 있다면 해당 문장을 건너뜁니다\n",
    "3. 원문과 번역문을 정규화(normalize)하고 공백으로 분리합니다\n",
    "4. 원문과 번역문의 길이가 설정한 최소 및 최대 길이 사이에 있는지 확인합니다 만약 그렇다면, `X_r`과 `y_r`에 각각 원문과 번역문을 추가합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n",
      "Go.\tVa !\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 프랑스어-영어 병렬 코퍼스를 읽어옴\n",
    "corpus = open('/home/pervinco/Datasets/fra-eng/fra.txt', 'r', encoding='utf-8').readlines()\n",
    "\n",
    "corpus = corpus[:30000] # 3만개의 데이터만 사용\n",
    "\n",
    "print(len(corpus))\n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29444 29444\n",
      "['i', 'see', '.'] ['je', 'comprends', '.']\n"
     ]
    }
   ],
   "source": [
    "MIN_LENGTH = 3\n",
    "MAX_LENGTH = 25\n",
    "\n",
    "X_r, y_r = [], [] # 원시 데이터를 저장할 빈 리스트 생성\n",
    "\n",
    "# 데이터 전처리\n",
    "for parallel in corpus:\n",
    "    so,ta,_ = parallel[:-1].split('\\t') # 입력 문장과 출력 문장을 분리\n",
    "    if so.strip() == \"\" or ta.strip() == \"\": # 만약 입력 문장이나 출력 문장이 비어있으면 무시\n",
    "        continue\n",
    "\n",
    "    normalized_so = normalize_string(so).split() # 입력 문장을 정규화하고 단어 단위로 분리\n",
    "    normalized_ta = normalize_string(ta).split() # 출력 문장을 정규화하고 단어 단위로 분리\n",
    "\n",
    "    # 입력 문장과 출력 문장의 길이가 최소 길이와 최대 길이 사이에 있으면 리스트에 추가\n",
    "    if len(normalized_so) >= MIN_LENGTH and len(normalized_so) <= MAX_LENGTH \\\n",
    "    and len(normalized_ta) >= MIN_LENGTH and len(normalized_ta) <= MAX_LENGTH:\n",
    "        X_r.append(normalized_so)\n",
    "        y_r.append(normalized_ta)\n",
    "\n",
    "print(len(X_r), len(y_r)) # 입력 문장과 출력 문장의 개수 출력\n",
    "print(X_r[0], y_r[0]) # 첫 번째 입력 문장과 출력 문장 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 소스 및 타겟 단어장 (Vocabulary) 생성\n",
    "소스와 타겟 데이터를 사용하여 각각의 단어 기반의 단어장 (Vocabulary)을 생성합니다. 이를 위해 먼저 소스와 타겟 데이터를 flatten한 후, 중복된 단어를 제거하기 위해 `set()` 함수를 사용합니다. 이렇게 생성된 단어장은 각각 `source_vocab`과 `target_vocab`에 저장됩니다\n",
    "\n",
    "`len(source_vocab)`와 `len(target_vocab)`를 출력하여 각각의 단어장에 포함된 단어의 개수를 확인할 수 있습니다\n",
    "\n",
    "##### 인덱스 매핑 생성\n",
    "단어장을 기반으로 단어와 인덱스 사이의 매핑을 생성합니다. 이를 위해 먼저 `<PAD>`, `<UNK>`, `<s>`, `</s>`와 같은 특수 토큰을 포함한 초기 매핑 딕셔너리를 생성합니다. 각각의 특수 토큰은 다음과 같은 역할을 합니다:\n",
    "- `<PAD>` : 패딩(Padding) 토큰으로, 배치 처리를 위해 서로 다른 길이의 시퀀스를 동일한 길이로 맞추기 위해 사용\n",
    "- `<UNK>` : 알 수 없는(Unknown) 토큰으로, 단어장에 없는 단어를 대체하는 데 사용\n",
    "- `<s>` : 시작(Start) 토큰으로, 디코더의 입력 시퀀스의 시작을 나타냄\n",
    "- `</s>` : 종료(End) 토큰으로, 디코더의 출력 시퀀스의 종료를 나타냄\n",
    "\n",
    "`source2index`와 `target2index` 딕셔너리에 각각 소스와 타겟 단어장의 단어들을 추가합니다. 이 때, 이미 딕셔너리에 존재하는 단어는 추가하지 않습니다.\n",
    "\n",
    "마지막으로, `index2source`와 `index2target` 딕셔너리를 생성하여 인덱스와 단어 사이의 역매핑을 구성합니다. 이렇게 생성된 매핑 딕셔너리들은 추후에 데이터 전처리 및 결과 해석에 사용됩니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4269 7409\n"
     ]
    }
   ],
   "source": [
    "# 소스와 타겟 어휘집을 생성\n",
    "source_vocab = list(set(flatten(X_r))) # 소스 어휘집 생성\n",
    "target_vocab = list(set(flatten(y_r))) # 타겟 어휘집 생성\n",
    "print(len(source_vocab), len(target_vocab)) # 소스 어휘집과 타겟 어휘집의 크기 출력\n",
    "\n",
    "# 소스와 타겟 어휘집을 인덱스로 변환하는 딕셔너리 생성\n",
    "source2index = {'<PAD>': 0, '<UNK>': 1, '<s>': 2, '</s>': 3} # 소스 어휘집을 인덱스로 변환하는 딕셔너리 초기화\n",
    "for vo in source_vocab: # 소스 어휘집의 각 단어에 대해\n",
    "    if source2index.get(vo) is None: # 해당 단어가 딕셔너리에 없다면\n",
    "        source2index[vo] = len(source2index) # 딕셔너리에 추가\n",
    "index2source = {v:k for k, v in source2index.items()} # 인덱스를 소스 어휘집으로 변환하는 딕셔너리 생성\n",
    "\n",
    "target2index = {'<PAD>': 0, '<UNK>': 1, '<s>': 2, '</s>': 3} # 타겟 어휘집을 인덱스로 변환하는 딕셔너리 초기화\n",
    "for vo in target_vocab: # 타겟 어휘집의 각 단어에 대해\n",
    "    if target2index.get(vo) is None: # 해당 단어가 딕셔너리에 없다면\n",
    "        target2index[vo] = len(target2index) # 딕셔너리에 추가\n",
    "index2target = {v:k for k, v in target2index.items()} # 인덱스를 타겟 어휘집으로 변환하는 딕셔너리 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### prepare_sequence 함수와 데이터 전처리\n",
    "\n",
    "- `prepare_sequence` 함수는 주어진 시퀀스를 인덱스로 변환하는 함수입니다. 이 함수는 seq(단어 시퀀스)와 to_index(단어를 인덱스로 매핑하는 딕셔너리)를 입력으로 받아, 시퀀스의 각 단어를 해당 인덱스로 변환하고, 이를 PyTorch의 Variable로 변환하여 반환합니다. 만약 단어가 to_index 딕셔너리에 없으면, \"<UNK>\"(unknown) 토큰의 인덱스로 변환합니다\n",
    "\n",
    "- 이후, 전처리된 원문(X_r)과 번역문(y_r) 데이터를 사용하여, 각 시퀀스의 끝에 \"</s>\"(end of sentence) 토큰을 추가하고, prepare_sequence 함수를 사용하여 인덱스로 변환한 후, 이를 PyTorch의 Variable로 변환합니다. 이렇게 변환된 데이터를 X_p와 y_p 리스트에 저장합니다\n",
    "\n",
    "- 마지막으로, 변환된 원문(X_p)과 번역문(y_p) 데이터를 zip 함수를 사용하여 쌍으로 묶어 train_data 리스트에 저장합니다. 이렇게 생성된 train_data는 원문과 번역문의 쌍으로 이루어진 학습 데이터입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([[2633, 2184, 2358,    3]], device='cuda:0'),\n",
       "  tensor([[1409, 2076, 4722,    3]], device='cuda:0')),\n",
       " (tensor([[2633,   32, 2358,    3]], device='cuda:0'),\n",
       "  tensor([[2320, 5337, 4722,    3]], device='cuda:0')),\n",
       " (tensor([[2633, 2497,  137,    3]], device='cuda:0'),\n",
       "  tensor([[2320, 1550, 6190, 1942,    3]], device='cuda:0')),\n",
       " (tensor([[2633, 2497,  137,    3]], device='cuda:0'),\n",
       "  tensor([[1409, 1726, 1550,  833, 1942,    3]], device='cuda:0')),\n",
       " (tensor([[2633, 2497, 2358,    3]], device='cuda:0'),\n",
       "  tensor([[2320, 1550, 6190, 4722,    3]], device='cuda:0'))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시퀀스를 준비하는 함수\n",
    "def prepare_sequence(seq, to_index):\n",
    "    idxs = list(map(lambda w: to_index[w] if to_index.get(w) is not None else to_index[\"<UNK>\"], seq)) # 시퀀스를 인덱스로 변환\n",
    "    return Variable(LongTensor(idxs)) # 변환된 인덱스를 텐서로 변환\n",
    "\n",
    "X_p, y_p = [], []\n",
    "\n",
    "for so, ta in zip(X_r, y_r): # 각 소스와 타겟에 대해\n",
    "    X_p.append(prepare_sequence(so + ['</s>'], source2index).view(1, -1)) # 소스 시퀀스를 인덱스로 변환하여 리스트에 추가\n",
    "    y_p.append(prepare_sequence(ta + ['</s>'], target2index).view(1, -1)) # 타겟 시퀀스를 인덱스로 변환하여 리스트에 추가\n",
    "\n",
    "train_data = list(zip(X_p, y_p)) # 소스와 타겟 시퀀스를 튜플로 묶어 학습 데이터 생성\n",
    "\n",
    "train_data[:5] # 학습 데이터의 첫 5개를 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### pack_padded_sequence와 pad_packed_sequence\n",
    "\n",
    "`torch.nn.utils.rnn.pack_padded_sequence`와 `torch.nn.utils.rnn.pad_packed_sequence`는 PyTorch에서 제공하는 유틸리티 함수로, 패딩된 시퀀스를 처리할 때 사용됩니다\n",
    "\n",
    "- `pack_padded_sequence` : 패딩된 시퀀스를 입력으로 받아, 패딩되지 않은 시퀀스로 변환합니다. 이 함수는 RNN 계열 모델에 입력하기 전에 사용되며, RNN 계열 모델이 패딩된 부분을 처리하지 않도록 도와줍니다. 이 함수는 입력 시퀀스와 각 시퀀스의 실제 길이를 인자로 받습니다\n",
    "\n",
    "- `pad_packed_sequence` : 패딩되지 않은 시퀀스를 입력으로 받아, 패딩된 시퀀스로 변환합니다. 이 함수는 RNN 계열 모델의 출력을 처리할 때 사용되며, 패딩된 시퀀스 형태로 복원해줍니다.\n",
    "\n",
    "\n",
    "##### nn.Embedding\n",
    "\n",
    "`nn.Embedding`은 PyTorch에서 제공하는 임베딩 레이어로, 정수 인코딩된 단어를 벡터 형태로 변환하는 역할을 합니다. 이 레이어는 단어 임베딩을 학습하고 저장하는 기능을 수행합니다\n",
    "\n",
    "`nn.Embedding`의 초기화(`__init__`) 인자는 다음과 같습니다:\n",
    "\n",
    "- `num_embeddings` : 임베딩 레이어에 저장할 단어의 개수를 지정합니다. 이는 단어장의 크기와 동일해야 합니다\n",
    "\n",
    "- `embedding_dim` : 임베딩 벡터의 차원을 지정합니다. 이는 각 단어의 임베딩 벡터의 크기를 의미합니다\n",
    "\n",
    "임베딩 레이어는 정수 인코딩된 단어를 입력으로 받아 해당 단어의 임베딩 벡터를 반환합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encoder 구현\n",
    "\n",
    "Encoder 클래스는 Seq2Seq 모델의 인코더 부분을 구현한 클래스입니다. 인코더는 입력 시퀀스를 받아서 고정된 크기의 은닉 상태 벡터로 변환하는 역할을 합니다. 이 클래스는 GRU를 사용하여 구해봅시다\n",
    "\n",
    "`Encoder` 클래스의 초기화 인자는 다음과 같습니다:\n",
    "\n",
    "- `input_size` : 인코더의 입력 차원의 크기를 지정합니다. 이는 입력 단어의 원-핫 벡터 크기와 동일합니다\n",
    "\n",
    "- `embedding_size` : 임베딩 레이어의 출력 차원의 크기를 지정합니다. 이는 각 단어의 임베딩 벡터의 크기를 의미합니다\n",
    "\n",
    "- `hidden_size` : GRU 모듈의 은닉 상태의 크기를 지정합니다. 이는 GRU의 은닉층의 뉴런 수를 의미합니다\n",
    "\n",
    "- `n_layers` : GRU 셀을 몇 층으로 쌓을 것인지를 결정합니다. 기본값은 1입니다\n",
    "\n",
    "- `bidirec` : 양방향 GRU를 사용할지 여부를 결정하는 옵션입니다. 기본값은 False입니다. True로 설정하면 양방향 GRU가 사용됩니다\n",
    "\n",
    "<br>\n",
    "\n",
    "`forward` 메서드는 인코더의 순전파를 구현한 메서드입니다. 이 메서드는 다음과 같은 인자를 받습니다:\n",
    "\n",
    "- `inputs` : 입력 시퀀스의 배치를 나타내는 텐서입니다. 형태는 (배치 크기, 시퀀스 길이)입니다\n",
    "\n",
    "- `input_lengths` : 입력 시퀀스의 실제 길이를 나타내는 리스트입니다. 이는 패딩된 시퀀스를 처리하기 위해 사용됩니다\n",
    "\n",
    "`forward` 메서드는 입력 시퀀스를 임베딩 레이어를 통과시키고, 패딩된 시퀀스를 처리하기 위해 패킹 및 언패킹을 수행합니다. 그 후, GRU를 통과시켜 출력과 은닉 상태를 얻습니다. 마지막으로 은닉 상태를 반환합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 클래스 정의\n",
    "class Encoder(nn.Module):\n",
    "    # 초기화 함수\n",
    "    def __init__(self, input_size, embedding_size,hidden_size, n_layers=1,bidirec=False):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        # 인코더의 입력 크기, 은닉층 크기, 레이어 수 설정\n",
    "        # input_size: 입력 데이터의 차원 수\n",
    "        # hidden_size: 은닉층의 노드 수\n",
    "        # n_layers: 은닉층의 수\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # 임베딩 레이어를 정의\n",
    "        # 임베딩 레이어는 입력 데이터를 임베딩 벡터로 변환하는 역할을 함\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "\n",
    "        # 양방향 GRU를 사용할지 여부에 따라 GRU 레이어\n",
    "        # 양방향 GRU를 사용하면, n_direction을 2로 설정하고, 그렇지 않으면 1로 설정\n",
    "        if bidirec:\n",
    "            self.n_direction = 2\n",
    "            self.gru = nn.GRU(embedding_size, hidden_size, n_layers, batch_first=True, bidirectional=True)\n",
    "        else:\n",
    "            self.n_direction = 1\n",
    "            self.gru = nn.GRU(embedding_size, hidden_size, n_layers, batch_first=True)\n",
    "\n",
    "    # 은닉 상태를 초기화하는 함수\n",
    "    # 입력의 크기에 따라 0으로 채워진 텐서를 생성하고, CUDA를 사용할 경우 GPU로 이동\n",
    "    def init_hidden(self, inputs):\n",
    "        hidden = Variable(torch.zeros(self.n_layers * self.n_direction, inputs.size(0), self.hidden_size))\n",
    "        return hidden.cuda() if USE_CUDA else hidden\n",
    "\n",
    "    # 가중치를 초기화하는 함수\n",
    "    # 임베딩 레이어와 GRU 레이어의 가중치를 xavier_uniform 방식으로 초기화\n",
    "    def init_weight(self):\n",
    "        self.embedding.weight = nn.init.xavier_uniform(self.embedding.weight)\n",
    "        self.gru.weight_hh_l0 = nn.init.xavier_uniform(self.gru.weight_hh_l0)\n",
    "        self.gru.weight_ih_l0 = nn.init.xavier_uniform(self.gru.weight_ih_l0)\n",
    "\n",
    "    # 순전파 정의\n",
    "    # 입력과 입력 길이를 받아서 임베딩 레이어와 GRU 레이어를 통과\n",
    "    # GRU 레이어의 출력과 은닉 상태를 반환\n",
    "    def forward(self, inputs, input_lengths):\n",
    "        hidden = self.init_hidden(inputs)\n",
    "\n",
    "        embedded = self.embedding(inputs)\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths, batch_first=True)\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
    "\n",
    "        # 레이어 수가 1보다 크면, 마지막 두 레이어의 은닉 상태를 사용하고, 그렇지 않으면 마지막 레이어의 은닉 상태를 사용\n",
    "        if self.n_layers > 1:\n",
    "            if self.n_direction == 2:\n",
    "                hidden = hidden[-2:]\n",
    "            else:\n",
    "                hidden = hidden[-1]\n",
    "\n",
    "        return outputs, torch.cat([h for h in hidden], 1).unsqueeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Decoder는 Seq2Seq 모델의 출력 시퀀스를 생성하는 부분입니다. 주어진 인코더의 출력과 이전 시점의 출력을 기반으로 다음 시점의 출력을 생성합니다. 이 과정에서 어텐션 메커니즘을 사용하여 입력 시퀀스와 출력 시퀀스 사이의 연관성을 학습합니다\n",
    "\n",
    "아래에서 구현 할 Decoder 클래스는 다음과 같은 구성 요소를 가집니다:\n",
    "\n",
    "- `__init__` : 초기화 함수로, 입력 크기, 임베딩 크기, 은닉 크기, 층의 개수, 드롭아웃 확률 등을 인자로 받습니다\n",
    "- `init_hidden` : 초기 은닉 상태를 생성하는 함수로, 입력 텐서를 인자로 받아 은닉 상태를 초기화합니다\n",
    "- `init_weight` : 가중치를 초기화하는 함수로, Xavier 초기화 방법을 사용하여 임베딩, GRU, 선형, 어텐션 계층의 가중치를 초기화합니다\n",
    "- `Attention` : 어텐션 메커니즘을 구현하는 함수로, 현재 은닉 상태, 인코더 출력, 인코더 마스킹을 인자로 받아 컨텍스트 벡터와 어텐션 가중치를 반환합니다\n",
    "- `forward` : 디코더의 순전파를 구현하는 함수로, 입력 텐서, 컨텍스트 벡터, 최대 길이, 인코더 출력, 인코더 마스킹, 학습 여부를 인자로 받아 예측된 출력을 반환합니다\n",
    "- `decode` : 주어진 컨텍스트 벡터와 인코더 출력을 사용하여 출력 시퀀스를 생성하는 함수입니다. 이 함수는 디코더의 순전파를 반복적으로 수행하여 출력 시퀀스를 생성하고, 어텐션 가중치를 반환합니다\n",
    "\n",
    "<br>\n",
    "\n",
    "`Attention` 함수는 주어진 현재 은닉 상태와 인코더 출력을 사용하여 어텐션 메커니즘을 구현합니다. 어텐션 메커니즘은 입력 시퀀스와 출력 시퀀스 사이의 연관성을 학습하여, 각 시점에서 어떤 입력 단어에 집중해야 하는지를 결정합니다\n",
    "\n",
    "우리는 Bahdanau Attention을 사용하여 Attention function을 구현하겠습니다\n",
    "\n",
    "어텐션 메커니즘의 수식은 다음과 같습니다:\n",
    "\n",
    "1. 에너지 계산: $e_{ij} = a(s_{i-1}, h_j)$\n",
    "   - $s_{i-1}$: 이전 시점의 디코더 은닉 상태\n",
    "   - $h_j$: 인코더 출력의 j번째 단어에 대한 은닉 상태\n",
    "   - $a$: 어텐션 함수 (여기서는 선형 계층 `self.attn`을 사용)\n",
    "\n",
    "2. 어텐션 가중치 계산: $\\alpha_{ij} = \\frac{\\exp(e_{ij})}{\\sum_{k=1}^T \\exp(e_{ik})}$\n",
    "   - $\\alpha_{ij}$: i번째 디코더 출력과 j번째 인코더 입력 사이의 어텐션 가중치\n",
    "\n",
    "3. 컨텍스트 벡터 계산: $c_i = \\sum_{j=1}^T \\alpha_{ij} h_j$\n",
    "   - $c_i$: i번째 디코더 출력에 대한 컨텍스트 벡터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    # 초기화 함수\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, n_layers=1, dropout_p=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        # 디코더의 은닉층 크기와 레이어 수를 설정\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # 임베딩 레이어를 생성. 입력 크기와 임베딩 크기를 인자로 받음\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        # 드롭아웃 레이어를 생성. 드롭아웃 확률을 인자로 받음\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        # GRU 레이어를 생성. 임베딩 크기 + 은닉층 크기, 은닉층 크기, 레이어 수를 인자로 받음\n",
    "        self.gru = nn.GRU(embedding_size + hidden_size, hidden_size, n_layers, batch_first=True)\n",
    "        # 선형 레이어를 생성. 은닉층 크기 * 2, 입력 크기를 인자로 받음\n",
    "        self.linear = nn.Linear(hidden_size * 2, input_size)\n",
    "        # Attention 레이어를 생성. 은닉층 크기를 인자로 받음\n",
    "        self.attn = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "\n",
    "    # 은닉 상태를 초기화하는 함수\n",
    "    def init_hidden(self,inputs):\n",
    "        # 은닉 상태를 0으로 초기화\n",
    "        hidden = Variable(torch.zeros(self.n_layers, inputs.size(0), self.hidden_size))\n",
    "        # CUDA를 사용할 경우 GPU로 이동\n",
    "        return hidden.cuda() if USE_CUDA else hidden\n",
    "\n",
    "    # 가중치를 초기화하는 함수\n",
    "    def init_weight(self):\n",
    "        # 각 레이어의 가중치를 Xavier 초기화를 사용하여 초기화\n",
    "        self.embedding.weight = nn.init.xavier_uniform(self.embedding.weight)\n",
    "        self.gru.weight_hh_l0 = nn.init.xavier_uniform(self.gru.weight_hh_l0)\n",
    "        self.gru.weight_ih_l0 = nn.init.xavier_uniform(self.gru.weight_ih_l0)\n",
    "        self.linear.weight = nn.init.xavier_uniform(self.linear.weight)\n",
    "        self.attn.weight = nn.init.xavier_uniform(self.attn.weight)\n",
    "\n",
    "    # Attention 메커니즘을 구현하는 함수\n",
    "    def Attention(self, hidden, encoder_outputs, encoder_maskings):\n",
    "        \"\"\"\n",
    "        hidden : 1,B,D\n",
    "        encoder_outputs : B,T,D\n",
    "        encoder_maskings : B,T # ByteTensor\n",
    "        \"\"\"\n",
    "        # hidden의 차원을 변경\n",
    "        hidden = hidden[0].unsqueeze(2)  # (1,B,D) -> (B,D,1)\n",
    "\n",
    "        # encoder_outputs의 크기를 가져옴\n",
    "        batch_size = encoder_outputs.size(0) # B\n",
    "        max_len = encoder_outputs.size(1) # T\n",
    "        # attention 에너지를 계산\n",
    "        energies = self.attn(encoder_outputs.contiguous().view(batch_size * max_len, -1)) # B*T,D -> B*T,D\n",
    "        energies = energies.view(batch_size,max_len, -1) # B,T,D\n",
    "        attn_energies = energies.bmm(hidden).squeeze(2) # B,T,D * B,D,1 --> B,T\n",
    "\n",
    "        # softmax를 사용하여 attention 가중치를 계산\n",
    "        alpha = F.softmax(attn_energies,1) # B,T\n",
    "        alpha = alpha.unsqueeze(1) # B,1,T\n",
    "        # context 벡터를 계산\n",
    "        context = alpha.bmm(encoder_outputs) # B,1,T * B,T,D => B,1,D\n",
    "\n",
    "        return context, alpha\n",
    "\n",
    "# 순전파 함수\n",
    "    def forward(self, inputs, context, max_length, encoder_outputs, encoder_maskings=None, is_training=False):\n",
    "        \"\"\"\n",
    "        inputs : B,1 (LongTensor, 시작 심볼)\n",
    "        context : B,1,D (FloatTensor, 마지막 인코더 은닉 상태)\n",
    "        max_length : int, 디코딩할 최대 길이\n",
    "        encoder_outputs : B,T,D\n",
    "        encoder_maskings : B,T # ByteTensor\n",
    "        is_training : bool, 드롭아웃을 훈련 단계에서만 적용하기 위함\n",
    "        \"\"\"\n",
    "        # 입력 단어의 임베딩을 계산\n",
    "        embedded = self.embedding(inputs)\n",
    "        # 은닉 상태를 초기화\n",
    "        hidden = self.init_hidden(inputs)\n",
    "        # 훈련 단계에서만 드롭아웃 적용\n",
    "        if is_training:\n",
    "            embedded = self.dropout(embedded)\n",
    "\n",
    "        decode = []\n",
    "        # GRU를 적용\n",
    "        for i in range(max_length):\n",
    "            # GRU의 입력으로 embedded와 context를 연결한 것을 사용\n",
    "            _, hidden = self.gru(torch.cat((embedded, context), 2), hidden) # h_t = f(h_{t-1},y_{t-1},c)\n",
    "            # hidden과 context를 연결하여 concated를 생성\n",
    "            concated = torch.cat((hidden, context.transpose(0, 1)), 2) # y_t = g(h_t,y_{t-1},c)\n",
    "            # 선형 레이어를 통해 score를 계산\n",
    "            score = self.linear(concated.squeeze(0))\n",
    "            # score에 softmax를 적용하여 확률 분포를 얻음\n",
    "            softmaxed = F.log_softmax(score,1)\n",
    "            # softmaxed를 decode 리스트에 추가\n",
    "            decode.append(softmaxed)\n",
    "            # softmaxed의 최대값 인덱스를 decoded에 저장\n",
    "            decoded = softmaxed.max(1)[1]\n",
    "            # decoded를 임베딩하여 embedded를 업데이트\n",
    "            embedded = self.embedding(decoded).unsqueeze(1) # y_{t-1}\n",
    "            # 훈련 단계에서만 드롭아웃 적용\n",
    "            if is_training:\n",
    "                embedded = self.dropout(embedded)\n",
    "\n",
    "            # attention을 사용하여 다음 context 벡터를 계산\n",
    "            context, alpha = self.Attention(hidden, encoder_outputs, encoder_maskings)\n",
    "\n",
    "        # decode 리스트를 텐서로 변환\n",
    "        scores = torch.cat(decode, 1)\n",
    "        # scores의 크기를 변경\n",
    "        return scores.view(inputs.size(0) * max_length, -1)\n",
    "\n",
    "    # 디코딩 함수\n",
    "    def decode(self, context, encoder_outputs):\n",
    "        # 디코딩을 시작하는 심볼을 start_decode에 저장\n",
    "        start_decode = Variable(LongTensor([[target2index['<s>']] * 1])).transpose(0, 1)\n",
    "        # start_decode를 임베딩\n",
    "        embedded = self.embedding(start_decode)\n",
    "        # 은닉 상태를 초기화\n",
    "        hidden = self.init_hidden(start_decode)\n",
    "\n",
    "        decodes = []\n",
    "        attentions = []\n",
    "        decoded = embedded\n",
    "        # decoded가 종료 심볼이 될 때까지 반복\n",
    "        while decoded.data.tolist()[0] != target2index['</s>']: # </s>까지\n",
    "            # GRU의 입력으로 embedded와 context를 연결한 것을 사용\n",
    "            _, hidden = self.gru(torch.cat((embedded, context), 2), hidden) # h_t = f(h_{t-1},y_{t-1},c)\n",
    "            # hidden과 context를 연결하여 concated를 생성\n",
    "            concated = torch.cat((hidden, context.transpose(0, 1)), 2) # y_t = g(h_t,y_{t-1},c)\n",
    "            # 선형 레이어를 통해 score를 계산\n",
    "            score = self.linear(concated.squeeze(0))\n",
    "            # score에 softmax를 적용하여 확률 분포를 얻음\n",
    "            softmaxed = F.log_softmax(score,1)\n",
    "            # softmaxed를 decodes 리스트에 추가\n",
    "            decodes.append(softmaxed)\n",
    "            # softmaxed의 최대값 인덱스를 decoded에 저장\n",
    "            decoded = softmaxed.max(1)[1]\n",
    "            # decoded를 임베딩하여 embedded를 업데이트\n",
    "            embedded = self.embedding(decoded).unsqueeze(1) # y_{t-1}\n",
    "            # attention을 사용하여 다음 context 벡터를 계산\n",
    "            context, alpha = self.Attention(hidden, encoder_outputs,None)\n",
    "            # alpha를 attentions 리스트에 추가\n",
    "            attentions.append(alpha.squeeze(1))\n",
    "\n",
    "        # decodes 리스트를 텐서로 변환하고 최대값 인덱스를 반환\n",
    "        return torch.cat(decodes).max(1)[1], torch.cat(attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seq2Seq 모델을 학습하는 과정을 구현해봅시다. 주요 설정 변수들은 다음과 같습니다:\n",
    "\n",
    "- `EPOCH`: 전체 데이터셋에 대한 학습 반복 횟수\n",
    "- `BATCH_SIZE`: 한 번에 학습할 데이터의 개수\n",
    "- `EMBEDDING_SIZE`: 단어 임베딩 벡터의 차원 크기\n",
    "- `HIDDEN_SIZE`: 인코더와 디코더의 은닉 상태의 크기\n",
    "- `LR`: 학습률(learning rate)로, 모델의 가중치를 업데이트하는 속도를 결정함\n",
    "- `DECODER_LEARNING_RATIO`: 디코더의 학습률을 인코더의 학습률과 다르게 설정할 수 있음. 여기서는 인코더의 학습률에 5를 곱한 값을 사용\n",
    "- `RESCHEDULED`: 학습률을 조절하는 스케줄링 여부를 결정 변수\n",
    "\n",
    "먼저, 인코더와 디코더 객체를 생성하고 가중치를 초기화합니다. 그런 다음, 손실 함수 (loss function)와 최적화 알고리즘을 설정합니다\n",
    "\n",
    "학습 과정은 다음과 같습니다:\n",
    "1. 배치 데이터를 가져옴\n",
    "2. 인코더와 디코더의 기울기를 0으로 초기화\n",
    "3. 인코더를 사용하여 입력 데이터를 처리하고, 은닉 상태와 출력을 얻음\n",
    "4. 디코더를 사용하여 예측값을 생성\n",
    "5. 손실 함수를 사용하여 예측값과 실제 목표값 사이의 차이를 계산\n",
    "6. 손실을 역전파하여 모델의 가중치를 업데이트\n",
    "\n",
    "학습 중간에 학습률을 조절할 수 있습니다. 여기서는 에포크의 절반 지점에서 학습률을 0.01배로 낮추는 방식을 사용합니다. 이를 위해 `RESCHEDULED` 변수를 사용하여 학습률이 조절되었는지 확인하고, 조절되지 않았다면 에포크의 절반 지점에서 학습률을 변경합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00/5] [000/115] mean_loss : 8.91\n",
      "[00/5] [050/115] mean_loss : 5.00\n",
      "[00/5] [100/115] mean_loss : 3.91\n",
      "[01/5] [000/115] mean_loss : 3.51\n",
      "[01/5] [050/115] mean_loss : 3.25\n",
      "[01/5] [100/115] mean_loss : 2.99\n",
      "[02/5] [000/115] mean_loss : 2.71\n",
      "[02/5] [050/115] mean_loss : 2.56\n",
      "[02/5] [100/115] mean_loss : 2.40\n",
      "[03/5] [000/115] mean_loss : 2.02\n",
      "[03/5] [050/115] mean_loss : 1.93\n",
      "[03/5] [100/115] mean_loss : 1.85\n",
      "[04/5] [000/115] mean_loss : 1.86\n",
      "[04/5] [050/115] mean_loss : 1.80\n",
      "[04/5] [100/115] mean_loss : 1.78\n"
     ]
    }
   ],
   "source": [
    "# 학습에 필요한 파라미터 설정\n",
    "EPOCH = 5 # 총 학습할 epoch의 수\n",
    "BATCH_SIZE = 256 # 한 번에 학습할 데이터의 수\n",
    "EMBEDDING_SIZE = 300 # 임베딩 벡터의 차원 수\n",
    "HIDDEN_SIZE = 512 # 히든 레이어의 노드 수\n",
    "LR = 0.001 # 학습률\n",
    "DECODER_LEARNING_RATIO = 5.0 # 디코더의 학습률 비율\n",
    "RESCHEDULED = False # 학습률 재조정 여부\n",
    "\n",
    "# 인코더와 디코더 객체 생성\n",
    "encoder = Encoder(len(source2index), EMBEDDING_SIZE, HIDDEN_SIZE, 3, True)\n",
    "decoder = Decoder(len(target2index), EMBEDDING_SIZE, HIDDEN_SIZE * 2)\n",
    "\n",
    "# 인코더와 디코더의 가중치 초기화\n",
    "encoder.init_weight()\n",
    "decoder.init_weight()\n",
    "\n",
    "# GPU가 사용 가능한 경우, 인코더와 디코더를 GPU로 이동\n",
    "if USE_CUDA:\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "\n",
    "# 손실 함수 설정 (CrossEntropyLoss 사용, 패딩된 부분은 무시)\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "# 최적화 함수 설정 (Adam 사용)\n",
    "enc_optimizer = optim.Adam(encoder.parameters(), lr=LR)\n",
    "dec_optimizer = optim.Adam(decoder.parameters(), lr=LR * DECODER_LEARNING_RATIO)\n",
    "\n",
    "# 학습 시작\n",
    "for epoch in range(EPOCH):\n",
    "    losses=[] # 손실을 저장할 리스트\n",
    "    for i, batch in enumerate(getBatch(BATCH_SIZE, train_data)): # 배치 사이즈만큼 데이터를 가져옴\n",
    "        inputs, targets, input_lengths, target_lengths = pad_to_batch(batch, source2index, target2index) # 배치 데이터를 패딩\n",
    "\n",
    "        # 입력 데이터에 대한 마스크 생성\n",
    "        input_masks = torch.cat([Variable(ByteTensor(tuple(map(lambda s: s ==0, t.data)))) for t in inputs]).view(inputs.size(0), -1)\n",
    "        start_decode = Variable(LongTensor([[target2index['<s>']] * targets.size(0)])).transpose(0, 1) # 디코딩 시작 토큰 설정\n",
    "        encoder.zero_grad() # 인코더의 그래디언트 초기화\n",
    "        decoder.zero_grad() # 디코더의 그래디언트 초기화\n",
    "        output, hidden_c = encoder(inputs, input_lengths) # 인코더를 통해 출력과 히든 상태 얻음\n",
    "\n",
    "        # 디코더를 통해 예측값 생성\n",
    "        preds = decoder(start_decode, hidden_c, targets.size(1), output, input_masks, True)\n",
    "\n",
    "        loss = loss_function(preds, targets.view(-1)) # 손실 계산\n",
    "        losses.append(loss.data.tolist() ) # 손실 저장\n",
    "        loss.backward() # 역전파 수행\n",
    "        torch.nn.utils.clip_grad_norm(encoder.parameters(), 50.0) # 그래디언트 클리핑\n",
    "        torch.nn.utils.clip_grad_norm(decoder.parameters(), 50.0) # 그래디언트 클리핑\n",
    "        enc_optimizer.step() # 인코더 파라미터 업데이트\n",
    "        dec_optimizer.step() # 디코더 파라미터 업데이트\n",
    "\n",
    "        # 일정 간격으로 손실 출력\n",
    "        if i % 50 == 0 or i % len(train_data) == 0:\n",
    "            print(\"[%02d/%d] [%03d/%d] mean_loss : %0.2f\" %(epoch, EPOCH, i, len(train_data)//BATCH_SIZE, np.mean(losses)))\n",
    "            losses=[]\n",
    "\n",
    "    # 학습 중간에 학습률 재조정\n",
    "    if RESCHEDULED == False and epoch  == EPOCH//2:\n",
    "        LR *= 0.01\n",
    "        enc_optimizer = optim.Adam(encoder.parameters(), lr=LR)\n",
    "        dec_optimizer = optim.Adam(decoder.parameters(), lr=LR * DECODER_LEARNING_RATIO)\n",
    "        RESCHEDULED = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`show_attention` 함수는 입력 단어, 출력 단어, 어텐션 가중치를 입력으로 받아 어텐션 가중치를 시각화하는 함수입니다. 이 함수를 사용하여 입력 단어와 출력 단어 사이의 어텐션 가중치를 관찰할 수 있습니다\n",
    "\n",
    "1. 먼저, 학습 데이터에서 무작위로 하나의 샘플을 선택합니다. 이 샘플의 입력 문장과 정답 문장을 확인한 후, 인코더와 디코더를 사용하여 번역 결과를 생성합니다. 생성된 번역 결과를 출력하고, 어텐션 가중치를 시각화하여 입력 문장과 출력 문장 사이의 연관성을 확인합니다\n",
    "\n",
    "2. `test` 변수에 무작위로 선택된 학습 데이터를 저장하고, 이를 인코더와 디코더에 전달하여 번역 결과를 생성합니다. 번역 결과와 함께 어텐션 가중치도 반환됩니다\n",
    "\n",
    "3. `input_` 변수에는 입력 문장의 단어 인덱스를 저장하고, `pred` 변수에는 생성된 번역 결과의 단어 인덱스를 저장합니다. 이들 인덱스를 단어로 변환하여 입력 문장, 정답 문장, 번역 결과를 출력합니다\n",
    "\n",
    "4. 마지막으로, `show_attention` 함수를 사용하여 어텐션 가중치를 시각화합니다. 이를 통해 입력 문장과 출력 문장 사이의 연관성을 관찰할 수 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source :  i can t go alone .\n",
      "Truth :  je ne peux m y rendre seule .\n",
      "Prediction :  je ne peux pas partir y y .\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_attention(input_words, output_words, attentions):\n",
    "    # 색상 바를 가진 plot 설정\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone') # attention을 나타내는 행렬을 plot으로 표현\n",
    "    fig.colorbar(cax) # 색상 바 추가\n",
    "\n",
    "    # 축 설정\n",
    "    ax.set_xticklabels([''] + input_words, rotation=90) # x축에 입력 단어 설정\n",
    "    ax.set_yticklabels([''] + output_words) # y축에 출력 단어 설정\n",
    "\n",
    "    # 모든 눈금에 레이블 표시\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show() # plot 표시\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "test = random.choice(train_data) # 학습 데이터에서 무작위로 하나 선택\n",
    "input_ = test[0] # 입력 데이터\n",
    "truth = test[1] # 실제 값\n",
    "\n",
    "output, hidden = encoder(input_, [input_.size(1)]) # 인코더를 통해 출력과 히든 상태 얻음\n",
    "pred, attn = decoder.decode(hidden, output) # 디코더를 통해 예측값과 attention 얻음\n",
    "\n",
    "input_ = [index2source[i] for i in input_.data.tolist()[0]] # 입력 데이터를 단어로 변환\n",
    "pred = [index2target[i] for i in pred.data.tolist()] # 예측값을 단어로 변환\n",
    "\n",
    "# 결과 출력\n",
    "print('Source : ',' '.join([i for i in input_ if i not in ['</s>']])) # 입력 문장 출력\n",
    "print('Truth : ',' '.join([index2target[i] for i in truth.data.tolist()[0] if i not in [2, 3]])) # 실제 문장 출력\n",
    "print('Prediction : ',' '.join([i for i in pred if i not in ['</s>']])) # 예측 문장 출력\n",
    "\n",
    "if USE_CUDA:\n",
    "    attn = attn.cpu() # CUDA를 사용하는 경우, attention을 CPU로 이동\n",
    "\n",
    "show_attention(input_, pred, attn.data) # attention을 plotting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "upstage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
