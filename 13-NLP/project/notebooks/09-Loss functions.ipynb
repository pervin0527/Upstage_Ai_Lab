{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pervinco/miniconda3/envs/nlp-project/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from rouge import Rouge\n",
    "from datetime import datetime\n",
    "\n",
    "from torch import nn\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['#Person1#', '#Person2#', '#Person3#', '#Person4#', '#Person5#', '#Person6#', '#Person7#', '#PhoneNumber#', '#Address#', '#PassportNumber#', '#CardNumber#', '#Email#', '#DateOfBirth#']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pervinco/miniconda3/envs/nlp-project/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"psyche/KoT5-summarization\")\n",
    "special_tokens_dict={'additional_special_tokens': ['#Person1#', '#Person2#','#Person3#', '#Person4#', '#Person5#', '#Person6#', '#Person7#', '#PhoneNumber#', \n",
    "                                                   '#Address#', '#PassportNumber#', '#CardNumber#', '#Email#', '#DateOfBirth#',]}\n",
    "\n",
    "tokenizer.add_special_tokens(special_tokens_dict)\n",
    "print(tokenizer.special_tokens_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"lcw99/t5-large-korean-text-summary\" ## \"psyche/KoT5-summarization\"\n",
    "train_df = pd.read_csv('../dataset/cleaned_train.csv')\n",
    "val_df = pd.read_csv('../dataset/cleaned_dev.csv')\n",
    "test_df = pd.read_csv(\"../dataset/test.csv\")\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 2\n",
    "num_workers = 0\n",
    "log_interval = 300\n",
    "dig_max_len = 1024\n",
    "sum_max_len = 512\n",
    "\n",
    "remove_tokens = [\n",
    "    '<usr>',\n",
    "    f\"{tokenizer.unk_token}\", \n",
    "    f\"{tokenizer.eos_token}\", \n",
    "    f\"{tokenizer.pad_token}\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, input_len, summ_len, is_train=True):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.df = df\n",
    "        self.source_len = input_len\n",
    "        self.summ_len = summ_len\n",
    "        self.is_train = is_train\n",
    "        if self.is_train:\n",
    "            self.input_ids = tokenizer(self.df['dialogue'].tolist(), return_tensors=\"pt\", padding=True,\n",
    "                                add_special_tokens=True, truncation=True, max_length=512, return_token_type_ids=False).input_ids\n",
    "            self.labels = tokenizer(self.df['summary'].tolist(), return_tensors=\"pt\", padding=True,\n",
    "                                add_special_tokens=True, truncation=True, max_length=100, return_token_type_ids=False).input_ids\n",
    "        else:\n",
    "            self.input_ids = tokenizer(self.df['dialogue'].tolist(), return_tensors=\"pt\", padding=True,\n",
    "                                add_special_tokens=True, truncation=True, max_length=512, return_token_type_ids=False).input_ids\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_train:\n",
    "            return self.input_ids[idx], self.labels[idx]\n",
    "        else:\n",
    "            return self.input_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_df[['dialogue', 'summary']], tokenizer, dig_max_len, sum_max_len)\n",
    "val_dataset = CustomDataset(val_df[['dialogue', 'summary']], tokenizer, dig_max_len, sum_max_len)\n",
    "test_dataset = CustomDataset(test_df[['dialogue']], tokenizer, dig_max_len, sum_max_len, is_train=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ROUGELoss(nn.Module):\n",
    "    def __init__(self, smoothing=1e-5):\n",
    "        super(ROUGELoss, self).__init__()\n",
    "        self.smoothing = smoothing\n",
    "        self.rouge = Rouge()\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        pred_strs = [' '.join(map(str, seq)) for seq in predictions.tolist()]\n",
    "        targ_strs = [' '.join(map(str, seq)) for seq in targets.tolist()]\n",
    "\n",
    "        scores = []\n",
    "        for pred, targ in zip(pred_strs, targ_strs):\n",
    "            try:\n",
    "                score = self.rouge.get_scores(pred, targ)[0]\n",
    "                rouge_1 = score['rouge-1']['f']\n",
    "                rouge_2 = score['rouge-2']['f']\n",
    "                rouge_l = score['rouge-l']['f']\n",
    "                # avg_rouge = (rouge_1 + rouge_2 + rouge_l) / 3\n",
    "                # scores.append(avg_rouge)\n",
    "\n",
    "                scores.append(rouge_1)\n",
    "\n",
    "            except ValueError:\n",
    "                scores.append(0.0)\n",
    "\n",
    "        return 1 - torch.tensor(scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_to_words(tokenizer, preds, labels):\n",
    "    decoded_preds = tokenizer.batch_decode(preds, clean_up_tokenization_spaces=True)\n",
    "    labels = tokenizer.batch_decode(labels, clean_up_tokenization_spaces=True)\n",
    "\n",
    "    replaced_predictions = decoded_preds.copy()\n",
    "    replaced_labels = labels.copy()\n",
    "    # remove_tokens = ['<usr>', f\"{tokenizer.unk_token}\", f\"{tokenizer.eos_token}\", f\"{tokenizer.pad_token}\"]\n",
    "\n",
    "    for token in remove_tokens:\n",
    "        replaced_predictions = [sentence.replace(token,\" \") for sentence in replaced_predictions]\n",
    "        replaced_labels = [sentence.replace(token,\" \") for sentence in replaced_labels]\n",
    "    return replaced_predictions, replaced_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(replaced_predictions, replaced_labels):\n",
    "    rouge = Rouge()\n",
    "\n",
    "    results = rouge.get_scores(replaced_predictions, replaced_labels,avg=True)\n",
    "    result = {key: value[\"f\"] for key, value in results.items()}\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, device, train_loader, optimizer, log_interval, train_step):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    ce_losses = []\n",
    "    rouge_losses = []\n",
    "    rouge_loss_fn = ROUGELoss()\n",
    "    \n",
    "    for idx, batch in tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Training Epoch {epoch}\"):\n",
    "        input_ids = batch[0].to(device, dtype=torch.long)\n",
    "        labels = batch[1].to(device, dtype=torch.long)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, labels=labels)\n",
    "        ce_loss = outputs.loss\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                max_length=256, \n",
    "                num_beams=4,\n",
    "                repetition_penalty=2.0, \n",
    "                length_penalty=1.0, \n",
    "                early_stopping=True,\n",
    "                no_repeat_ngram_size=2\n",
    "            )\n",
    "        \n",
    "        rouge_loss = rouge_loss_fn(pred_ids, labels)\n",
    "        \n",
    "        loss = ce_loss + rouge_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        ce_losses.append(ce_loss.item())\n",
    "        rouge_losses.append(rouge_loss.item())\n",
    "        train_step += 1\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    avg_ce_loss = sum(ce_losses) / len(ce_losses)\n",
    "    avg_rouge_loss = sum(rouge_losses) / len(rouge_losses)\n",
    "\n",
    "    return train_step, avg_loss, avg_ce_loss, avg_rouge_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(tokenizer, model, device, val_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_results = []\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in tqdm(enumerate(val_loader), total=len(val_loader), desc=\"Validating\"):\n",
    "            input_ids = batch[0].to(device, dtype=torch.long)\n",
    "            labels = batch[1].to(device, dtype=torch.long)\n",
    "\n",
    "            pred_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                max_length=256, \n",
    "                num_beams=4,\n",
    "                repetition_penalty=2.0, \n",
    "                length_penalty=1.0, \n",
    "                early_stopping=True,\n",
    "                no_repeat_ngram_size=2\n",
    "            )\n",
    "\n",
    "            loss = model(input_ids=input_ids, labels=labels).loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            replaced_predictions, replaced_labels = ids_to_words(tokenizer, pred_ids, labels)\n",
    "            result = compute_metrics(replaced_predictions, replaced_labels)\n",
    "            \n",
    "            all_results.append(result)\n",
    "            all_predictions.extend(replaced_predictions)\n",
    "            all_labels.extend(replaced_labels)\n",
    "\n",
    "    val_loss = total_loss / len(val_loader)\n",
    "    avg_result = {key: sum(r[key] for r in all_results) / len(all_results) for key in all_results[0]}\n",
    "    \n",
    "    return val_loss, avg_result, all_predictions, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 6229/6229 [1:26:59<00:00,  1.19it/s]\n",
      "Validating: 100%|██████████| 250/250 [02:52<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Train Loss: 2.108886, CE Loss: 1.412862, ROUGE Loss: 0.696024\n",
      "Validation Loss: 1.158374, Rouge-1: 0.288390, Rouge-2: 0.086566, Rouge-l: 0.271636\n",
      "Average ROUGE: 0.215530\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# 는 #Person1# 에게 숨쉬기가 좀 힘들다고 말한다. #Person2# 의 알레르기가 있다고 생각한다.       \n",
      "GOLD: #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                                 \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   지미는 #Person1# 에게 3시 30분에 헬스장에서 가고 싶어합니다. 지미는 그 후에 다리와 팔목을 운동했다고 말한다. \n",
      "GOLD: #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                         \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# 는 #Person1# 에게 더 이상 건강에 해로운 음식을 먹는 것을 멈춰야 한다고 말한다. 그들은 닭고기를 먹는 편 생각한다.         \n",
      "GOLD: #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                 \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "New best model saved with average ROUGE: 0.215530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 6229/6229 [1:37:47<00:00,  1.06it/s]\n",
      "Validating: 100%|██████████| 250/250 [03:28<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "Train Loss: 1.740772, CE Loss: 1.067675, ROUGE Loss: 0.673097\n",
      "Validation Loss: 1.054275, Rouge-1: 0.287257, Rouge-2: 0.089531, Rouge-l: 0.275114\n",
      "Average ROUGE: 0.217301\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   의사사는 #Person1# 에게 요즘 숨쉬기가 좀 힘들다고 말한다. 의사 씨는 #Person2# 의 폐 전문의에게 보내서 천식에 대한 검사를 받게 할 예정이다. \n",
      "GOLD: #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                                 \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   지미는 나중에 운동하러 가자고 제안한다. #Person1# 은 3시 30분에 헬스장에서 만나기로 한다.           \n",
      "GOLD: #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                         \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 은 더 이상 건강에 해로운 음식을 먹는 것을 멈춰야 한다. #Person2# 는 더 건강한 음식을 먹기 시작하기로 결정했습니다. 그들은 닭고기는 구워서 먹으면 정말 행운이라고 생각한다. \n",
      "GOLD: #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                 \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "New best model saved with average ROUGE: 0.217301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 6229/6229 [1:41:32<00:00,  1.02it/s]\n",
      "Validating: 100%|██████████| 250/250 [03:11<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "Train Loss: 1.523523, CE Loss: 0.859338, ROUGE Loss: 0.664184\n",
      "Validation Loss: 1.004056, Rouge-1: 0.298969, Rouge-2: 0.095564, Rouge-l: 0.281341\n",
      "Average ROUGE: 0.225291\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   의사 선생님은 #Person1# 에게 오늘 하루의 숨쉬기가 힘들다고 말하고, #Person2# 는 모든 것을 잊어버렸다고 생각하지만, 의사는 그에게 다양한 식사에 대해 이야기한다. 의사 선생님이 다른 폐 전문의에게 보내서 천식에 대한 검사를 받게 할 것이라고 말한다. \n",
      "GOLD: #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                                 \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   지미는 #Person1# 에게 나중에 운동하러 가자고 제안한다. 그들은 3시 30분에 헬스장에서 만나기로 한다.                            \n",
      "GOLD: #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                         \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 은 더 이상 건강에 해로운 음식을 먹는 것을 멈춰야 한다. #Person2# 는 #Person1# 에게 닭고기는 구워서 먹으면 정말 건강에라고 조언한다.       \n",
      "GOLD: #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                 \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "New best model saved with average ROUGE: 0.225291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4:  58%|█████▊    | 3622/6229 [59:45<41:03,  1.06it/s]  "
     ]
    }
   ],
   "source": [
    "train_step = 0\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "save_path = os.path.join(\"./T5_runs\", timestamp)\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "best_avg_rouge = 0\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_step, train_loss, train_ce_loss, train_rouge_loss = train(epoch, model, device, train_loader, optimizer, log_interval, train_step)\n",
    "    val_loss, val_result, val_predictions, val_labels = validate(tokenizer, model, device, val_loader)\n",
    "    \n",
    "    avg_rouge = (val_result['rouge-1'] + val_result['rouge-2'] + val_result['rouge-l']) / 3\n",
    "    print(f\"Epoch {epoch}/{epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.6f}, CE Loss: {train_ce_loss:.6f}, ROUGE Loss: {train_rouge_loss:.6f}\")\n",
    "    print(f\"Validation Loss: {val_loss:.6f}, Rouge-1: {val_result['rouge-1']:.6f}, Rouge-2: {val_result['rouge-2']:.6f}, Rouge-l: {val_result['rouge-l']:.6f}\")\n",
    "    print(f\"Average ROUGE: {avg_rouge:.6f}\")\n",
    "    \n",
    "    print('-'*150)\n",
    "    for i in range(3):\n",
    "        print(f\"PRED: {val_predictions[i]}\")\n",
    "        print(f\"GOLD: {val_labels[i]}\")\n",
    "        print('-'*150)\n",
    "    \n",
    "    # 최고 성능 모델 저장\n",
    "    if avg_rouge > best_avg_rouge:\n",
    "        best_avg_rouge = avg_rouge\n",
    "        torch.save(model.state_dict(), os.path.join(save_path, 'best.pth'))\n",
    "        print(f\"New best model saved with average ROUGE: {best_avg_rouge:.6f}\")\n",
    "    \n",
    "    torch.save(model.state_dict(), os.path.join(save_path, f'epoch-{epoch}.pth'))\n",
    "\n",
    "torch.save(model.state_dict(), os.path.join(save_path, 'last.pth'))\n",
    "print(\"Training completed. Last model saved.\")\n",
    "\n",
    "print(f\"Best average ROUGE: {best_avg_rouge:.6f}\")\n",
    "print(f\"Best model saved at: {os.path.join(save_path, 'best.pth')}\")\n",
    "print(f\"Last model saved at: {os.path.join(save_path, 'last.pth')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tokenizer, model, device, test_loader, fname):\n",
    "    model.eval()\n",
    "    summary = []\n",
    "    with torch.no_grad():\n",
    "        for input_ids in tqdm(test_loader):\n",
    "            input_ids = input_ids.to(device, dtype=torch.long)\n",
    "\n",
    "            pred_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                max_length=256, \n",
    "                num_beams=4,\n",
    "                repetition_penalty=2.0, \n",
    "                length_penalty=1.0, \n",
    "                early_stopping=True,\n",
    "                no_repeat_ngram_size=2\n",
    "            )\n",
    "            for ids in pred_ids:\n",
    "                result = tokenizer.decode(ids)\n",
    "                summary.append(result)\n",
    "                \n",
    "    remove_tokens = ['<usr>', f\"{tokenizer.unk_token}\", f\"{tokenizer.eos_token}\", f\"{tokenizer.pad_token}\"]\n",
    "    preprocessed_summary = summary.copy()\n",
    "    for token in remove_tokens:\n",
    "        preprocessed_summary = [sentence.replace(token,\" \") for sentence in preprocessed_summary]\n",
    "\n",
    "    output = pd.DataFrame(\n",
    "        {\n",
    "            \"fname\": fname,\n",
    "            \"summary\" : preprocessed_summary,\n",
    "        }\n",
    "    )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"/home/pervinco/Upstage_Ai_Lab/project/notebooks/T5_runs/2024-09-05-15-51-10\"\n",
    "best_model = torch.load(f'{ckpt_path}/best.pth')\n",
    "output = predict(tokenizer, model, device, test_loader, test_df['fname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(f\"{ckpt_path}/prediction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
