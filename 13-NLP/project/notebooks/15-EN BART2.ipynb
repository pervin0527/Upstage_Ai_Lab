{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from rouge import Rouge\n",
    "from datetime import datetime\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from transformers import AutoTokenizer\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration, BartConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "save_path = os.path.join(\"./BART_runs\", timestamp)\n",
    "\n",
    "weights_path = os.path.join(save_path, 'weights')\n",
    "logs_path = os.path.join(save_path, 'logs')\n",
    "os.makedirs(weights_path, exist_ok=True)\n",
    "os.makedirs(logs_path, exist_ok=True)\n",
    "\n",
    "config = {\n",
    "    \"general\": {\n",
    "        \"data_path\": \"../dataset\",\n",
    "        \"train_file\": \"en_train.csv\",\n",
    "        \"valid_file\": \"en_dev.csv\",\n",
    "        \"test_file\": \"test.csv\",\n",
    "        \"model_name\": \"facebook/bart-large-xsum\",\n",
    "        \"output_dir\": save_path,\n",
    "        \"model_cfg\": \"\"\n",
    "    },\n",
    "    \"tokenizer\": {\n",
    "        \"path\": \"./tokenizer\",\n",
    "        \"encoder_max_len\": 512,\n",
    "        \"decoder_max_len\": 256,\n",
    "        \"bos_token\": \"<s>\",\n",
    "        \"eos_token\": \"</s>\",\n",
    "        \"sep_token\": \"<sep>\",\n",
    "        \"mask_token\": \"<mask>\",\n",
    "        \"special_tokens\": [\n",
    "            \"<sep>\",\n",
    "            '#Person1#',\n",
    "            '#Person2#',\n",
    "            '#Person3#',\n",
    "            '#Person4#',\n",
    "            '#Person5#',\n",
    "            '#Person6#',\n",
    "            '#Person7#',\n",
    "            '#SSN#',\n",
    "            '#Email#',\n",
    "            '#Address#',\n",
    "            '#Reaction#',\n",
    "            '#CarNumber#',\n",
    "            '#Movietitle#',\n",
    "            '#DateOfBirth#',\n",
    "            '#CardNumber#',\n",
    "            '#PhoneNumber#',\n",
    "            '#PassportNumber#'\n",
    "\n",
    "            \"<DOC>\",\n",
    "            \"<link_other>\",\n",
    "            \"< link_photo>\",\n",
    "            \"<love>\",\n",
    "            \"<file_audio>\",\n",
    "            \"<fole_other>\",\n",
    "            \"<file:Amelia.doc>\",\n",
    "            \"<gif>\",\n",
    "            \"<File_video>\",\n",
    "            \"<file>\",\n",
    "            \"<picutre>\",\n",
    "            \"<file:research_papers>\",\n",
    "            \"<moa>\",\n",
    "            \"<photo_file>\",\n",
    "            \"<file_doc>\",\n",
    "            \"<file _gif>\",\n",
    "            \"<file_location>\",\n",
    "            \"<emoticon_thumbup>\",\n",
    "            \"<file:jpg>\",\n",
    "            \"<file.other>\",\n",
    "            \"<OMG>\",\n",
    "            \"<file:photo>\",\n",
    "            \"<emoticon_:smiley:>\",\n",
    "            \"<thumbsup>\",\n",
    "            \"<file_photo>\",\n",
    "            \"<file_photo >\",\n",
    "            \"<file_movie>\",\n",
    "            \"<file_record>\",\n",
    "            \"<link_photo>\",\n",
    "            \"<file:assignment>\",\n",
    "            \"<file_picture>\",\n",
    "            \"<foto>\",\n",
    "            \"<file_photo_screenshot_from_phone>\",\n",
    "            \"<emoticon>\",\n",
    "            \"<file _video>\",\n",
    "            \"<file:URGENT>\",\n",
    "            \"<location>\",\n",
    "            \"<othre_file>\",\n",
    "            \"<file-other>\",\n",
    "            \"<kisses>\",\n",
    "            \"<File:Excelsheet>\",\n",
    "            \"<file_GIF>\",\n",
    "            \"<other_file>\",\n",
    "            \"<link>\",\n",
    "            \"<file_photo? or <file_photo>\",\n",
    "            \"<file_docx>\",\n",
    "            \"<file-photo>\",\n",
    "            \"<file_gps>\",\n",
    "            \"<File_link>\",\n",
    "            \"<other>\",\n",
    "            \"<fiile_gif>\",\n",
    "            \"<file_other_>\",\n",
    "            \"<file:video>\",\n",
    "            \"<file_zip>\",\n",
    "            \"<fil_gif>\",\n",
    "            \"<gif_file>\",\n",
    "            \"<file_git>\",\n",
    "            \"<link_video>\",\n",
    "            \"<file_other>\",\n",
    "            \"<file_others>\",\n",
    "            \"<file_photos>\",\n",
    "            \"<file_song>\",\n",
    "            \"<crickets>\",\n",
    "            \"<‎file_photo>\",\n",
    "            \"<LOL>\",\n",
    "            \"<facepalm>\",\n",
    "            \"< link>\",\n",
    "            \"<fIie_others>\",\n",
    "            \"<flie_photo>\",\n",
    "            \"<file _other>\",\n",
    "            \"<file_video>\",\n",
    "            \"<file other>\",\n",
    "            \"<waves>\",\n",
    "            \"<file photo>\",\n",
    "            \"<lol>\",\n",
    "            \"<file_image>\",\n",
    "            \"<file_pic>\",\n",
    "            \"<emoticon_stuck_out_tongue>\",\n",
    "            \"<thumb up>\",\n",
    "            \"<file_gif>\",\n",
    "            \"<file _photo>\",\n",
    "            \"<file_foto>\",\n",
    "            \"<emoticon_smile>\",\n",
    "            \"<video>\",\n",
    "            \"<file_link>\",\n",
    "            \"<file_contact>\",\n",
    "            \"<photo>\",\n",
    "            \"<File_line>\",\n",
    "            \"<send_file>\",\n",
    "            \"<File_photo>\",\n",
    "            \"<# <file_othetr>\",\n",
    "            \"<file_ photo>\",\n",
    "            \"<file_ other>\",\n",
    "            \"<video_file>\",\n",
    "\n",
    "        ]\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"seed\": 42,\n",
    "        \"overwrite_output_dir\": True,\n",
    "\n",
    "        \"epochs\": 1000,\n",
    "        \"batch_size\": 8,\n",
    "        \"learning_rate\": 0.000001,\n",
    "        \"weight_decay\": 0.01,\n",
    "        \"accumulation_steps\": 4,\n",
    "        \"patience\": 10,\n",
    "\n",
    "        \"max_lr\": 0.0001,\n",
    "        \"warmup_epochs\": 10,\n",
    "        \"T_0\": 100,\n",
    "        \"T_mult\": 1,\n",
    "        \"T_gamma\": 0.5,\n",
    "    },\n",
    "    \"inference\": {\n",
    "        \"no_repeat_ngram_size\": 2,\n",
    "        \"early_stopping\": False,\n",
    "        \"generate_max_length\": 200,\n",
    "        \"num_beams\": 4,\n",
    "        \"batch_size\": 32,\n",
    "        \"remove_tokens\": [\n",
    "            \"<unk>\",\n",
    "            \"<s>\",\n",
    "            \"</s>\",\n",
    "            \"<pad>\",\n",
    "            \"<sep>\",\n",
    "            \"<mask>\"\n",
    "        ]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_config = BartConfig.from_pretrained(config['general']['model_name'])\n",
    "\n",
    "# tokenizer = BartTokenizerFast.from_pretrained(\"../tokenizer/ko_sentencepiece\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(config['general']['model_name'], config=config)\n",
    "remove_tokens = ['<usr>', f\"{tokenizer.bos_token}\", f\"{tokenizer.unk_token}\", f\"{tokenizer.eos_token}\", f\"{tokenizer.pad_token}\", f\"{tokenizer.sep_token}\", f\"{tokenizer.mask_token}\"]\n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\": config['tokenizer']['special_tokens']})\n",
    "print(tokenizer.special_tokens_map)\n",
    "\n",
    "model = BartForConditionalGeneration.from_pretrained(config['general']['model_name'])\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config['training']['learning_rate'], weight_decay=config['training']['weight_decay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f\"{config['general']['data_path']}/{config['general']['train_file']}\")\n",
    "val_df = pd.read_csv(f\"{config['general']['data_path']}/{config['general']['valid_file']}\")\n",
    "test_df = pd.read_csv(f\"{config['general']['data_path']}/{config['general']['test_file']}\")\n",
    "\n",
    "samsum_train = pd.read_csv(f\"{config['general']['data_path']}/cleaned_samsum_train.csv\")\n",
    "samsum_valid = pd.read_csv(f\"{config['general']['data_path']}/cleaned_samsum_valid.csv\")\n",
    "samsum_test = pd.read_csv(f\"{config['general']['data_path']}/cleaned_samsum_test.csv\")\n",
    "\n",
    "trans_train = pd.read_csv(f\"{config['general']['data_path']}/processed_translated_train.csv\")\n",
    "trans_valid = pd.read_csv(f\"{config['general']['data_path']}/processed_translated_train.csv\")\n",
    "\n",
    "trans_train['dialogue'] = trans_train['translated_dialogue']\n",
    "trans_train['summary'] = trans_train['translated_summary']\n",
    "trans_valid['dialogue'] = trans_valid['translated_dialogue']\n",
    "trans_valid['summary'] = trans_valid['translated_summary']\n",
    "\n",
    "train_df = pd.concat([train_df, samsum_train, samsum_valid, samsum_test])\n",
    "train_df['dialogue'] = train_df['dialogue'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, is_train=True):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.df = df.copy()\n",
    "        self.is_train = is_train\n",
    "\n",
    "        # 화자가 바뀔 때 SEP 토큰을 추가\n",
    "        self.df.loc[:, 'dialogue'] = self.df['dialogue'].apply(self.add_sep_tokens)\n",
    "\n",
    "        if self.is_train:           \n",
    "            self.input_ids = tokenizer(self.df['dialogue'].tolist(), \n",
    "                                       return_tensors=\"pt\", \n",
    "                                       padding=True,\n",
    "                                       add_special_tokens=True, \n",
    "                                       truncation=True, \n",
    "                                       max_length=config['tokenizer']['encoder_max_len'], \n",
    "                                       return_token_type_ids=False).input_ids\n",
    "            \n",
    "            self.labels = tokenizer(self.df['summary'].tolist(), \n",
    "                                    return_tensors=\"pt\", \n",
    "                                    padding=True,\n",
    "                                    add_special_tokens=True, \n",
    "                                    truncation=True, \n",
    "                                    max_length=config['tokenizer']['decoder_max_len'],\n",
    "                                    return_token_type_ids=False).input_ids\n",
    "        else:\n",
    "            self.input_ids = tokenizer(self.df['dialogue'].tolist(), \n",
    "                                       return_tensors=\"pt\", \n",
    "                                       padding=True,\n",
    "                                       add_special_tokens=True, \n",
    "                                       truncation=True, \n",
    "                                       max_length=config['tokenizer']['encoder_max_len'], \n",
    "                                       return_token_type_ids=False).input_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_train:\n",
    "            return self.input_ids[idx], self.labels[idx]\n",
    "        else:\n",
    "            return self.input_ids[idx]\n",
    "\n",
    "\n",
    "    def add_sep_tokens(self, dialogue):\n",
    "        # 화자가 바뀔 때 SEP 토큰을 추가\n",
    "        pattern = r'(#Person\\d+#)'  # 화자를 나타내는 패턴\n",
    "        parts = re.split(pattern, dialogue)  # 화자를 기준으로 대화 분리\n",
    "        result = []\n",
    "        prev_speaker = None\n",
    "        for part in parts:\n",
    "            if re.match(pattern, part):  # 화자가 바뀌면\n",
    "                if prev_speaker and prev_speaker != part:\n",
    "                    result.append('<sep>')  # SEP 토큰 추가\n",
    "                prev_speaker = part\n",
    "            result.append(part)\n",
    "        return ''.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_df[['dialogue', 'summary']], tokenizer)\n",
    "val_dataset = CustomDataset(val_df[['dialogue', 'summary']], tokenizer)\n",
    "test_dataset = CustomDataset(test_df[['dialogue']], tokenizer, is_train=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config['training']['batch_size'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config['training']['batch_size'], shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config['training']['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "masked_input_ids, original_input_ids = batch[0], batch[1]\n",
    "\n",
    "masked_example = tokenizer.decode(masked_input_ids[0], skip_special_tokens=False)\n",
    "original_example = tokenizer.decode(original_input_ids[0], skip_special_tokens=False)\n",
    "\n",
    "masked_example, original_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_to_words(tokenizer, preds, labels):\n",
    "    decoded_preds = tokenizer.batch_decode(preds, clean_up_tokenization_spaces=True)\n",
    "    labels = tokenizer.batch_decode(labels, clean_up_tokenization_spaces=True)\n",
    "\n",
    "    replaced_predictions = decoded_preds.copy()\n",
    "    replaced_labels = labels.copy()\n",
    "\n",
    "    for token in remove_tokens:\n",
    "        replaced_predictions = [sentence.replace(token,\" \") for sentence in replaced_predictions]\n",
    "        replaced_labels = [sentence.replace(token,\" \") for sentence in replaced_labels]\n",
    "        \n",
    "    return replaced_predictions, replaced_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(replaced_predictions, replaced_labels):\n",
    "    rouge = Rouge()\n",
    "\n",
    "    results = rouge.get_scores(replaced_predictions, replaced_labels,avg=True)\n",
    "    result = {key: value[\"f\"] for key, value in results.items()}\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineAnnealingWarmUpRestarts(_LRScheduler):\n",
    "    def __init__(self, optimizer, T_0, T_mult=1, eta_max=0.1, T_up=0, gamma=1., last_epoch=-1):\n",
    "        if T_0 <= 0 or not isinstance(T_0, int):\n",
    "            raise ValueError(\"Expected positive integer T_0, but got {}\".format(T_0))\n",
    "        if T_mult < 1 or not isinstance(T_mult, int):\n",
    "            raise ValueError(\"Expected integer T_mult >= 1, but got {}\".format(T_mult))\n",
    "        if T_up < 0 or not isinstance(T_up, int):\n",
    "            raise ValueError(\"Expected positive integer T_up, but got {}\".format(T_up))\n",
    "        self.T_0 = T_0\n",
    "        self.T_mult = T_mult\n",
    "        self.base_eta_max = eta_max\n",
    "        self.eta_max = eta_max\n",
    "        self.T_up = T_up\n",
    "        self.T_i = T_0\n",
    "        self.gamma = gamma\n",
    "        self.cycle = 0\n",
    "        self.T_cur = last_epoch\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "    \n",
    "    def get_lr(self):\n",
    "        if self.T_cur == -1:\n",
    "            return self.base_lrs\n",
    "        elif self.T_cur < self.T_up:\n",
    "            return [(self.eta_max - base_lr)*self.T_cur / self.T_up + base_lr for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr + (self.eta_max - base_lr) * (1 + math.cos(math.pi * (self.T_cur-self.T_up) / (self.T_i - self.T_up))) / 2\n",
    "                    for base_lr in self.base_lrs]\n",
    "\n",
    "    def step(self, epoch=None):\n",
    "        if epoch is None:\n",
    "            epoch = self.last_epoch + 1\n",
    "            self.T_cur = self.T_cur + 1\n",
    "            if self.T_cur >= self.T_i:\n",
    "                self.cycle += 1\n",
    "                self.T_cur = self.T_cur - self.T_i\n",
    "                self.T_i = (self.T_i - self.T_up) * self.T_mult + self.T_up\n",
    "        else:\n",
    "            if epoch >= self.T_0:\n",
    "                if self.T_mult == 1:\n",
    "                    self.T_cur = epoch % self.T_0\n",
    "                    self.cycle = epoch // self.T_0\n",
    "                else:\n",
    "                    n = int(math.log((epoch / self.T_0 * (self.T_mult - 1) + 1), self.T_mult))\n",
    "                    self.cycle = n\n",
    "                    self.T_cur = epoch - self.T_0 * (self.T_mult ** n - 1) / (self.T_mult - 1)\n",
    "                    self.T_i = self.T_0 * self.T_mult ** (n)\n",
    "            else:\n",
    "                self.T_i = self.T_0\n",
    "                self.T_cur = epoch\n",
    "                \n",
    "        self.eta_max = self.base_eta_max * (self.gamma**self.cycle)\n",
    "        self.last_epoch = math.floor(epoch)\n",
    "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
    "            param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, device, train_loader, optimizer, writer, accumulation_steps):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for idx, batch in tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Training Epoch {epoch}\", leave=False):\n",
    "        input_ids = batch[0].to(device, dtype=torch.long)\n",
    "        labels = batch[1].to(device, dtype=torch.long)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, labels=labels)\n",
    "        ce_loss = outputs.loss\n",
    "        ce_loss = ce_loss / accumulation_steps \n",
    "        ce_loss.backward()\n",
    "\n",
    "        if (idx + 1) % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        total_loss += ce_loss.item() * accumulation_steps\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    writer.add_scalar('Loss/train', avg_loss, epoch)\n",
    "\n",
    "    return avg_loss\n",
    "\n",
    "def validate(tokenizer, model, device, val_loader, writer, epoch):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_results = []\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in tqdm(enumerate(val_loader), total=len(val_loader), desc=\"Validating\", leave=False):\n",
    "            input_ids = batch[0].to(device, dtype=torch.long)\n",
    "            labels = batch[1].to(device, dtype=torch.long)\n",
    "\n",
    "            pred_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                max_length=config['inference']['generate_max_length'], \n",
    "                num_beams=config['inference']['num_beams'],\n",
    "                repetition_penalty=2.0, \n",
    "                length_penalty=1.0, \n",
    "                early_stopping=True,\n",
    "                no_repeat_ngram_size=2\n",
    "            )\n",
    "\n",
    "            loss = model(input_ids=input_ids, labels=labels).loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            replaced_predictions, replaced_labels = ids_to_words(tokenizer, pred_ids, labels)\n",
    "            result = compute_metrics(replaced_predictions, replaced_labels)\n",
    "\n",
    "            all_results.append(result)\n",
    "            all_predictions.extend(replaced_predictions)\n",
    "            all_labels.extend(replaced_labels)\n",
    "\n",
    "    val_loss = total_loss / len(val_loader)\n",
    "    avg_result = {key: sum(r[key] for r in all_results) / len(all_results) for key in all_results[0]}\n",
    "    \n",
    "    writer.add_scalar('Loss/valid', val_loss, epoch)\n",
    "    writer.add_scalar('ROUGE/rouge-1', avg_result['rouge-1'], epoch)\n",
    "    writer.add_scalar('ROUGE/rouge-2', avg_result['rouge-2'], epoch)\n",
    "    writer.add_scalar('ROUGE/rouge-l', avg_result['rouge-l'], epoch)\n",
    "\n",
    "    return val_loss, avg_result, all_predictions, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = float('inf')\n",
    "early_stopping_counter = 0\n",
    "writer = SummaryWriter(log_dir=logs_path)\n",
    "scheduler = CosineAnnealingWarmUpRestarts(optimizer, T_0=config['training']['T_0'], T_mult=config['training']['T_mult'], eta_max=config['training']['max_lr'],  T_up=config['training']['warmup_epochs'], gamma=config['training']['T_gamma'])\n",
    "\n",
    "for epoch in range(1, config['training']['epochs'] + 1):\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Epoch {epoch}/{config['training']['epochs']}, Current Learning Rate: {current_lr:.6f}\")\n",
    "    \n",
    "    train_loss = train(epoch, model, device, train_loader, optimizer, writer, config['training']['accumulation_steps'])    \n",
    "    val_loss, val_result, val_predictions, val_labels = validate(tokenizer, model, device, val_loader, writer, epoch)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.6f}, Valid Loss: {val_loss:.6f}\")\n",
    "    print(f\"Rouge-1: {val_result['rouge-1']:.6f}, Rouge-2: {val_result['rouge-2']:.6f}, Rouge-l: {val_result['rouge-l']:.6f}\")\n",
    "\n",
    "    scheduler.step()\n",
    "    print('-'*150)\n",
    "    \n",
    "    for i in range(3):\n",
    "        print(f\"PRED: {val_predictions[i].strip()}\")\n",
    "        print(f\"GOLD: {val_labels[i]}\")\n",
    "        print('-'*150)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stopping_counter = 0\n",
    "        torch.save(model.state_dict(), os.path.join(weights_path, 'best_finetune.pth'))\n",
    "        print(f\"New best model saved with validation loss: {best_val_loss:.6f}\")\n",
    "    \n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        print(f\"Not improved. Early stopping counter: {early_stopping_counter}/{config['training']['patience']}\")\n",
    "\n",
    "    if early_stopping_counter >= config['training']['patience']:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "writer.close()\n",
    "torch.save(model.state_dict(), os.path.join(weights_path, 'last_finetune.pth'))\n",
    "print(\"Training completed. Last model saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tokenizer, model, device, test_loader, fname):\n",
    "    model.eval()\n",
    "    summary = []\n",
    "    with torch.no_grad():\n",
    "        for input_ids in tqdm(test_loader):\n",
    "            input_ids = input_ids.to(device, dtype=torch.long)\n",
    "\n",
    "            pred_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                max_length=config['inference']['generate_max_length'], \n",
    "                num_beams=config['inference']['num_beams'],\n",
    "                repetition_penalty=2.0, \n",
    "                length_penalty=1.0, \n",
    "                early_stopping=True,\n",
    "                no_repeat_ngram_size=2\n",
    "            )\n",
    "            for ids in pred_ids:\n",
    "                result = tokenizer.decode(ids)\n",
    "                summary.append(result)\n",
    "                \n",
    "    # remove_tokens = ['<usr>', f\"{tokenizer.unk_token}\", f\"{tokenizer.eos_token}\", f\"{tokenizer.pad_token}\"]\n",
    "    preprocessed_summary = summary.copy()\n",
    "    for token in remove_tokens:\n",
    "        preprocessed_summary = [sentence.replace(token,\" \") for sentence in preprocessed_summary]\n",
    "\n",
    "    output = pd.DataFrame(\n",
    "        {\n",
    "            \"fname\": fname,\n",
    "            \"summary\" : preprocessed_summary,\n",
    "        }\n",
    "    )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(f'{save_path}/weights/best_finetune.pth'))\n",
    "output = predict(tokenizer, model, device, test_loader, test_df['fname'])\n",
    "output.to_csv(f\"{save_path}/prediction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from openai import OpenAI\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "data_top5 = pd.read_csv(\"../dataset/top5_samples.csv\")\n",
    "\n",
    "# content = \"Translate the following English sentence into conversational Korean. \\\n",
    "#            Ensure that the special strings like #string# are not translated. \\\n",
    "#            Names of people (e.g., Mr. Smith) and places (e.g., Hawkins) can be translated into Korean.\"\n",
    "\n",
    "content = f\"\"\"\n",
    "Translate the following English sentence into conversational Korean.\n",
    "Ensure that the special strings like #string# are not translated.\n",
    "Names of people (e.g., Mr. Smith) and places (e.g., Hawkins) can be translated into Korean.\n",
    "Here are some example summaries to guide the tone of the translation:\n",
    "example1. {data_top5.iloc[0]['summary']}\n",
    "example2. {data_top5.iloc[1]['summary']}\n",
    "example3. {data_top5.iloc[2]['summary']}\n",
    "example4. {data_top5.iloc[3]['summary']}\n",
    "example5. {data_top5.iloc[4]['summary']}\n",
    "example6. {data_top5.iloc[5]['summary']}\n",
    "example7. {data_top5.iloc[6]['summary']}\n",
    "example8. {data_top5.iloc[7]['summary']}\n",
    "example9. {data_top5.iloc[8]['summary']}\n",
    "example10. {data_top5.iloc[9]['summary']}\n",
    "\"\"\"\n",
    "\n",
    "def translate_text_with_gpt(text):\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": content},\n",
    "                {\"role\": \"user\", \"content\": text}\n",
    "            ]\n",
    "        )\n",
    "        translation = completion.choices[0].message.content.strip()\n",
    "        return translation\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during translation: {e}\")\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.read_csv(f\"{save_path}/prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = random.randint(0, output.shape[0]-1)\n",
    "print(f\"{idx:>08}\")\n",
    "\n",
    "sample_summary = output.loc[idx, 'summary']\n",
    "translated_summary = translate_text_with_gpt(sample_summary)\n",
    "\n",
    "print(\"Original Summary:\\n\",sample_summary,\"\\n\")\n",
    "print(\"Translated Summary:\\n\",translated_summary,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in tqdm(output.iterrows(), total=output.shape[0], desc=\"Translating summaries\"):\n",
    "    original_summary = row['summary']\n",
    "    translated_summary = translate_text_with_gpt(original_summary)\n",
    "    output.at[index, 'summary'] = translated_summary  # 번역된 값 대입\n",
    "\n",
    "output.to_csv(f\"{save_path}/translated_prediction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
