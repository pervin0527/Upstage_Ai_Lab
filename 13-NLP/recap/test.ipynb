{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import unicodedata\n",
    "\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "import unicodedata\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 유니코드 문자열을 아스키 문자열로 변환하는 함수\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# 문자열을 정규화하는 함수\n",
    "def normalize_string(s):\n",
    "    s = unicode_to_ascii(s.lower().strip())\n",
    "    s = re.sub(r\"([,.!?])\", r\" \\1 \", s)\n",
    "    s = re.sub(r\"[^a-zA-Z,.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "class MNTDataset(Dataset):\n",
    "    def __init__(self, txt_path, min_length, max_length):\n",
    "        self.X, self.Y = [], []\n",
    "        self.min_length = min_length\n",
    "        self.max_length = max_length\n",
    "        self.corpus = open(txt_path, 'r', encoding='utf-8').readlines()\n",
    "\n",
    "        self.preprocess()\n",
    "        self.build_vocab()\n",
    "\n",
    "    def preprocess(self):\n",
    "        for parallel in self.corpus:\n",
    "            src, trg, _ = parallel.strip().split('\\t')\n",
    "\n",
    "            ## src 문장이나 trg 문장이 비어있는 경우 제외.\n",
    "            if src.strip() == \"\" or trg.strip() == \"\":\n",
    "                continue\n",
    "\n",
    "            ## 문장을 정규화하고 단어 단위로 분리.\n",
    "            normalized_src = normalize_string(src).split()\n",
    "            normalized_trg = normalize_string(trg).split()\n",
    "\n",
    "            if len(normalized_src) >= self.min_length and len(normalized_trg) <= self.max_length \\\n",
    "            and len(normalized_trg) >= self.min_length and len(normalized_src) <= self.max_length:\n",
    "                self.X.append(normalized_src)\n",
    "                self.Y.append(normalized_trg)\n",
    "\n",
    "    def build_vocab(self):\n",
    "        flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "        self.source_vocab = list(set(flatten(self.X)))\n",
    "        self.target_vocab = list(set(flatten(self.Y)))\n",
    "        print(len(self.source_vocab), len(self.target_vocab))\n",
    "\n",
    "        self.source2index = {'<PAD>': 0, '<UNK>': 1, '<SOS>': 2, '<EOS>': 3}\n",
    "        self.target2index = {'<PAD>': 0, '<UNK>': 1, '<SOS>': 2, '<EOS>': 3}\n",
    "\n",
    "        for vocab in self.source_vocab:\n",
    "            if self.source2index.get(vocab) is None: ## 단어가 사전에 없다면\n",
    "                self.source2index[vocab] = len(self.source2index)\n",
    "        self.index2source = {v:k for k, v in self.source2index.items()}\n",
    "\n",
    "        for vocab in self.target_vocab:\n",
    "            if self.target2index.get(vocab) is None:\n",
    "                self.target2index[vocab] = len(self.target2index)\n",
    "        self.index2target = {v:k for k, v in self.target2index.items()}\n",
    "\n",
    "    def prepare_sequence(self, seq, to_index, max_len=None):\n",
    "        idxs = list(map(lambda w: to_index[w] if to_index.get(w) is not None else to_index[\"<UNK>\"], seq))\n",
    "        if max_len is not None:\n",
    "            # 패딩 추가\n",
    "            idxs = idxs + [to_index['<PAD>']] * (max_len - len(idxs))\n",
    "            idxs = idxs[:max_len]  # 최대 길이를 초과하지 않도록 자름\n",
    "        return torch.LongTensor(idxs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src = self.X[idx]\n",
    "        trg = self.Y[idx]\n",
    "        return src, trg\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        # 각 배치에서 소스와 타겟 시퀀스를 분리\n",
    "        batch_src, batch_trg = zip(*batch)\n",
    "\n",
    "        # 소스와 타겟 시퀀스의 최대 길이\n",
    "        max_len_src = max([len(s) for s in batch_src]) + 1  # +1 for <EOS>\n",
    "        max_len_trg = max([len(t) for t in batch_trg]) + 1  # +1 for <EOS>\n",
    "\n",
    "        # 시퀀스를 인덱스로 변환하고 패딩을 추가\n",
    "        src_sequences = [self.prepare_sequence(s + ['<EOS>'], self.source2index, max_len_src) for s in batch_src]\n",
    "        trg_sequences = [self.prepare_sequence(t + ['<EOS>'], self.target2index, max_len_trg) for t in batch_trg]\n",
    "\n",
    "        # 텐서로 결합\n",
    "        src_batch = torch.stack(src_sequences)\n",
    "        trg_batch = torch.stack(trg_sequences)\n",
    "\n",
    "        # 각 시퀀스의 길이 계산\n",
    "        src_lengths = [len(s) for s in batch_src]\n",
    "        trg_lengths = [len(t) for t in batch_trg]\n",
    "\n",
    "        return src_batch, trg_batch, src_lengths, trg_lengths\n",
    "\n",
    "    def get_dataloader(self, batch_size, shuffle, num_workers):\n",
    "        return DataLoader(self, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, collate_fn=self.collate_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNTDataset(\"/home/pervinco/Datasets/fra-eng/fra.txt\", 3, 25)\n",
    "\n",
    "print(len(dataset.X), len(dataset.Y))\n",
    "print(dataset.X[0], dataset.Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = dataset.get_dataloader(256, True, 32)\n",
    "\n",
    "for data in dataloader:\n",
    "    print(len(data))\n",
    "    print(data[0].shape)\n",
    "    print(data[1].shape)\n",
    "    print(data[2])\n",
    "    print(data[3])\n",
    "\n",
    "    print(data[0][0])\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "- ```torch.nn.utils.rnn.pack_padded_sequence``` : 패딩된 시퀀스를 입력 받아 패딩되지 않은 시퀀스로 변환.\n",
    "- RNN 계열이 패딩된 부분을 처리하지 않도록 도와준다.\n",
    "- 함수는 입력 시퀀스와 각 시퀀스의 실제 길이를 입력으로 받는다.\n",
    "\n",
    "- ```pad_packed_sequence``` : 패딩되지 않은 시퀀스를 입력으로 받아 패딩된 시퀀스로 변환한다.\n",
    "- 함수는 RNN 계열 모델의 출력을 처리할 때 사용되며 패딩된 시퀀스 형태로 복원해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, n_layers=1, bidirec=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size = input_size ## x_t의 차원\n",
    "        self.hidden_size = hidden_size ## h_t의 차원\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "\n",
    "        # 양방향 GRU를 사용할지 여부에 따라 GRU 레이어\n",
    "        # 양방향 GRU를 사용하면, n_direction을 2로 설정하고, 그렇지 않으면 1로 설정\n",
    "        if bidirec:\n",
    "            self.n_direction = 2\n",
    "            self.gru = nn.GRU(embedding_size, hidden_size, n_layers, batch_first=True, bidirectional=True)\n",
    "        else:\n",
    "            self.n_direction = 1\n",
    "            self.gru = nn.GRU(embedding_size, hidden_size, n_layers, batch_first=True)\n",
    "\n",
    "    # 은닉 상태를 초기화하는 함수\n",
    "    # 입력의 크기에 따라 0으로 채워진 텐서를 생성하고, CUDA를 사용할 경우 GPU로 이동\n",
    "    def init_hidden(self, inputs):\n",
    "        hidden = Variable(torch.zeros(self.n_layers * self.n_direction, inputs.size(0), self.hidden_size))\n",
    "        return hidden.cuda() if USE_CUDA else hidden\n",
    "\n",
    "    # 가중치를 초기화하는 함수\n",
    "    # 임베딩 레이어와 GRU 레이어의 가중치를 xavier_uniform 방식으로 초기화\n",
    "    def init_weight(self):\n",
    "        self.embedding.weight = nn.init.xavier_uniform(self.embedding.weight)\n",
    "        self.gru.weight_hh_l0 = nn.init.xavier_uniform(self.gru.weight_hh_l0)\n",
    "        self.gru.weight_ih_l0 = nn.init.xavier_uniform(self.gru.weight_ih_l0)\n",
    "\n",
    "    # 순전파 정의\n",
    "    # 입력과 입력 길이를 받아서 임베딩 레이어와 GRU 레이어를 통과\n",
    "    # GRU 레이어의 출력과 은닉 상태를 반환\n",
    "    def forward(self, inputs, input_lengths):\n",
    "        hidden = self.init_hidden(inputs)\n",
    "\n",
    "        embedded = self.embedding(inputs)\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths, batch_first=True)\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
    "\n",
    "        # 레이어 수가 1보다 크면, 마지막 두 레이어의 은닉 상태를 사용하고, 그렇지 않으면 마지막 레이어의 은닉 상태를 사용\n",
    "        if self.n_layers > 1:\n",
    "            if self.n_direction == 2:\n",
    "                hidden = hidden[-2:]\n",
    "            else:\n",
    "                hidden = hidden[-1]\n",
    "\n",
    "        return outputs, torch.cat([h for h in hidden], 1).unsqueeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, n_layers=1, dropout_p=0.1):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "        # GRU 레이어를 생성. 임베딩 크기 + 은닉층 크기, 은닉층 크기, 레이어 수를 인자로 받음\n",
    "        self.gru = nn.GRU(embedding_size + hidden_size, hidden_size, n_layers, batch_first=True)\n",
    "        # 선형 레이어를 생성. 은닉층 크기 * 2, 입력 크기를 인자로 받음\n",
    "        self.linear = nn.Linear(hidden_size * 2, input_size)\n",
    "        # Attention 레이어를 생성. 은닉층 크기를 인자로 받음\n",
    "        self.attn = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "\n",
    "    # 은닉 상태를 초기화하는 함수\n",
    "    def init_hidden(self,inputs):\n",
    "        hidden = Variable(torch.zeros(self.n_layers, inputs.size(0), self.hidden_size))\n",
    "        return hidden.cuda() if USE_CUDA else hidden\n",
    "\n",
    "    # 가중치를 초기화하는 함수\n",
    "    def init_weight(self):\n",
    "        self.embedding.weight = nn.init.xavier_uniform(self.embedding.weight)\n",
    "        self.gru.weight_hh_l0 = nn.init.xavier_uniform(self.gru.weight_hh_l0)\n",
    "        self.gru.weight_ih_l0 = nn.init.xavier_uniform(self.gru.weight_ih_l0)\n",
    "        self.linear.weight = nn.init.xavier_uniform(self.linear.weight)\n",
    "        self.attn.weight = nn.init.xavier_uniform(self.attn.weight)\n",
    "\n",
    "    # Attention 메커니즘을 구현하는 함수\n",
    "    def Attention(self, hidden, encoder_outputs, encoder_maskings):\n",
    "        \"\"\"\n",
    "        hidden : 1,B,D\n",
    "        encoder_outputs : B,T,D\n",
    "        encoder_maskings : B,T # ByteTensor\n",
    "        \"\"\"\n",
    "        # hidden의 차원을 변경\n",
    "        hidden = hidden[0].unsqueeze(2)  # (1,B,D) -> (B,D,1)\n",
    "\n",
    "        # encoder_outputs의 크기를 가져옴\n",
    "        batch_size = encoder_outputs.size(0) # B\n",
    "        max_len = encoder_outputs.size(1) # T\n",
    "        # attention 에너지를 계산\n",
    "        energies = self.attn(encoder_outputs.contiguous().view(batch_size * max_len, -1)) # B*T,D -> B*T,D\n",
    "        energies = energies.view(batch_size,max_len, -1) # B,T,D\n",
    "        attn_energies = energies.bmm(hidden).squeeze(2) # B,T,D * B,D,1 --> B,T\n",
    "\n",
    "        # softmax를 사용하여 attention 가중치를 계산\n",
    "        alpha = F.softmax(attn_energies,1) # B,T\n",
    "        alpha = alpha.unsqueeze(1) # B,1,T\n",
    "        # context 벡터를 계산\n",
    "        context = alpha.bmm(encoder_outputs) # B,1,T * B,T,D => B,1,D\n",
    "\n",
    "        return context, alpha\n",
    "\n",
    "# 순전파 함수\n",
    "    def forward(self, inputs, context, max_length, encoder_outputs, encoder_maskings=None, is_training=False):\n",
    "        \"\"\"\n",
    "        inputs : B,1 (torch.LongTensor, 시작 심볼)\n",
    "        context : B,1,D (FloatTensor, 마지막 인코더 은닉 상태)\n",
    "        max_length : int, 디코딩할 최대 길이\n",
    "        encoder_outputs : B,T,D\n",
    "        encoder_maskings : B,T # ByteTensor\n",
    "        is_training : bool, 드롭아웃을 훈련 단계에서만 적용하기 위함\n",
    "        \"\"\"\n",
    "\n",
    "        embedded = self.embedding(inputs)\n",
    "        hidden = self.init_hidden(inputs)\n",
    "\n",
    "        if is_training:\n",
    "            embedded = self.dropout(embedded)\n",
    "\n",
    "        decode = []\n",
    "        for i in range(max_length):\n",
    "            # GRU의 입력으로 embedded와 context를 연결한 것을 사용\n",
    "            _, hidden = self.gru(torch.cat((embedded, context), 2), hidden) # h_t = f(h_{t-1},y_{t-1},c)\n",
    "\n",
    "            # hidden과 context를 연결하여 concated를 생성\n",
    "            concated = torch.cat((hidden, context.transpose(0, 1)), 2) # y_t = g(h_t,y_{t-1},c)\n",
    "\n",
    "            # 선형 레이어를 통해 score를 계산\n",
    "            score = self.linear(concated.squeeze(0))\n",
    "\n",
    "            # score에 softmax를 적용하여 확률 분포를 얻음\n",
    "            softmaxed = F.log_softmax(score,1)\n",
    "\n",
    "            # softmaxed를 decode 리스트에 추가\n",
    "            decode.append(softmaxed)\n",
    "\n",
    "            # softmaxed의 최대값 인덱스를 decoded에 저장\n",
    "            decoded = softmaxed.max(1)[1]\n",
    "\n",
    "            # decoded를 임베딩하여 embedded를 업데이트\n",
    "            embedded = self.embedding(decoded).unsqueeze(1) # y_{t-1}\n",
    "            \n",
    "            # 훈련 단계에서만 드롭아웃 적용\n",
    "            if is_training:\n",
    "                embedded = self.dropout(embedded)\n",
    "\n",
    "            # attention을 사용하여 다음 context 벡터를 계산\n",
    "            context, alpha = self.Attention(hidden, encoder_outputs, encoder_maskings)\n",
    "\n",
    "        # decode 리스트를 텐서로 변환\n",
    "        scores = torch.cat(decode, 1)\n",
    "        # scores의 크기를 변경\n",
    "        return scores.view(inputs.size(0) * max_length, -1)\n",
    "\n",
    "    # 디코딩 함수\n",
    "    def decode(self, context, encoder_outputs):\n",
    "        # 디코딩을 시작하는 심볼을 start_decode에 저장\n",
    "        start_decode = Variable(torch.LongTensor([[2] * 1])).transpose(0, 1)\n",
    "        # start_decode를 임베딩\n",
    "        embedded = self.embedding(start_decode)\n",
    "        # 은닉 상태를 초기화\n",
    "        hidden = self.init_hidden(start_decode)\n",
    "\n",
    "        decodes = []\n",
    "        attentions = []\n",
    "        decoded = embedded\n",
    "        # decoded가 종료 심볼이 될 때까지 반복\n",
    "        while decoded.data.tolist()[0] != 3: # </s>까지\n",
    "            # GRU의 입력으로 embedded와 context를 연결한 것을 사용\n",
    "            _, hidden = self.gru(torch.cat((embedded, context), 2), hidden) # h_t = f(h_{t-1},y_{t-1},c)\n",
    "            # hidden과 context를 연결하여 concated를 생성\n",
    "            concated = torch.cat((hidden, context.transpose(0, 1)), 2) # y_t = g(h_t,y_{t-1},c)\n",
    "            # 선형 레이어를 통해 score를 계산\n",
    "            score = self.linear(concated.squeeze(0))\n",
    "            # score에 softmax를 적용하여 확률 분포를 얻음\n",
    "            softmaxed = F.log_softmax(score,1)\n",
    "            # softmaxed를 decodes 리스트에 추가\n",
    "            decodes.append(softmaxed)\n",
    "            # softmaxed의 최대값 인덱스를 decoded에 저장\n",
    "            decoded = softmaxed.max(1)[1]\n",
    "            # decoded를 임베딩하여 embedded를 업데이트\n",
    "            embedded = self.embedding(decoded).unsqueeze(1) # y_{t-1}\n",
    "            # attention을 사용하여 다음 context 벡터를 계산\n",
    "            context, alpha = self.Attention(hidden, encoder_outputs,None)\n",
    "            # alpha를 attentions 리스트에 추가\n",
    "            attentions.append(alpha.squeeze(1))\n",
    "\n",
    "        # decodes 리스트를 텐서로 변환하고 최대값 인덱스를 반환\n",
    "        return torch.cat(decodes).max(1)[1], torch.cat(attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 함수 정의\n",
    "def train_model(encoder, decoder, dataloader, encoder_optimizer, decoder_optimizer, criterion, num_epochs, max_length):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for i, (src_seqs, trg_seqs) in enumerate(dataloader):\n",
    "            # CUDA 사용 여부에 따라 데이터를 GPU로 이동\n",
    "            src_seqs = src_seqs.squeeze(1)\n",
    "            trg_seqs = trg_seqs.squeeze(1)\n",
    "            if USE_CUDA:\n",
    "                src_seqs = src_seqs.cuda()\n",
    "                trg_seqs = trg_seqs.cuda()\n",
    "\n",
    "            # 입력 시퀀스의 길이 계산\n",
    "            input_lengths = torch.sum(src_seqs != 0, dim=1)\n",
    "\n",
    "            # 인코더의 forward 호출\n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "\n",
    "            encoder_outputs, encoder_hidden = encoder(src_seqs, input_lengths)\n",
    "\n",
    "            # 디코더의 첫 입력으로 <SOS> 토큰을 설정\n",
    "            decoder_input = torch.LongTensor([[2]] * src_seqs.size(0))\n",
    "            if USE_CUDA:\n",
    "                decoder_input = decoder_input.cuda()\n",
    "\n",
    "            # 인코더의 마지막 은닉 상태를 context로 사용\n",
    "            context = encoder_hidden.unsqueeze(0)\n",
    "\n",
    "            # 디코더의 forward 호출\n",
    "            decoder_output = decoder(decoder_input, context, max_length, encoder_outputs, is_training=True)\n",
    "\n",
    "            # 목표 시퀀스 길이에 맞게 타겟 시퀀스를 변경\n",
    "            target = trg_seqs[:, :max_length].contiguous().view(-1)\n",
    "            loss = criterion(decoder_output, target)\n",
    "            loss.backward()\n",
    "\n",
    "            # 가중치 업데이트\n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(dataloader):.4f}')\n",
    "\n",
    "# 데이터 로드\n",
    "dataset = MNTDataset(\"/home/pervinco/Datasets/fra-eng/fra.txt\", 3, 25)\n",
    "dataloader = dataset.get_dataloader(batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "# 인코더 및 디코더 초기화\n",
    "embedding_size = 256\n",
    "hidden_size = 512\n",
    "input_size_encoder = len(dataset.source2index)\n",
    "input_size_decoder = len(dataset.target2index)\n",
    "encoder = Encoder(input_size_encoder, embedding_size, hidden_size, n_layers=2, bidirec=True)\n",
    "decoder = Decoder(input_size_decoder, embedding_size, hidden_size, n_layers=2)\n",
    "\n",
    "# CUDA 사용 여부\n",
    "if USE_CUDA:\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "\n",
    "# 손실 함수 및 옵티마이저 정의\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=dataset.target2index['<PAD>'])\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=0.001)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=0.001)\n",
    "\n",
    "# 모델 학습\n",
    "num_epochs = 20\n",
    "max_length = 25\n",
    "train_model(encoder, decoder, dataloader, encoder_optimizer, decoder_optimizer, criterion, num_epochs, max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "upstage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
