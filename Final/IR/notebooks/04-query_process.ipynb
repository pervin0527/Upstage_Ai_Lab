{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/pervinco/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import torch\n",
    "import json\n",
    "import huggingface_hub\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "## LLM 정의 및 프롬프트 hub\n",
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "## Function call\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "## jsonl 파일 로더\n",
    "from langchain.document_loaders import JSONLoader\n",
    "\n",
    "## 인코더, 벡터 DB\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "## Huggingface와 Langchain 연동\n",
    "from langchain_huggingface.llms import HuggingFacePipeline\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from langchain.tools import Tool\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../keys.env\")\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
    "\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "huggingface_hub.login(hf_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## documents.jsonl 로드 및 처리\n",
    "\n",
    "1. 문서 데이터를 encoder 모델로 임베딩.\n",
    "2. Faiss를 벡터 DB로 정하고 벡터를 저장."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4272\n",
      "page_content='건강한 사람이 에너지 균형을 평형 상태로 유지하는 것은 중요합니다. 에너지 균형은 에너지 섭취와 에너지 소비의 수학적 동등성을 의미합니다. 일반적으로 건강한 사람은 1-2주의 기간 동안 에너지 균형을 달성합니다. 이 기간 동안에는 올바른 식단과 적절한 운동을 통해 에너지 섭취와 에너지 소비를 조절해야 합니다. 식단은 영양가 있는 식품을 포함하고, 적절한 칼로리를 섭취해야 합니다. 또한, 운동은 에너지 소비를 촉진시키고 근육을 강화시킵니다. 이렇게 에너지 균형을 유지하면 건강을 유지하고 비만이나 영양 실조와 같은 문제를 예방할 수 있습니다. 따라서 건강한 사람은 에너지 균형을 평형 상태로 유지하는 것이 중요하며, 이를 위해 1-2주의 기간 동안 식단과 운동을 조절해야 합니다.' metadata={'source': '/home/pervinco/Upstage_Ai_Lab/Final/IR/dataset/documents.jsonl', 'seq_num': 1}\n"
     ]
    }
   ],
   "source": [
    "loader = JSONLoader(\n",
    "    file_path='../dataset/documents.jsonl', \n",
    "    json_lines=True, \n",
    "    jq_schema='.content'  # 'content' 필드만 추출\n",
    ")\n",
    "documents = loader.load()\n",
    "print(len(documents))\n",
    "\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pervinco/miniconda3/envs/IR/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "벡터 DB에 저장된 벡터의 수: 4272\n",
      "입력한 텍스트의 수: 4272\n"
     ]
    }
   ],
   "source": [
    "## OpenAIEmbeddings로 임베딩\n",
    "# embedding_model = OpenAIEmbeddings()\n",
    "# embeddings = embedding_model.embed_documents([doc.page_content for doc in documents])\n",
    "\n",
    "## 벡터를 FAISS에 저장\n",
    "# faiss_index = FAISS.from_texts([doc.page_content for doc in documents], embedding_model)\n",
    "\n",
    "## Hugging Face Embeddings 설정\n",
    "model_name = \"jhgan/ko-sroberta-multitask\"\n",
    "model_kwargs = {\"device\": \"cuda:0\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": False}\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs)\n",
    "\n",
    "## 문서 내용 가져오기\n",
    "contents = [doc.page_content for doc in documents]\n",
    "\n",
    "## 벡터 DB 생성 및 저장\n",
    "vector_db = FAISS.from_texts(texts=contents, embedding=embedding_model)\n",
    "\n",
    "## 검색기 설정\n",
    "retriever = vector_db.as_retriever(search_kwargs={\"k\": 10})\n",
    "\n",
    "## 벡터 DB에 저장된 벡터의 수 확인\n",
    "print(f\"벡터 DB에 저장된 벡터의 수: {vector_db.index.ntotal}\")\n",
    "print(f\"입력한 텍스트의 수: {len(contents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='건강한 사람이 에너지 균형을 평형 상태로 유지하는 것은 중요합니다. 에너지 균형은 에너지 섭취와 에너지 소비의 수학적 동등성을 의미합니다. 일반적으로 건강한 사람은 1-2주의 기간 동안 에너지 균형을 달성합니다. 이 기간 동안에는 올바른 식단과 적절한 운동을 통해 에너지 섭취와 에너지 소비를 조절해야 합니다. 식단은 영양가 있는 식품을 포함하고, 적절한 칼로리를 섭취해야 합니다. 또한, 운동은 에너지 소비를 촉진시키고 근육을 강화시킵니다. 이렇게 에너지 균형을 유지하면 건강을 유지하고 비만이나 영양 실조와 같은 문제를 예방할 수 있습니다. 따라서 건강한 사람은 에너지 균형을 평형 상태로 유지하는 것이 중요하며, 이를 위해 1-2주의 기간 동안 식단과 운동을 조절해야 합니다.'),\n",
       " Document(metadata={}, page_content=\"에너지 전달은 다양한 형태와 방식으로 이루어집니다. 에너지는 한 형태에서 다른 형태로 전달될 수 있으며, 이는 우리 일상 생활에서도 많이 경험할 수 있습니다. 예를 들어, 태양에서 나오는 에너지는 태양광 전지를 통해 전기 에너지로 변환될 수 있습니다. 또한, 운동 에너지는 자전거의 페달을 밟으면서 전기 에너지로 변환될 수 있습니다. 이처럼 에너지 전달은 다양한 종류와 방식을 가지고 있습니다.\\n\\n하지만, 모든 종류의 에너지 전달을 가장 알맞게 설명하는 명제는 '사용할 수 있는 에너지의 감소를 초래합니다.'입니다. 에너지는 전달되는 과정에서 일부가 손실되기 때문에, 전달된 에너지의 양은 원래의 양보다 적어집니다. 이러한 손실은 에너지의 효율성을 나타내는 중요한 요소 중 하나입니다. 에너지 전달 과정에서 발생하는 손실을 최소화하기 위해 우리는 다양한 기술과 방법을 개발하고 연구하고 있습니다.\\n\\n에너지 전달은 우리의 삶과 사회에 매우 중요한 역할을 합니다. 우리는 에너지를 사용하여 가정이나 사무실을 데워주고, 차량을 움직이게 하며, 전자기기를 작동시킵니다. 따라서, 에너지 전달에 대한 이해와 연구는 우리의 삶의 질을 향상시키는 데에 큰 도움이 될 것입니다.\"),\n",
       " Document(metadata={}, page_content='적응성 열발생은 영양 상태의 변화 (영양 부족 또는 과잉)와 에너지 불균형을 최소화하기 위해 몸이 열 생산을 조절하는 메커니즘입니다. 이는 신체의 대사 활동을 통해 열을 생성하고, 온도 조절을 위해 열을 방출하는 과정을 포함합니다. 몸은 영양 상태에 따라 열 생산을 조절하여 에너지 불균형을 균형화하고, 영양 상태의 변화에 대응합니다. 이러한 적응성 열발생은 신체의 홈오스타시스를 유지하는 데 중요한 역할을 합니다. 따라서 영양 상태의 변화와 에너지 불균형을 최소화하기 위해 몸이 열 생산을 조절하는 것을 적응성 열발생이라고 합니다.'),\n",
       " Document(metadata={}, page_content='많은 국가가 화석 연료 에너지에 의존하고 있습니다. 그러나 일부 과학자들은 대신 재생 가능한 에너지원을 사용하는 것을 제안합니다. 그 이유는 환경에 더 안전하기 때문입니다. 재생 가능한 에너지원은 태양, 바람, 수력 등과 같은 자연의 자원을 이용하여 에너지를 생산합니다. 이러한 에너지원은 화석 연료와 달리 대기 오염, 온실 가스 배출, 지구 온난화 등의 부작용을 최소화합니다. 또한, 재생 가능한 에너지원은 무한히 사용할 수 있으며, 고갈되지 않습니다. 이는 에너지 안정성과 경제적 이익을 제공합니다. 따라서, 과학자들은 재생 가능한 에너지원 사용을 제안하고 있습니다.'),\n",
       " Document(metadata={}, page_content='에너지를 잘 흡수하는 객체는 잘 방사한다. 이는 에너지 보존의 법칙에 따라서 발생하는 현상이다. 에너지를 흡수하는 객체는 외부에서 들어오는 에너지를 흡수하여 내부에 저장하고, 이후에 필요한 시점에 다시 방출한다. 이러한 특성을 가진 객체는 다양한 분야에서 활용되고 있다. 예를 들어, 태양광 패널은 태양으로부터 에너지를 흡수하여 전기 에너지로 변환하는데 사용된다. 또한, 열 전달을 효율적으로 이루어지게 하기 위해 열 흡수체가 사용된다. 이러한 객체들은 에너지의 효율적인 이용을 가능하게 하며, 지속 가능한 에너지 시스템의 구축에 기여한다.'),\n",
       " Document(metadata={}, page_content='자동차 엔진은 시동이 걸리면 가솔린과 공기가 혼합되어 연소됩니다. 이 과정에서 열, 소리, 그리고 화학 제품이 방출됩니다. 그러나 엔진이 작동할 때 이 중 어느 것이 일정하게 유지되는지는 에너지 총량입니다. 에너지 총량은 시동이 걸린 후부터 엔진이 꺼질 때까지 변하지 않습니다. 이는 엔진의 효율성과 성능을 결정하는 중요한 요소입니다. 따라서 자동차 엔진의 작동 원리를 이해하고 유지보수를 위해서는 에너지 총량에 대한 이해가 필요합니다.'),\n",
       " Document(metadata={}, page_content='바람은 체사피크만의 남동쪽 해안에 이득을 주는 천연자원입니다. 이 바람은 어떤 방식으로 인간에게 가장 크게 이득을 줄까요? 바람은 전기 에너지로 변환될 수 있습니다. 바람은 풍력 발전기를 통해 전기로 변환될 수 있습니다. 풍력 발전기는 바람의 에너지를 이용하여 회전하는 발전기입니다. 회전하는 발전기는 전기를 생산하고 이를 인간이 사용할 수 있는 전기로 변환합니다. 이렇게 바람의 에너지를 전기로 변환함으로써 인간은 청정하고 지속 가능한 에너지를 얻을 수 있습니다. 바람의 에너지는 환경에 미치는 영향도 적고, 재생 가능한 에너지원으로 인간의 에너지 수요를 충족시킬 수 있습니다. 따라서 바람은 인간에게 가장 크게 이득을 주는 천연자원 중 하나입니다.'),\n",
       " Document(metadata={}, page_content='에너지 회사들은 종종 다양한 자원으로부터 전기를 생산합니다. 이러한 자원에는 풍력, 태양열, 수력, 화력 등이 포함됩니다. 그 중에서도 풍력은 대기질을 가장 크게 향상시키는 자원입니다. 풍력 발전은 바람의 힘을 이용하여 전기를 생산하는 것으로, 이는 환경에 친화적이며 대기질 오염을 최소화하는 방법 중 하나입니다. 바람은 자연적으로 발생하는 자원이기 때문에 에너지 회사들은 풍력 발전을 통해 지속 가능한 전기 생산을 실현할 수 있습니다. 풍력 발전소는 풍량이 많은 지역에 설치되며, 바람이 불면 터빈이 회전하여 전기를 생산합니다. 이러한 풍력 발전소는 대기질을 개선하고 환경을 보호하는 데 큰 역할을 합니다. 따라서, 풍력은 대기질을 가장 크게 향상시키는 자원으로 알려져 있습니다.'),\n",
       " Document(metadata={}, page_content='가르시아 선생님의 과학 수업에서는 에너지와 에너지 비용을 줄이는 방법을 공부하고 있습니다. 학생들은 10월의 전기 요금을 11월의 예상 요금과 비교해야 합니다. 이를 위해 각 학생은 11월 동안 실천할 에너지 절약 팁의 목록을 얻게 됩니다. 그러나 학생들의 조사에서 가장 통제할 수 없는 요소는 11월의 실외 온도입니다. 실외 온도는 계절에 따라 변동하기 때문에 학생들은 이를 고려하여 에너지 절약을 계획해야 합니다. 따라서 실외 온도가 낮을 때는 난방을 덜 사용하고, 실외 온도가 높을 때는 에어컨을 덜 사용하는 등의 조치를 취할 수 있습니다. 이렇게 실외 온도는 학생들이 통제할 수 없는 요소 중 하나이지만, 에너지 절약을 위해 적극적으로 고려되어야 합니다.'),\n",
       " Document(metadata={}, page_content='태양열 발전은 환경에 가장 적은 해를 끼치는 전기원 중 하나입니다. 태양열 발전은 태양에서 나오는 에너지를 이용하여 전기를 생산하는 과정입니다. 이 방식은 화석 연료를 사용하지 않으며, 이산화탄소와 같은 온실가스를 배출하지 않습니다. 따라서 태양열 발전은 대기 오염과 기후 변화에 큰 영향을 미치지 않습니다. 또한, 태양은 무한한 자원이기 때문에 태양열 발전은 지속 가능한 에너지 소스입니다. 태양열 발전은 환경 보호와 에너지 절약을 동시에 실현할 수 있는 효과적인 전기원입니다.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"에너지 균형을 유지하는 방법은 무엇인가요?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eval.jsonl 로드 및 처리\n",
    "\n",
    "```eval.jsonl``` 파일 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220\n",
      "dict_keys(['eval_id', 'msg'])\n"
     ]
    }
   ],
   "source": [
    "def load_jsonl(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return [json.loads(line) for line in f]\n",
    "\n",
    "eval_data = load_jsonl(\"../dataset/eval.jsonl\")\n",
    "print(len(eval_data))\n",
    "print(eval_data[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dialogue_format(messages):\n",
    "    dialogue = \"\"\n",
    "    for msg in messages:\n",
    "        role = msg['role']\n",
    "        content = msg['content']\n",
    "        if role == 'user':\n",
    "            dialogue += f\"user: {content}\\n\"\n",
    "        elif role == 'assistant':\n",
    "            dialogue += f\"assistant: {content}\\n\"\n",
    "    return dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': '나무의 분류에 대해 조사해 보기 위한 방법은?'}]\n",
      "user: 나무의 분류에 대해 조사해 보기 위한 방법은?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample1 = eval_data[0]['msg']\n",
    "print(sample1)\n",
    "\n",
    "dialogue1 = convert_to_dialogue_format(sample1)\n",
    "print(dialogue1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': '이란 콘트라 사건이 뭐야'}, {'role': 'assistant', 'content': '이란-콘트라 사건은 로널드 레이건 집권기인 1986년에 레이건 행정부와 CIA가 적성국이었던 이란에게 무기를 몰래 수출한 대금으로 니카라과의 우익 성향 반군 콘트라를 지원하면서 동시에 반군으로부터 마약을 사들인 후 미국에 판매하다가 발각되어 큰 파장을 일으킨 사건입니다.'}, {'role': 'user', 'content': '이 사건이 미국 정치에 미친 영향은?'}]\n",
      "user: 이란 콘트라 사건이 뭐야\n",
      "assistant: 이란-콘트라 사건은 로널드 레이건 집권기인 1986년에 레이건 행정부와 CIA가 적성국이었던 이란에게 무기를 몰래 수출한 대금으로 니카라과의 우익 성향 반군 콘트라를 지원하면서 동시에 반군으로부터 마약을 사들인 후 미국에 판매하다가 발각되어 큰 파장을 일으킨 사건입니다.\n",
      "user: 이 사건이 미국 정치에 미친 영향은?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample2 = eval_data[8]['msg']\n",
    "print(sample2)\n",
    "\n",
    "dialogue2 = convert_to_dialogue_format(sample2)\n",
    "print(dialogue2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': '요새 너무 힘들다.'}]\n",
      "user: 요새 너무 힘들다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample3 = eval_data[21]['msg']\n",
    "print(sample3)\n",
    "\n",
    "dialogue3 = convert_to_dialogue_format(sample3)\n",
    "print(dialogue3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM agent\n",
    "\n",
    "1. LLama3 모델, 토크나이저 로드\n",
    "2. Fucntion Call 정의\n",
    "\n",
    "상황별로 내가 정해주는게 아니라 LLM이 알아서, 스스로 판단하는 것이 핵심.\n",
    "\n",
    "다음과 같은 처리 파이프라인을 정의하고자 함.\n",
    "1. 질의가 멀티턴(multi-turn) 대화인 경우 LLM이 정리해서 Standalone Query를 생성하고 멀티턴이 아닌 경우 건너뛴다.\n",
    "2. 질의가 ```과학상식```에 해당한다면 encoder로 전달해 임베딩하고 벡터 db로 전달해 유사도 기반 검색을 수행한다. 그렇지 않은 경우 \"답변할 수 없습니다.\"로 처리한다.\n",
    "\n",
    "Reference\n",
    "\n",
    "- [https://python.langchain.com/docs/integrations/chat/](https://python.langchain.com/docs/integrations/chat/)\n",
    "- [https://github.com/sionic-ai/xionic-ko-llama-3-70b](https://github.com/sionic-ai/xionic-ko-llama-3-70b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(base_url=\"http://sionic.chat:8001/v1\",\n",
    "                 api_key=\"934c4bbc-c384-4bea-af82-1450d7f8128d\",\n",
    "                 model=\"xionic-ko-llama-3-70b\",\n",
    "                 temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pervinco/miniconda3/envs/IR/lib/python3.9/site-packages/langsmith/client.py:323: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"hwchase17/react-chat-json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_standalone_query(query):\n",
    "    if isinstance(query, str) and \"user:\" in query and \"assistant:\" in query:\n",
    "        conversation_lines = query.split(\"\\n\")\n",
    "        \n",
    "        # 대화의 전체 맥락을 활용하여 standalone query 생성\n",
    "        standalone_query = \" \".join([line.strip() for line in conversation_lines if line])\n",
    "\n",
    "        return {\n",
    "            \"query\": standalone_query,\n",
    "            \"multi-turn\": True\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"query\": query.strip(),\n",
    "            \"multi-turn\": False\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_85482/1084847435.py:16: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 1.0. Use :meth:`~Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc.` instead.\n",
      "  agent = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "# Tool definition\n",
    "standalone_query_tool = Tool(\n",
    "    name=\"Standalone Query Generator\",\n",
    "    func=create_standalone_query,\n",
    "    description=\"This tool processes dialogue history and generates a standalone query. \\\n",
    "                 For single-turn dialogues, it returns 'multi-turn: False' and the query unchanged as 'query: query'. \\\n",
    "                 For multi-turn dialogues, the tool extracts the user's last question and generates a concise standalone query based on the context of previous interactions. \\\n",
    "                 It returns 'query: standalone_query' and 'multi-turn: True'. \\\n",
    "                 The purpose is to enable the LLM to efficiently summarize dialogue history and generate actionable queries for further processing.\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 에이전트 초기화\n",
    "tools = [standalone_query_tool]\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    llm=ChatOpenAI(),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use the Standalone Query Generator tool to generate a concise standalone query based on the context of the previous interactions.\n",
      "Action: Standalone Query Generator\n",
      "Action Input: 나무의 분류에 대해 조사해 보기 위한 방법은?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'query': '나무의 분류에 대해 조사해 보기 위한 방법은?', 'multi-turn': False}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe query is already standalone, no need for further action.\n",
      "Final Answer: 나무의 분류에 대해 조사해 보기 위한 방법은?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'user: 나무의 분류에 대해 조사해 보기 위한 방법은?\\n', 'output': '나무의 분류에 대해 조사해 보기 위한 방법은?'}\n"
     ]
    }
   ],
   "source": [
    "output_single_turn = agent.invoke(dialogue1)\n",
    "print(output_single_turn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use the Standalone Query Generator to extract the user's last question and generate a concise standalone query.\n",
      "Action: Standalone Query Generator\n",
      "Action Input: 이 사건이 미국 정치에 미친 영향은?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'query': '이 사건이 미국 정치에 미친 영향은?', 'multi-turn': False}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: 이 사건이 미국 정치에 미친 영향은 미국 내에서 큰 파장을 일으켰습니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'user: 이란 콘트라 사건이 뭐야\\nassistant: 이란-콘트라 사건은 로널드 레이건 집권기인 1986년에 레이건 행정부와 CIA가 적성국이었던 이란에게 무기를 몰래 수출한 대금으로 니카라과의 우익 성향 반군 콘트라를 지원하면서 동시에 반군으로부터 마약을 사들인 후 미국에 판매하다가 발각되어 큰 파장을 일으킨 사건입니다.\\nuser: 이 사건이 미국 정치에 미친 영향은?\\n', 'output': '이 사건이 미국 정치에 미친 영향은 미국 내에서 큰 파장을 일으켰습니다.'}\n"
     ]
    }
   ],
   "source": [
    "output_multi_turn = agent.invoke(dialogue2)\n",
    "print(output_multi_turn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "standalone_content = (\"입력된 내용이 한 줄의 문장인지 여러 줄의 대화 내용인지 분류하세요. 분류 결과에 따라 다음과 같이 json 형식으로 응답합니다.\"\n",
    "                      \"- 단일 문장인 경우 : {multi_turn:False, query:입력 문장} \"\n",
    "                      \"- 여러 줄의 대화 내용은 경우 : {multi_turn:True, query: 대화 내용을 종합하여 만든 새로운 질문}\")\n",
    "\n",
    "def create_standalone_query(query):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        # response_format={\"type\":\"json_object\"},\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": standalone_content},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    response = completion.choices[0].message.content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_content = (\"입력된 내용이 교육 또는 일반 상식 또는 과학 상식에 대한 질문에 해당하는지 분류하세요. 분류 결과에 따라 다음과 같이 json 형식으로 응답합니다.\"\n",
    "                  \"- 교육이나 과학 상식에 대한 질문이 아닌 일상 대화인 경우 : {out_of_domain: True, query: 적절한 응답을 할 수 없습니다.}\"\n",
    "                  \"- 교육이나 과학 상식에 대한 질문인 경우 : {out_of_domain: False, query: 입력된 쿼리를 그대로 반환한다.}\")\n",
    "\n",
    "def domain_check(query):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        # response_format={\"type\":\"json_object\"},\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": domain_content},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    response = completion.choices[0].message.content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"multi_turn\": False,\n",
      "  \"query\": \"나무의 분류에 대해 조사해 보기 위한 방법은?\"\n",
      "}\n",
      "{\n",
      "  \"out_of_domain\": False,\n",
      "  \"query\": \"나무의 분류에 대해 조사해 보기 위한 방법은?\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "result1 = create_standalone_query(dialogue1)\n",
    "print(result1)\n",
    "\n",
    "print(domain_check(result1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"multi_turn\": True,\n",
      "  \"query\": \"이란-콘트라 사건이 미국 정치에 미친 영향은 무엇인가요?\"\n",
      "}\n",
      "{\n",
      "  \"out_of_domain\": False,\n",
      "  \"query\": \"이란-콘트라 사건이 미국 정치에 미친 영향은 무엇인가요?\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "result2 = create_standalone_query(dialogue2)\n",
    "print(result2)\n",
    "\n",
    "print(domain_check(result2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{multi_turn:False, query: \"요새 너무 힘들다.\"}\n",
      "{\n",
      "  \"out_of_domain\": True,\n",
      "  \"query\": \"적절한 응답을 할 수 없습니다.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "result3 = create_standalone_query(dialogue3)\n",
    "print(result3)\n",
    "\n",
    "print(domain_check(result3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
