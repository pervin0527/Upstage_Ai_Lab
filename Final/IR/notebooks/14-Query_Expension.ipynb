{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/pervinco/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import faiss\n",
    "import warnings\n",
    "import huggingface_hub\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "from langchain.schema import Document\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../keys.env\")\n",
    "\n",
    "upstage_api_key = os.getenv(\"UPSTAGE_API_KEY\")\n",
    "os.environ['UPSTAGE_API_KEY'] = upstage_api_key\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
    "\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "huggingface_hub.login(hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "model = \"gpt-4o\"\n",
    "\n",
    "# client = OpenAI(\n",
    "#     api_key=upstage_api_key,\n",
    "#     base_url=\"https://api.upstage.ai/v1/solar\"\n",
    "# )\n",
    "# model = \"solar-pro\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_json_response(response):\n",
    "    # 코드 블록(예: ```json, ```) 제거\n",
    "    cleaned_response = re.sub(r'```(?:json)?', '', response).strip()\n",
    "    \n",
    "    return cleaned_response\n",
    "\n",
    "def query_expansion(query, model:str, client:OpenAI):\n",
    "    content = (\n",
    "        \" 당신은 한국어 질의를 이해하여 정확한 문서들을 검색하도록 질의를 개선하는 전문가입니다. \"\n",
    "        \" 사용자의 질문 의도를 명확히 파악하고, 그 의도를 유지하면서 검색 시스템이 관련 문서를 더 잘 찾을 수 있도록 질의를 더 명확하게 만드세요. \"\n",
    "        \" 생성된 질의는 반드시 사용자의 본래 의도를 반영해야 하며, 새로운 정보나 본래 질의에 포함되지 않은 세부 정보(예: 국가, 인물, 특정 사건 등)를 임의로 추가하지 마세요. \"\n",
    "         \"오직 사용자가 제공한 정보만을 바탕으로 질의를 확장하고, 검색에 필수적인 정보만 포함하도록 하세요. \"\n",
    "        \" 또한, 확장된 질의는 자연스러운 문장 형태로 제공되어야 합니다. \"\n",
    "        \" 반환하는 형식은 반드시 JSON 포맷이어야 하며, 모든 문자열은 쌍따옴표로 감싸야 합니다. \"\n",
    "        '{ \"query\": \"확장된 자연스러운 질의\" }.'\n",
    "    )\n",
    "\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\" : \"system\", \"content\" : content},\n",
    "            {\"role\" : \"user\", \"content\" : query}\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    response = completion.choices[0].message.content\n",
    "    response = clean_json_response(response)\n",
    "    \n",
    "    try:\n",
    "        json_response = json.loads(response)\n",
    "    except json.JSONDecodeError:\n",
    "        return {\"error\": \"Invalid JSON response\", \"response\": response}\n",
    "    \n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return [json.loads(line) for line in f]\n",
    "\n",
    "def load_query(query_path, model, client, output_path):\n",
    "    queries = load_jsonl(query_path)\n",
    "    expanded_queries = []\n",
    "\n",
    "    for query_data in queries:\n",
    "        eval_id = query_data['eval_id']\n",
    "        msg_history = query_data['msg']\n",
    "        \n",
    "        conversation_history = \" \".join([msg['content'] for msg in msg_history if msg['role'] == 'user'])\n",
    "        \n",
    "        expanded_query_result = query_expansion(conversation_history, model, client)\n",
    "        print(eval_id)\n",
    "        print(conversation_history)\n",
    "        print(expanded_query_result['query'], '\\n')\n",
    "        \n",
    "        expanded_queries.append({\n",
    "            \"eval_id\": eval_id,\n",
    "            \"original_conversation\": conversation_history,\n",
    "            \"expanded_query\": expanded_query_result.get('query', 'Expansion failed')\n",
    "        })\n",
    "    \n",
    "    # Save expanded queries to a jsonl file\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for query in expanded_queries:\n",
    "            json.dump(query, f, ensure_ascii=False)\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n",
      "나무의 분류에 대해 조사해 보기 위한 방법은?\n",
      "나무의 분류를 조사하는 방법 \n",
      "\n",
      "213\n",
      "각 나라에서의 공교육 지출 현황에 대해 알려줘.\n",
      "각 나라의 공교육 지출 현황 \n",
      "\n",
      "107\n",
      "기억 상실증 걸리면 너무 무섭겠다. 어떤 원인 때문에 발생하는지 궁금해.\n",
      "기억 상실증의 발생 원인 \n",
      "\n",
      "81\n",
      "통학 버스의 가치에 대해 말해줘.\n",
      "통학 버스의 가치와 중요성 \n",
      "\n",
      "280\n",
      "Dmitri Ivanovsky가 누구야?\n",
      "Dmitri Ivanovsky라는 인물에 대한 정보 \n",
      "\n",
      "10\n",
      "피임을 하기 위한 방법중 약으로 처리하는 방법은 쓸만한가?\n",
      "피임을 위한 방법 중 약을 사용하는 것이 효과적인지 평가 \n",
      "\n",
      "100\n",
      "헬륨이 다른 원소들과 반응을 잘 안하는 이유는?\n",
      "헬륨이 다른 원소들과 반응을 잘 하지 않는 이유 \n",
      "\n",
      "279\n",
      "문맹 비율이 사회 발전에 미치는 영향은?\n",
      "문맹 비율이 사회 발전에 미치는 영향 \n",
      "\n",
      "42\n",
      "이란 콘트라 사건이 뭐야 이 사건이 미국 정치에 미친 영향은?\n",
      "이란 콘트라 사건의 내용과 이 사건이 미국 정치에 미친 영향 \n",
      "\n",
      "308\n",
      "자기장이 얼마나 센지 표현하는 방식은?\n",
      "자기장의 세기를 표현하는 방식 \n",
      "\n",
      "205\n",
      "피를 맑게 하고 몸 속의 노폐물을 없애는 역할을 하는 기관은?\n",
      "피를 맑게 하고 몸 속의 노폐물을 제거하는 인체 기관 \n",
      "\n",
      "289\n",
      "글리코겐의 분해는 인체에서 왜 필요한가?\n",
      "인체에서 글리코겐 분해의 필요성 \n",
      "\n",
      "268\n",
      "빗방울이 점점 커지게 되는 요인은?\n",
      "빗방울이 점점 커지게 되는 요인 \n",
      "\n",
      "18\n",
      "기체의 부피나 형태가 왜 일정하지 않을까?\n",
      "기체의 부피와 형태가 일정하지 않은 이유 \n",
      "\n",
      "9\n",
      "식물이 빛을 에너지로 변환하는 과정에 대해 설명해줘.\n",
      "식물이 빛을 에너지로 변환하는 광합성 과정에 대한 설명 \n",
      "\n",
      "101\n",
      "직류와 교류 전류의 차이에 대해 알려줘.\n",
      "직류 전류와 교류 전류의 차이 \n",
      "\n",
      "236\n",
      "기름과 물이 섞여 있을 수 있나?\n",
      "기름과 물의 혼합 가능성에 대한 설명 \n",
      "\n",
      "59\n",
      "인간이 2세를 생산할 때 DNA의 결합 과정에 대히 설명해줘.\n",
      "인간이 2세를 생산할 때 DNA의 결합 과정 설명 \n",
      "\n",
      "25\n",
      "금성에서 달이 어떻게 보일까?\n",
      "금성에서 관찰할 수 있는 달의 모습 \n",
      "\n",
      "5\n",
      "차량의 연비가 좋아질때 나타나는 긍정적인 효과는?\n",
      "차량의 연비가 좋아질 때 긍정적인 효과 \n",
      "\n",
      "104\n",
      "혼합물의 특성에 대해 알려줘.\n",
      "혼합물의 물리적 및 화학적 특성 \n",
      "\n",
      "276\n",
      "요새 너무 힘들다.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'query'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mload_query\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../dataset/eval.jsonl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../dataset/expanded_query.jsonl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 18\u001b[0m, in \u001b[0;36mload_query\u001b[0;34m(query_path, model, client, output_path)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(eval_id)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(conversation_history)\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mexpanded_query_result\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m     expanded_queries\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: eval_id,\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal_conversation\u001b[39m\u001b[38;5;124m\"\u001b[39m: conversation_history,\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpanded_query\u001b[39m\u001b[38;5;124m\"\u001b[39m: expanded_query_result\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpansion failed\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     24\u001b[0m     })\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Save expanded queries to a jsonl file\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'query'"
     ]
    }
   ],
   "source": [
    "load_query(\"../dataset/eval.jsonl\", model, client, \"../dataset/expanded_query.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
