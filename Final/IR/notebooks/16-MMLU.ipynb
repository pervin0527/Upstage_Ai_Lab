{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "from collections import defaultdict\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../keys.env\")\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['OPENAI_API_KEY'] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_path = \"../dataset/processed_documents.jsonl\"\n",
    "\n",
    "output_path = \"../dataset/custom\"\n",
    "os.makedirs(f\"{output_path}/arc\", exist_ok=True)\n",
    "os.makedirs(f\"{output_path}/mmlu\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmlu_documents = []\n",
    "arc_documents = []\n",
    "arc_file_path = f'{output_path}/arc_documents.jsonl'\n",
    "mmlu_file_path = f'{output_path}/mmlu_documents.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_domain(src_value):\n",
    "    # Extract the part after the second double underscore\n",
    "    parts = src_value.split('__')\n",
    "    if len(parts) >= 3:\n",
    "        return parts[1]\n",
    "    return None\n",
    "\n",
    "\n",
    "domains_documents = defaultdict(list)\n",
    "\n",
    "# Classify documents by their domain and save them\n",
    "with open(mmlu_file_path, 'w', encoding='utf-8') as mmlu_file:\n",
    "    for doc in mmlu_documents:\n",
    "        json.dump(doc, mmlu_file, ensure_ascii=False)\n",
    "        mmlu_file.write('\\n')\n",
    "\n",
    "        # Extract domain and group documents by domain\n",
    "        domain = extract_domain(doc['src'])\n",
    "        if domain:\n",
    "            domains_documents[domain].append(doc)\n",
    "\n",
    "# Save documents into separate files based on domain\n",
    "for domain, docs in domains_documents.items():\n",
    "    domain_file_path = f'{output_path}/mmlu/{domain}_documents.jsonl'\n",
    "    with open(domain_file_path, 'w', encoding='utf-8') as domain_file:\n",
    "        for doc in docs:\n",
    "            json.dump(doc, domain_file, ensure_ascii=False)\n",
    "            domain_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "model = \"gpt-4o\"\n",
    "\n",
    "def clean_json_response(response):\n",
    "    # 코드 블록(예: ```json, ```) 제거\n",
    "    cleaned_response = re.sub(r'```(?:json)?', '', response).strip()\n",
    "    return cleaned_response\n",
    "\n",
    "def generate_domain(document, model:str, client:OpenAI):\n",
    "    prompt = (\n",
    "        \"당신은 주어진 문서를 읽고 이해하여 핵심을 파악하는 언어 전문가입니다. \"\n",
    "        \" 해당 문서가 어떤 분야에 해당하는지 영어로 하나의 도메인을 정해야합니다. \"\n",
    "        \" 만약 두 개 이상의 단어로 도메인을 만드는 경우 '_'로 단어들을 연결하세요.\"\n",
    "        \" 반환하는 형식은 반드시 JSON 포맷이어야 하며, 모든 문자열은 쌍따옴표로 감싸야 합니다. \"\n",
    "        \" 형식은 다음과 같아야 합니다: \"\n",
    "        '{ \"domain\" : \"생성한 도메인\"}. '\n",
    "    )\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\" : \"system\", \"content\" : prompt},\n",
    "            {\"role\" : \"user\", \"content\" : document}\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    response = completion.choices[0].message.content\n",
    "    response = clean_json_response(response)\n",
    "    \n",
    "    try:\n",
    "        json_response = json.loads(response)\n",
    "    except json.JSONDecodeError:\n",
    "        return {\"error\": \"Invalid JSON response\", \"response\": response}\n",
    "    \n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(arc_file_path, 'w', encoding='utf-8') as arc_file:\n",
    "    for doc in arc_documents:\n",
    "        json.dump(doc, arc_file, ensure_ascii=False)\n",
    "        arc_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2047/2047 [23:52<00:00,  1.43it/s] \n"
     ]
    }
   ],
   "source": [
    "for doc in tqdm(arc_documents):\n",
    "    document_content = doc[\"content\"]\n",
    "    domain_info = generate_domain(document_content, model, client)\n",
    "    doc[\"domain\"] = domain_info['domain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_by_domain = {}\n",
    "for doc in arc_documents:\n",
    "    domain = doc[\"domain\"]\n",
    "    if domain not in documents_by_domain:\n",
    "        documents_by_domain[domain] = []\n",
    "    documents_by_domain[domain].append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257\n",
      "Acoustic_Technology\n",
      "Acoustics\n",
      "Aerospace_Engineering\n",
      "Agricultural_Science\n",
      "Agriculture\n",
      "Agriculture_Environmental_Science\n",
      "Agriculture_and_Fisheries\n",
      "Anatomy\n",
      "Anatomy_Education\n",
      "Animal_Behavior\n",
      "Animal_Behavior_Research\n",
      "Animal_Nutrition\n",
      "Animal_Training\n",
      "Aquaculture\n",
      "Aquarium_horticulture\n",
      "Architecture\n",
      "Art_and_Design\n",
      "Astrobiology\n",
      "Astronomy\n",
      "Astrophysics\n",
      "Atmospheric_Science\n",
      "Automotive\n",
      "Automotive_Engineering\n",
      "Automotive_Industry\n",
      "Automotive_Racing\n",
      "Automotive_Safety\n",
      "Aviation\n",
      "Behavioral_Science\n",
      "Biochemistry\n",
      "Biology\n",
      "Biomedical_Research\n",
      "Biomedical_Science\n",
      "Biophysics\n",
      "Biotechnology\n",
      "Botany\n",
      "Broadcasting\n",
      "Cardiology\n",
      "Carpentry\n",
      "Cell_Biology\n",
      "Chemistry\n",
      "Chemistry_Education\n",
      "Chemistry_Safety\n",
      "Civil_Engineering\n",
      "Climate_Change\n",
      "Climate_Science\n",
      "Climatology\n",
      "Communication_Technology\n",
      "Construction\n",
      "Consumer_Electronics\n",
      "Cooking\n",
      "Cosmology\n",
      "Culinary\n",
      "Culinary_Arts\n",
      "Cultural_Anthropology\n",
      "Data_Analysis\n",
      "Data_Visualization\n",
      "Dermatology\n",
      "Developmental_Biology\n",
      "Earth_Science\n",
      "Earth_science\n",
      "Ecology\n",
      "Education\n",
      "Education_Safety\n",
      "Education_Technology\n",
      "Electrical_Engineering\n",
      "Electrical_Safety\n",
      "Electronics\n",
      "Embryology\n",
      "Endocrinology\n",
      "Energy\n",
      "Energy_Conservation\n",
      "Energy_Efficiency\n",
      "Energy_Engineering\n",
      "Energy_Production\n",
      "Energy_Resources\n",
      "Energy_Storage\n",
      "Energy_Transfer\n",
      "Engineering\n",
      "Entomology\n",
      "Environment\n",
      "Environmental_Conservation\n",
      "Environmental_Economics\n",
      "Environmental_Education\n",
      "Environmental_Engineering\n",
      "Environmental_Health\n",
      "Environmental_Impact\n",
      "Environmental_Science\n",
      "Environmental_Studies\n",
      "Environmental_Sustainability\n",
      "Environmental_Technology\n",
      "Evolutionary_Biology\n",
      "Exercise_Physiology\n",
      "Exercise_Science\n",
      "Eyewear\n",
      "Fashion\n",
      "Fisheries_Research\n",
      "Food\n",
      "Food_Chemistry\n",
      "Food_Delivery\n",
      "Food_Safety\n",
      "Food_Science\n",
      "Forestry\n",
      "Gardening\n",
      "Genetic_Engineering\n",
      "Genetically_Modified_Organisms\n",
      "Genetics\n",
      "Genetics_and_Behavioral_Science\n",
      "Genomics\n",
      "Geography\n",
      "Geology\n",
      "Geometry\n",
      "Geophysics\n",
      "Geoscience\n",
      "Geothermal_Energy\n",
      "Government\n",
      "Health\n",
      "Health_Care\n",
      "Health_Fitness\n",
      "Health_Research\n",
      "Health_Science\n",
      "Health_and_Fitness\n",
      "Health_and_Nutrition\n",
      "Health_and_Wellness\n",
      "Healthcare\n",
      "Hematology\n",
      "History_of_Science\n",
      "History_of_Technology\n",
      "Home_Appliance\n",
      "Home_Appliances\n",
      "Home_Automation\n",
      "Home_Safety\n",
      "Horticulture\n",
      "Human_Biology\n",
      "Human_Physiology\n",
      "Human_Sensory_Perception\n",
      "Hydrology\n",
      "Immunology\n",
      "Interior_Design\n",
      "Investigation\n",
      "Kinesiology\n",
      "Lab_Safety\n",
      "Laboratory_Equipment\n",
      "Laboratory_Management\n",
      "Laboratory_Practices\n",
      "Laboratory_Safety\n",
      "Literature\n",
      "Logistics\n",
      "Marine_Biology\n",
      "Marine_Science\n",
      "Material_Science\n",
      "Materials_Science\n",
      "Mathematics\n",
      "Measurement\n",
      "Mechanical_Engineering\n",
      "Medicine\n",
      "Meteorology\n",
      "Microbiology\n",
      "Microscopy\n",
      "Mining\n",
      "Molecular_Biology\n",
      "Music\n",
      "Music_Performance\n",
      "Natural_Resource_Extraction\n",
      "Natural_Science\n",
      "Natural_Sciences\n",
      "Nephrology\n",
      "Neuroscience\n",
      "Nuclear_Energy\n",
      "Nuclear_Physics\n",
      "Nuclear_physics\n",
      "Nutrition\n",
      "Nutrition_Research\n",
      "Nutrition_Science\n",
      "Nutrition_and_Health\n",
      "Oceanography\n",
      "Optics\n",
      "Origins_of_Life\n",
      "Ornithology\n",
      "Outdoor_Recreation\n",
      "Paleobotany\n",
      "Paleoclimatology\n",
      "Paleontology\n",
      "Parasitology\n",
      "Pet_Care\n",
      "Petroleum_Geology\n",
      "Pharmaceutical\n",
      "Pharmaceutical_Ethics\n",
      "Pharmaceutical_Research\n",
      "Pharmaceuticals\n",
      "Pharmacology\n",
      "Philosophy\n",
      "Physical_Chemistry\n",
      "Physical_Sciences\n",
      "Physics\n",
      "Physics_Education\n",
      "Physics_Experiment\n",
      "Physiology\n",
      "Planetary_Science\n",
      "Problem_Solving\n",
      "Product_Design\n",
      "Public_Health\n",
      "Recreation\n",
      "Renewable_Energy\n",
      "Research_Methodology\n",
      "Retail_Jewelry\n",
      "Robotics\n",
      "Science\n",
      "Science_Communication\n",
      "Science_Education\n",
      "Science_Experiment\n",
      "Science_Experimentation\n",
      "Science_Research\n",
      "Science_and_Invention\n",
      "Science_education\n",
      "Scientific_Method\n",
      "Scientific_Methodology\n",
      "Scientific_Research\n",
      "Scientific_Research_Methodology\n",
      "Sewing_Technology\n",
      "Sociology\n",
      "Soil_Biology\n",
      "Soil_Science\n",
      "Space_Exploration\n",
      "Sports\n",
      "Sports_Science\n",
      "Statistics\n",
      "Supply_Chain_Management\n",
      "Sustainability\n",
      "Sustainable_Development\n",
      "Sustainable_Energy\n",
      "Sustainable_Materials\n",
      "Technology\n",
      "Technology_and_Innovation\n",
      "Thermal_Insulation\n",
      "Thermodynamics\n",
      "Urban_Planning\n",
      "Veterinary_Medicine\n",
      "Water_Conservation\n",
      "Water_Treatment\n",
      "Weather\n",
      "Weather_Climate\n",
      "Weather_Forecasting\n",
      "Wildlife_Conservation\n",
      "Wildlife_Tracking\n",
      "Zoology\n",
      "agriculture\n",
      "astronomy\n",
      "biology\n",
      "chemistry\n",
      "genetics\n",
      "home_safety\n",
      "mathematics\n",
      "meteorology\n",
      "physics\n",
      "science\n",
      "scientific_research\n",
      "환경학\n"
     ]
    }
   ],
   "source": [
    "print(len(documents_by_domain))\n",
    "\n",
    "for domain in sorted(documents_by_domain):\n",
    "    print(domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for domain, docs in documents_by_domain.items():\n",
    "    domain_file_path = f'{output_path}/arc/{domain}_documents.jsonl'\n",
    "    with open(domain_file_path, 'w', encoding='utf-8') as domain_file:\n",
    "        for doc in docs:\n",
    "            json.dump(doc, domain_file, ensure_ascii=False)\n",
    "            domain_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
