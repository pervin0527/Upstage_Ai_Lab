{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Insufficient parameters to connect",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/data/ephemeral/home/Upstage_Ai_Lab/Final/IR/src\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcassio\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mcassio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mauto\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/cassio/config/__init__.py:362\u001b[0m, in \u001b[0;36minit\u001b[0;34m(auto, session, secure_connect_bundle, init_string, token, database_id, keyspace, contact_points, username, password, cluster_kwargs, tempfile_basedir, bundle_url_template, cloud_kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;124;03mGlobally set the default Cassandra connection (/keyspace) for CassIO.\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03mThis default will be used by all other db-requiring CassIO instantiations,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03mwill be made available replacing the previous one.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m default_session, default_keyspace\n\u001b[0;32m--> 362\u001b[0m default_session, default_keyspace \u001b[38;5;241m=\u001b[39m \u001b[43mget_session_and_keyspace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauto\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauto\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43msecure_connect_bundle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msecure_connect_bundle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatabase_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatabase_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeyspace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeyspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontact_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontact_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43musername\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musername\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpassword\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcluster_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcluster_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtempfile_basedir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtempfile_basedir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbundle_url_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbundle_url_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloud_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcloud_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/cassio/config/__init__.py:258\u001b[0m, in \u001b[0;36mget_session_and_keyspace\u001b[0;34m(auto, session, secure_connect_bundle, init_string, token, database_id, keyspace, contact_points, username, password, cluster_kwargs, tempfile_basedir, bundle_url_template, cloud_kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo secure-connect-bundle was available.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 258\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInsufficient parameters to connect\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# keyspace to be resolved in any case\u001b[39;00m\n\u001b[1;32m    260\u001b[0m chosen_keyspace \u001b[38;5;241m=\u001b[39m _first_valid(\n\u001b[1;32m    261\u001b[0m     keyspace_from_arg, keyspace_from_is, keyspace_from_bundle\n\u001b[1;32m    262\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Insufficient parameters to connect"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/data/ephemeral/home/Upstage_Ai_Lab/Final/IR/src\")\n",
    "\n",
    "import cassio\n",
    "cassio.init(auto=True)\n",
    "\n",
    "import json\n",
    "import random\n",
    "import huggingface_hub\n",
    "\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../keys.env\")\n",
    "\n",
    "upstage_api_key = os.getenv(\"UPSTAGE_API_KEY\")\n",
    "os.environ['UPSTAGE_API_KEY'] = upstage_api_key\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
    "\n",
    "voyage_api_key = os.getenv('VOYAGE_API_KEY')\n",
    "os.environ['VOYAGE_API_KEY'] = voyage_api_key\n",
    "\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "huggingface_hub.login(hf_token)\n",
    "\n",
    "from langchain.schema import Document\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.graph_vectorstores.links import add_links\n",
    "from langchain_community.graph_vectorstores import CassandraGraphVectorStore\n",
    "from langchain_community.graph_vectorstores.extractors import KeybertLinkExtractor\n",
    "\n",
    "from config import Args\n",
    "from data.data import load_document, chunking, load_query\n",
    "from sparse_retriever.model import load_sparse_model\n",
    "from dense_retriever.model import load_dense_model, load_upstage_encoder, load_hf_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args()\n",
    "args.encoder_method = \"hugginface\"\n",
    "args.hf_model_name = \"dragonkue/bge-m3-ko\"\n",
    "args.doc_file_path = \"../dataset/processed_documents_queries.jsonl\"\n",
    "args.faiss_index_file = None\n",
    "\n",
    "args.chunk_size = 100\n",
    "args.chunk_overlap = 50\n",
    "\n",
    "documents = load_document(args.doc_file_path)\n",
    "print(len(documents))\n",
    "\n",
    "questions = load_query(args.doc_file_path)\n",
    "print(len(questions))\n",
    "\n",
    "random.shuffle(questions)\n",
    "questions = questions[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_chunks = chunking(args, documents)\n",
    "print(len(rec_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_map(gt, pred):    \n",
    "    sum_average_precision = 0    \n",
    "    for j in pred:        \n",
    "        if gt[j[\"eval_id\"]]:            \n",
    "            hit_count = 0            \n",
    "            sum_precision = 0            \n",
    "            for i,docid in enumerate(j[\"topk\"][:3]):                \n",
    "                if docid in gt[j[\"eval_id\"]]:                    \n",
    "                    hit_count += 1                    \n",
    "                    sum_precision += hit_count/(i+1)            \n",
    "            average_precision = sum_precision / hit_count if hit_count > 0 else 0        \n",
    "        else:            \n",
    "            average_precision = 0 if j[\"topk\"] else 1        \n",
    "        sum_average_precision += average_precision    \n",
    "    return sum_average_precision/len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = load_hf_encoder(args.hf_model_name, args.model_kwargs, args.encode_kwargs)\n",
    "vector_store = FAISS.from_documents(rec_chunks, embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = {}\n",
    "for question in questions:\n",
    "    query, question_id = question['query'], question['metadata']['docid']\n",
    "    gt[question_id] = [question_id]\n",
    "\n",
    "pred = []\n",
    "for question in tqdm(questions):\n",
    "    query, question_id = question['query'], question['metadata']['docid']\n",
    "    \n",
    "    search_result = vector_store.similarity_search_with_relevance_scores(query, k=3)\n",
    "    \n",
    "    topk_result = []\n",
    "    for doc, score in search_result:\n",
    "        topk_result.append(doc.metadata.get('docid'))\n",
    "\n",
    "    pred.append({\n",
    "        \"eval_id\": question_id,\n",
    "        \"topk\": topk_result\n",
    "    })\n",
    "\n",
    "mean_average_precision = calc_map(gt, pred)\n",
    "print(f\"Mean Average Precision (MAP): {mean_average_precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = KeybertLinkExtractor()\n",
    "\n",
    "for chunk in rec_chunks:\n",
    "    add_links(chunk, extractor.extract_one(chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = CassandraGraphVectorStore.from_documents(\n",
    "    embedding=embedder,\n",
    "    documents=documents,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = {}\n",
    "for question in questions:\n",
    "    query, question_id = question['query'], question['metadata']['docid']\n",
    "    gt[question_id] = [question_id]\n",
    "\n",
    "pred = []\n",
    "for question in tqdm(questions):\n",
    "    query, question_id = question['query'], question['metadata']['docid']\n",
    "    \n",
    "    search_result = vector_store.similarity_search_with_relevance_scores(query, k=3)\n",
    "    \n",
    "    topk_result = []\n",
    "    for doc, score in search_result:\n",
    "        topk_result.append(doc.metadata.get('docid'))\n",
    "\n",
    "    pred.append({\n",
    "        \"eval_id\": question_id,\n",
    "        \"topk\": topk_result\n",
    "    })\n",
    "\n",
    "mean_average_precision = calc_map(gt, pred)\n",
    "print(f\"Mean Average Precision (MAP): {mean_average_precision}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
