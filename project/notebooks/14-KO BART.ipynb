{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pervinco/miniconda3/envs/nlp-project/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from tqdm import tqdm\n",
    "from rouge import Rouge\n",
    "from datetime import datetime\n",
    "\n",
    "from torch import nn\n",
    "from konlpy.tag import Mecab\n",
    "from tensorboardX import SummaryWriter\n",
    "from transformers import AutoTokenizer\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, BartTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "epochs = 1000\n",
    "batch_size = 8\n",
    "accumulation_steps = 4\n",
    "num_workers = 0\n",
    "patience = 10\n",
    "\n",
    "init_lr = 0.000001\n",
    "max_lr = 0.00001\n",
    "weight_decay = 0\n",
    "warmup_epochs = 10\n",
    "T_0 = 100\n",
    "T_mult = 1\n",
    "T_gamma = 0.5\n",
    "\n",
    "dig_max_len = 512\n",
    "sum_max_len = 256\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "save_path = os.path.join(\"./BART_runs\", timestamp)\n",
    "\n",
    "weights_path = os.path.join(save_path, 'weights')\n",
    "logs_path = os.path.join(save_path, 'logs')\n",
    "os.makedirs(weights_path, exist_ok=True)\n",
    "os.makedirs(logs_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'PreTrainedTokenizerFast'. \n",
      "The class this function is called from is 'BartTokenizerFast'.\n",
      "You are using a model of type encoder-decoder to instantiate a model of type bart. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of BartForConditionalGeneration were not initialized from the model checkpoint at noahkim/KoBigBird-KoBart-News-Summarization and are newly initialized: ['decoder.embed_positions.weight', 'decoder.embed_tokens.weight', 'decoder.layernorm_embedding.bias', 'decoder.layernorm_embedding.weight', 'decoder.layers.0.encoder_attn.k_proj.bias', 'decoder.layers.0.encoder_attn.k_proj.weight', 'decoder.layers.0.encoder_attn.out_proj.bias', 'decoder.layers.0.encoder_attn.out_proj.weight', 'decoder.layers.0.encoder_attn.q_proj.bias', 'decoder.layers.0.encoder_attn.q_proj.weight', 'decoder.layers.0.encoder_attn.v_proj.bias', 'decoder.layers.0.encoder_attn.v_proj.weight', 'decoder.layers.0.encoder_attn_layer_norm.bias', 'decoder.layers.0.encoder_attn_layer_norm.weight', 'decoder.layers.0.fc1.bias', 'decoder.layers.0.fc1.weight', 'decoder.layers.0.fc2.bias', 'decoder.layers.0.fc2.weight', 'decoder.layers.0.final_layer_norm.bias', 'decoder.layers.0.final_layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.out_proj.bias', 'decoder.layers.0.self_attn.out_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.0.self_attn_layer_norm.bias', 'decoder.layers.0.self_attn_layer_norm.weight', 'decoder.layers.1.encoder_attn.k_proj.bias', 'decoder.layers.1.encoder_attn.k_proj.weight', 'decoder.layers.1.encoder_attn.out_proj.bias', 'decoder.layers.1.encoder_attn.out_proj.weight', 'decoder.layers.1.encoder_attn.q_proj.bias', 'decoder.layers.1.encoder_attn.q_proj.weight', 'decoder.layers.1.encoder_attn.v_proj.bias', 'decoder.layers.1.encoder_attn.v_proj.weight', 'decoder.layers.1.encoder_attn_layer_norm.bias', 'decoder.layers.1.encoder_attn_layer_norm.weight', 'decoder.layers.1.fc1.bias', 'decoder.layers.1.fc1.weight', 'decoder.layers.1.fc2.bias', 'decoder.layers.1.fc2.weight', 'decoder.layers.1.final_layer_norm.bias', 'decoder.layers.1.final_layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.out_proj.bias', 'decoder.layers.1.self_attn.out_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.1.self_attn_layer_norm.bias', 'decoder.layers.1.self_attn_layer_norm.weight', 'decoder.layers.10.encoder_attn.k_proj.bias', 'decoder.layers.10.encoder_attn.k_proj.weight', 'decoder.layers.10.encoder_attn.out_proj.bias', 'decoder.layers.10.encoder_attn.out_proj.weight', 'decoder.layers.10.encoder_attn.q_proj.bias', 'decoder.layers.10.encoder_attn.q_proj.weight', 'decoder.layers.10.encoder_attn.v_proj.bias', 'decoder.layers.10.encoder_attn.v_proj.weight', 'decoder.layers.10.encoder_attn_layer_norm.bias', 'decoder.layers.10.encoder_attn_layer_norm.weight', 'decoder.layers.10.fc1.bias', 'decoder.layers.10.fc1.weight', 'decoder.layers.10.fc2.bias', 'decoder.layers.10.fc2.weight', 'decoder.layers.10.final_layer_norm.bias', 'decoder.layers.10.final_layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.out_proj.bias', 'decoder.layers.10.self_attn.out_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.10.self_attn_layer_norm.bias', 'decoder.layers.10.self_attn_layer_norm.weight', 'decoder.layers.11.encoder_attn.k_proj.bias', 'decoder.layers.11.encoder_attn.k_proj.weight', 'decoder.layers.11.encoder_attn.out_proj.bias', 'decoder.layers.11.encoder_attn.out_proj.weight', 'decoder.layers.11.encoder_attn.q_proj.bias', 'decoder.layers.11.encoder_attn.q_proj.weight', 'decoder.layers.11.encoder_attn.v_proj.bias', 'decoder.layers.11.encoder_attn.v_proj.weight', 'decoder.layers.11.encoder_attn_layer_norm.bias', 'decoder.layers.11.encoder_attn_layer_norm.weight', 'decoder.layers.11.fc1.bias', 'decoder.layers.11.fc1.weight', 'decoder.layers.11.fc2.bias', 'decoder.layers.11.fc2.weight', 'decoder.layers.11.final_layer_norm.bias', 'decoder.layers.11.final_layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.out_proj.bias', 'decoder.layers.11.self_attn.out_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.11.self_attn_layer_norm.bias', 'decoder.layers.11.self_attn_layer_norm.weight', 'decoder.layers.2.encoder_attn.k_proj.bias', 'decoder.layers.2.encoder_attn.k_proj.weight', 'decoder.layers.2.encoder_attn.out_proj.bias', 'decoder.layers.2.encoder_attn.out_proj.weight', 'decoder.layers.2.encoder_attn.q_proj.bias', 'decoder.layers.2.encoder_attn.q_proj.weight', 'decoder.layers.2.encoder_attn.v_proj.bias', 'decoder.layers.2.encoder_attn.v_proj.weight', 'decoder.layers.2.encoder_attn_layer_norm.bias', 'decoder.layers.2.encoder_attn_layer_norm.weight', 'decoder.layers.2.fc1.bias', 'decoder.layers.2.fc1.weight', 'decoder.layers.2.fc2.bias', 'decoder.layers.2.fc2.weight', 'decoder.layers.2.final_layer_norm.bias', 'decoder.layers.2.final_layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.out_proj.bias', 'decoder.layers.2.self_attn.out_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.2.self_attn_layer_norm.bias', 'decoder.layers.2.self_attn_layer_norm.weight', 'decoder.layers.3.encoder_attn.k_proj.bias', 'decoder.layers.3.encoder_attn.k_proj.weight', 'decoder.layers.3.encoder_attn.out_proj.bias', 'decoder.layers.3.encoder_attn.out_proj.weight', 'decoder.layers.3.encoder_attn.q_proj.bias', 'decoder.layers.3.encoder_attn.q_proj.weight', 'decoder.layers.3.encoder_attn.v_proj.bias', 'decoder.layers.3.encoder_attn.v_proj.weight', 'decoder.layers.3.encoder_attn_layer_norm.bias', 'decoder.layers.3.encoder_attn_layer_norm.weight', 'decoder.layers.3.fc1.bias', 'decoder.layers.3.fc1.weight', 'decoder.layers.3.fc2.bias', 'decoder.layers.3.fc2.weight', 'decoder.layers.3.final_layer_norm.bias', 'decoder.layers.3.final_layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.out_proj.bias', 'decoder.layers.3.self_attn.out_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.3.self_attn_layer_norm.bias', 'decoder.layers.3.self_attn_layer_norm.weight', 'decoder.layers.4.encoder_attn.k_proj.bias', 'decoder.layers.4.encoder_attn.k_proj.weight', 'decoder.layers.4.encoder_attn.out_proj.bias', 'decoder.layers.4.encoder_attn.out_proj.weight', 'decoder.layers.4.encoder_attn.q_proj.bias', 'decoder.layers.4.encoder_attn.q_proj.weight', 'decoder.layers.4.encoder_attn.v_proj.bias', 'decoder.layers.4.encoder_attn.v_proj.weight', 'decoder.layers.4.encoder_attn_layer_norm.bias', 'decoder.layers.4.encoder_attn_layer_norm.weight', 'decoder.layers.4.fc1.bias', 'decoder.layers.4.fc1.weight', 'decoder.layers.4.fc2.bias', 'decoder.layers.4.fc2.weight', 'decoder.layers.4.final_layer_norm.bias', 'decoder.layers.4.final_layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.out_proj.bias', 'decoder.layers.4.self_attn.out_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.4.self_attn_layer_norm.bias', 'decoder.layers.4.self_attn_layer_norm.weight', 'decoder.layers.5.encoder_attn.k_proj.bias', 'decoder.layers.5.encoder_attn.k_proj.weight', 'decoder.layers.5.encoder_attn.out_proj.bias', 'decoder.layers.5.encoder_attn.out_proj.weight', 'decoder.layers.5.encoder_attn.q_proj.bias', 'decoder.layers.5.encoder_attn.q_proj.weight', 'decoder.layers.5.encoder_attn.v_proj.bias', 'decoder.layers.5.encoder_attn.v_proj.weight', 'decoder.layers.5.encoder_attn_layer_norm.bias', 'decoder.layers.5.encoder_attn_layer_norm.weight', 'decoder.layers.5.fc1.bias', 'decoder.layers.5.fc1.weight', 'decoder.layers.5.fc2.bias', 'decoder.layers.5.fc2.weight', 'decoder.layers.5.final_layer_norm.bias', 'decoder.layers.5.final_layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.out_proj.bias', 'decoder.layers.5.self_attn.out_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.5.self_attn_layer_norm.bias', 'decoder.layers.5.self_attn_layer_norm.weight', 'decoder.layers.6.encoder_attn.k_proj.bias', 'decoder.layers.6.encoder_attn.k_proj.weight', 'decoder.layers.6.encoder_attn.out_proj.bias', 'decoder.layers.6.encoder_attn.out_proj.weight', 'decoder.layers.6.encoder_attn.q_proj.bias', 'decoder.layers.6.encoder_attn.q_proj.weight', 'decoder.layers.6.encoder_attn.v_proj.bias', 'decoder.layers.6.encoder_attn.v_proj.weight', 'decoder.layers.6.encoder_attn_layer_norm.bias', 'decoder.layers.6.encoder_attn_layer_norm.weight', 'decoder.layers.6.fc1.bias', 'decoder.layers.6.fc1.weight', 'decoder.layers.6.fc2.bias', 'decoder.layers.6.fc2.weight', 'decoder.layers.6.final_layer_norm.bias', 'decoder.layers.6.final_layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.out_proj.bias', 'decoder.layers.6.self_attn.out_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.6.self_attn_layer_norm.bias', 'decoder.layers.6.self_attn_layer_norm.weight', 'decoder.layers.7.encoder_attn.k_proj.bias', 'decoder.layers.7.encoder_attn.k_proj.weight', 'decoder.layers.7.encoder_attn.out_proj.bias', 'decoder.layers.7.encoder_attn.out_proj.weight', 'decoder.layers.7.encoder_attn.q_proj.bias', 'decoder.layers.7.encoder_attn.q_proj.weight', 'decoder.layers.7.encoder_attn.v_proj.bias', 'decoder.layers.7.encoder_attn.v_proj.weight', 'decoder.layers.7.encoder_attn_layer_norm.bias', 'decoder.layers.7.encoder_attn_layer_norm.weight', 'decoder.layers.7.fc1.bias', 'decoder.layers.7.fc1.weight', 'decoder.layers.7.fc2.bias', 'decoder.layers.7.fc2.weight', 'decoder.layers.7.final_layer_norm.bias', 'decoder.layers.7.final_layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.out_proj.bias', 'decoder.layers.7.self_attn.out_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.7.self_attn_layer_norm.bias', 'decoder.layers.7.self_attn_layer_norm.weight', 'decoder.layers.8.encoder_attn.k_proj.bias', 'decoder.layers.8.encoder_attn.k_proj.weight', 'decoder.layers.8.encoder_attn.out_proj.bias', 'decoder.layers.8.encoder_attn.out_proj.weight', 'decoder.layers.8.encoder_attn.q_proj.bias', 'decoder.layers.8.encoder_attn.q_proj.weight', 'decoder.layers.8.encoder_attn.v_proj.bias', 'decoder.layers.8.encoder_attn.v_proj.weight', 'decoder.layers.8.encoder_attn_layer_norm.bias', 'decoder.layers.8.encoder_attn_layer_norm.weight', 'decoder.layers.8.fc1.bias', 'decoder.layers.8.fc1.weight', 'decoder.layers.8.fc2.bias', 'decoder.layers.8.fc2.weight', 'decoder.layers.8.final_layer_norm.bias', 'decoder.layers.8.final_layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.out_proj.bias', 'decoder.layers.8.self_attn.out_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.8.self_attn_layer_norm.bias', 'decoder.layers.8.self_attn_layer_norm.weight', 'decoder.layers.9.encoder_attn.k_proj.bias', 'decoder.layers.9.encoder_attn.k_proj.weight', 'decoder.layers.9.encoder_attn.out_proj.bias', 'decoder.layers.9.encoder_attn.out_proj.weight', 'decoder.layers.9.encoder_attn.q_proj.bias', 'decoder.layers.9.encoder_attn.q_proj.weight', 'decoder.layers.9.encoder_attn.v_proj.bias', 'decoder.layers.9.encoder_attn.v_proj.weight', 'decoder.layers.9.encoder_attn_layer_norm.bias', 'decoder.layers.9.encoder_attn_layer_norm.weight', 'decoder.layers.9.fc1.bias', 'decoder.layers.9.fc1.weight', 'decoder.layers.9.fc2.bias', 'decoder.layers.9.fc2.weight', 'decoder.layers.9.final_layer_norm.bias', 'decoder.layers.9.final_layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.out_proj.bias', 'decoder.layers.9.self_attn.out_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'decoder.layers.9.self_attn_layer_norm.bias', 'decoder.layers.9.self_attn_layer_norm.weight', 'encoder.embed_positions.weight', 'encoder.embed_tokens.weight', 'encoder.layernorm_embedding.bias', 'encoder.layernorm_embedding.weight', 'encoder.layers.0.fc1.bias', 'encoder.layers.0.fc1.weight', 'encoder.layers.0.fc2.bias', 'encoder.layers.0.fc2.weight', 'encoder.layers.0.final_layer_norm.bias', 'encoder.layers.0.final_layer_norm.weight', 'encoder.layers.0.self_attn.k_proj.bias', 'encoder.layers.0.self_attn.k_proj.weight', 'encoder.layers.0.self_attn.out_proj.bias', 'encoder.layers.0.self_attn.out_proj.weight', 'encoder.layers.0.self_attn.q_proj.bias', 'encoder.layers.0.self_attn.q_proj.weight', 'encoder.layers.0.self_attn.v_proj.bias', 'encoder.layers.0.self_attn.v_proj.weight', 'encoder.layers.0.self_attn_layer_norm.bias', 'encoder.layers.0.self_attn_layer_norm.weight', 'encoder.layers.1.fc1.bias', 'encoder.layers.1.fc1.weight', 'encoder.layers.1.fc2.bias', 'encoder.layers.1.fc2.weight', 'encoder.layers.1.final_layer_norm.bias', 'encoder.layers.1.final_layer_norm.weight', 'encoder.layers.1.self_attn.k_proj.bias', 'encoder.layers.1.self_attn.k_proj.weight', 'encoder.layers.1.self_attn.out_proj.bias', 'encoder.layers.1.self_attn.out_proj.weight', 'encoder.layers.1.self_attn.q_proj.bias', 'encoder.layers.1.self_attn.q_proj.weight', 'encoder.layers.1.self_attn.v_proj.bias', 'encoder.layers.1.self_attn.v_proj.weight', 'encoder.layers.1.self_attn_layer_norm.bias', 'encoder.layers.1.self_attn_layer_norm.weight', 'encoder.layers.10.fc1.bias', 'encoder.layers.10.fc1.weight', 'encoder.layers.10.fc2.bias', 'encoder.layers.10.fc2.weight', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.10.self_attn.k_proj.bias', 'encoder.layers.10.self_attn.k_proj.weight', 'encoder.layers.10.self_attn.out_proj.bias', 'encoder.layers.10.self_attn.out_proj.weight', 'encoder.layers.10.self_attn.q_proj.bias', 'encoder.layers.10.self_attn.q_proj.weight', 'encoder.layers.10.self_attn.v_proj.bias', 'encoder.layers.10.self_attn.v_proj.weight', 'encoder.layers.10.self_attn_layer_norm.bias', 'encoder.layers.10.self_attn_layer_norm.weight', 'encoder.layers.11.fc1.bias', 'encoder.layers.11.fc1.weight', 'encoder.layers.11.fc2.bias', 'encoder.layers.11.fc2.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.11.self_attn.k_proj.bias', 'encoder.layers.11.self_attn.k_proj.weight', 'encoder.layers.11.self_attn.out_proj.bias', 'encoder.layers.11.self_attn.out_proj.weight', 'encoder.layers.11.self_attn.q_proj.bias', 'encoder.layers.11.self_attn.q_proj.weight', 'encoder.layers.11.self_attn.v_proj.bias', 'encoder.layers.11.self_attn.v_proj.weight', 'encoder.layers.11.self_attn_layer_norm.bias', 'encoder.layers.11.self_attn_layer_norm.weight', 'encoder.layers.2.fc1.bias', 'encoder.layers.2.fc1.weight', 'encoder.layers.2.fc2.bias', 'encoder.layers.2.fc2.weight', 'encoder.layers.2.final_layer_norm.bias', 'encoder.layers.2.final_layer_norm.weight', 'encoder.layers.2.self_attn.k_proj.bias', 'encoder.layers.2.self_attn.k_proj.weight', 'encoder.layers.2.self_attn.out_proj.bias', 'encoder.layers.2.self_attn.out_proj.weight', 'encoder.layers.2.self_attn.q_proj.bias', 'encoder.layers.2.self_attn.q_proj.weight', 'encoder.layers.2.self_attn.v_proj.bias', 'encoder.layers.2.self_attn.v_proj.weight', 'encoder.layers.2.self_attn_layer_norm.bias', 'encoder.layers.2.self_attn_layer_norm.weight', 'encoder.layers.3.fc1.bias', 'encoder.layers.3.fc1.weight', 'encoder.layers.3.fc2.bias', 'encoder.layers.3.fc2.weight', 'encoder.layers.3.final_layer_norm.bias', 'encoder.layers.3.final_layer_norm.weight', 'encoder.layers.3.self_attn.k_proj.bias', 'encoder.layers.3.self_attn.k_proj.weight', 'encoder.layers.3.self_attn.out_proj.bias', 'encoder.layers.3.self_attn.out_proj.weight', 'encoder.layers.3.self_attn.q_proj.bias', 'encoder.layers.3.self_attn.q_proj.weight', 'encoder.layers.3.self_attn.v_proj.bias', 'encoder.layers.3.self_attn.v_proj.weight', 'encoder.layers.3.self_attn_layer_norm.bias', 'encoder.layers.3.self_attn_layer_norm.weight', 'encoder.layers.4.fc1.bias', 'encoder.layers.4.fc1.weight', 'encoder.layers.4.fc2.bias', 'encoder.layers.4.fc2.weight', 'encoder.layers.4.final_layer_norm.bias', 'encoder.layers.4.final_layer_norm.weight', 'encoder.layers.4.self_attn.k_proj.bias', 'encoder.layers.4.self_attn.k_proj.weight', 'encoder.layers.4.self_attn.out_proj.bias', 'encoder.layers.4.self_attn.out_proj.weight', 'encoder.layers.4.self_attn.q_proj.bias', 'encoder.layers.4.self_attn.q_proj.weight', 'encoder.layers.4.self_attn.v_proj.bias', 'encoder.layers.4.self_attn.v_proj.weight', 'encoder.layers.4.self_attn_layer_norm.bias', 'encoder.layers.4.self_attn_layer_norm.weight', 'encoder.layers.5.fc1.bias', 'encoder.layers.5.fc1.weight', 'encoder.layers.5.fc2.bias', 'encoder.layers.5.fc2.weight', 'encoder.layers.5.final_layer_norm.bias', 'encoder.layers.5.final_layer_norm.weight', 'encoder.layers.5.self_attn.k_proj.bias', 'encoder.layers.5.self_attn.k_proj.weight', 'encoder.layers.5.self_attn.out_proj.bias', 'encoder.layers.5.self_attn.out_proj.weight', 'encoder.layers.5.self_attn.q_proj.bias', 'encoder.layers.5.self_attn.q_proj.weight', 'encoder.layers.5.self_attn.v_proj.bias', 'encoder.layers.5.self_attn.v_proj.weight', 'encoder.layers.5.self_attn_layer_norm.bias', 'encoder.layers.5.self_attn_layer_norm.weight', 'encoder.layers.6.fc1.bias', 'encoder.layers.6.fc1.weight', 'encoder.layers.6.fc2.bias', 'encoder.layers.6.fc2.weight', 'encoder.layers.6.final_layer_norm.bias', 'encoder.layers.6.final_layer_norm.weight', 'encoder.layers.6.self_attn.k_proj.bias', 'encoder.layers.6.self_attn.k_proj.weight', 'encoder.layers.6.self_attn.out_proj.bias', 'encoder.layers.6.self_attn.out_proj.weight', 'encoder.layers.6.self_attn.q_proj.bias', 'encoder.layers.6.self_attn.q_proj.weight', 'encoder.layers.6.self_attn.v_proj.bias', 'encoder.layers.6.self_attn.v_proj.weight', 'encoder.layers.6.self_attn_layer_norm.bias', 'encoder.layers.6.self_attn_layer_norm.weight', 'encoder.layers.7.fc1.bias', 'encoder.layers.7.fc1.weight', 'encoder.layers.7.fc2.bias', 'encoder.layers.7.fc2.weight', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.7.self_attn.k_proj.bias', 'encoder.layers.7.self_attn.k_proj.weight', 'encoder.layers.7.self_attn.out_proj.bias', 'encoder.layers.7.self_attn.out_proj.weight', 'encoder.layers.7.self_attn.q_proj.bias', 'encoder.layers.7.self_attn.q_proj.weight', 'encoder.layers.7.self_attn.v_proj.bias', 'encoder.layers.7.self_attn.v_proj.weight', 'encoder.layers.7.self_attn_layer_norm.bias', 'encoder.layers.7.self_attn_layer_norm.weight', 'encoder.layers.8.fc1.bias', 'encoder.layers.8.fc1.weight', 'encoder.layers.8.fc2.bias', 'encoder.layers.8.fc2.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.8.self_attn.k_proj.bias', 'encoder.layers.8.self_attn.k_proj.weight', 'encoder.layers.8.self_attn.out_proj.bias', 'encoder.layers.8.self_attn.out_proj.weight', 'encoder.layers.8.self_attn.q_proj.bias', 'encoder.layers.8.self_attn.q_proj.weight', 'encoder.layers.8.self_attn.v_proj.bias', 'encoder.layers.8.self_attn.v_proj.weight', 'encoder.layers.8.self_attn_layer_norm.bias', 'encoder.layers.8.self_attn_layer_norm.weight', 'encoder.layers.9.fc1.bias', 'encoder.layers.9.fc1.weight', 'encoder.layers.9.fc2.bias', 'encoder.layers.9.fc2.weight', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.self_attn.k_proj.bias', 'encoder.layers.9.self_attn.k_proj.weight', 'encoder.layers.9.self_attn.out_proj.bias', 'encoder.layers.9.self_attn.out_proj.weight', 'encoder.layers.9.self_attn.q_proj.bias', 'encoder.layers.9.self_attn.q_proj.weight', 'encoder.layers.9.self_attn.v_proj.bias', 'encoder.layers.9.self_attn.v_proj.weight', 'encoder.layers.9.self_attn_layer_norm.bias', 'encoder.layers.9.self_attn_layer_norm.weight', 'lm_head.weight', 'shared.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"noahkim/KoBigBird-KoBart-News-Summarization\"\n",
    "tokenizer = BartTokenizerFast.from_pretrained(\"../tokenizer/ko_sentencepiece\")\n",
    "model = BartForConditionalGeneration.from_pretrained(model_id).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '<sep>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>', 'additional_special_tokens': ['#Person1#', '#Person2#', '#Person3#', '#Person4#', '#Person5#', '#Person6#', '#Person7#', '#SSN#', '#Email#', '#Address#', '#Reaction#', '#CarNumber#', '#Movietitle#', '#DateOfBirth#', '#CardNumber#', '#PhoneNumber#', '#PassportNumber#']}\n"
     ]
    }
   ],
   "source": [
    "special_tokens = [\n",
    "    '#Person1#',\n",
    "    '#Person2#',\n",
    "    '#Person3#',\n",
    "    '#Person4#',\n",
    "    '#Person5#',\n",
    "    '#Person6#',\n",
    "    '#Person7#',\n",
    "    '#SSN#',\n",
    "    '#Email#',\n",
    "    '#Address#',\n",
    "    '#Reaction#',\n",
    "    '#CarNumber#',\n",
    "    '#Movietitle#',\n",
    "    '#DateOfBirth#',\n",
    "    '#CardNumber#',\n",
    "    '#PhoneNumber#',\n",
    "    '#PassportNumber#',\n",
    "]\n",
    "\n",
    "remove_tokens = ['<usr>', f\"{tokenizer.bos_token}\", f\"{tokenizer.unk_token}\", f\"{tokenizer.eos_token}\", f\"{tokenizer.pad_token}\", f\"{tokenizer.sep_token}\", f\"{tokenizer.mask_token}\"]\n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\": special_tokens})\n",
    "\n",
    "print(tokenizer.special_tokens_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpanCorruptionDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, input_len, mask_prob=0.15, permute_prob=0.3):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.df = df.copy()\n",
    "        self.source_len = input_len\n",
    "        self.mask_prob = mask_prob\n",
    "        self.permute_prob = permute_prob  # sentence permutation 확률 추가\n",
    "        \n",
    "        # 대화 내용에 마스킹을 적용\n",
    "        self.input_ids = tokenizer(self.df['total'].tolist(), \n",
    "                                   return_tensors=\"pt\", \n",
    "                                   padding=True,\n",
    "                                   add_special_tokens=True, \n",
    "                                   truncation=True, \n",
    "                                   max_length=self.source_len, \n",
    "                                   return_token_type_ids=False).input_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids = self.input_ids[idx]\n",
    "        \n",
    "        # Sentence Permutation 적용\n",
    "        if random.random() < self.permute_prob:\n",
    "            input_ids = self.apply_sentence_permutation(input_ids)\n",
    "        \n",
    "        # Span Corruption 적용 (일부 토큰을 <mask>로 대체)\n",
    "        masked_input_ids = self.apply_span_corruption(input_ids)\n",
    "        return masked_input_ids, input_ids  # 마스킹된 입력과 원본 레이블 반환\n",
    "\n",
    "    def apply_span_corruption(self, input_ids):\n",
    "        # 일부 토큰을 <mask>로 대체하는 로직\n",
    "        num_to_mask = int(len(input_ids) * self.mask_prob)\n",
    "        mask_indices = random.sample(range(len(input_ids)), num_to_mask)\n",
    "        \n",
    "        corrupted_ids = input_ids.clone()\n",
    "        corrupted_ids[mask_indices] = self.tokenizer.mask_token_id\n",
    "        return corrupted_ids\n",
    "\n",
    "    def apply_sentence_permutation(self, input_ids):\n",
    "        text = self.tokenizer.decode(input_ids, skip_special_tokens=True)\n",
    "        sentences = text.split(\". \")\n",
    "        \n",
    "        random.shuffle(sentences)\n",
    "        permuted_text = \". \".join(sentences)\n",
    "        permuted_input_ids = self.tokenizer(permuted_text, \n",
    "                                            return_tensors=\"pt\", \n",
    "                                            padding=True, \n",
    "                                            truncation=True, \n",
    "                                            max_length=self.source_len).input_ids.squeeze(0)\n",
    "        return permuted_input_ids\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # 마스킹된 입력과 원본 레이블을 각각 추출\n",
    "    masked_input_ids = [item[0] for item in batch]\n",
    "    input_ids = [item[1] for item in batch]\n",
    "    \n",
    "    # 패딩을 적용하여 같은 길이로 맞춤\n",
    "    masked_input_ids_padded = pad_sequence(masked_input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    input_ids_padded = pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    \n",
    "    return masked_input_ids_padded, input_ids_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../dataset/cleaned_train.csv')\n",
    "val_df = pd.read_csv('../dataset/cleaned_dev.csv')\n",
    "\n",
    "trans_train = pd.read_csv(\"../dataset/translated_train.csv\")\n",
    "trans_val = pd.read_csv(\"../dataset/translated_valid.csv\")\n",
    "trans_train['dialogue'] = trans_train['dialogue'].str.replace('\\n', ' ')\n",
    "trans_val['dialogue'] = trans_val['dialogue'].str.replace('\\n', ' ')\n",
    "\n",
    "train_df['total'] = train_df['dialogue'] + \" \" + train_df['summary']\n",
    "trans_train['total'] = trans_train['dialogue'] + \" \" + trans_train['dialogue']\n",
    "val_df['total'] = val_df['dialogue'] + \" \" + val_df['summary']\n",
    "trans_val['total'] = trans_val['dialogue'] + \" \" + trans_val['summary']\n",
    "\n",
    "train_df = pd.concat([train_df, trans_train, trans_val])\n",
    "\n",
    "pretrain_dataset = SpanCorruptionDataset(train_df[['total']], tokenizer, dig_max_len)\n",
    "prevalid_dataset = SpanCorruptionDataset(val_df[['total']], tokenizer, dig_max_len)\n",
    "\n",
    "pretrain_loader = DataLoader(pretrain_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, collate_fn=collate_fn)\n",
    "preval_loader = DataLoader(prevalid_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('#Person1# 만<mask>, 이 오후 영화에 아직 좌석이 남아있는지 확인하기<mask> 영화관에 전화해 줄 수 있을까? #Person2# 2<mask> 영화<mask><mask>으로 이미 예매<mask><mask> 식당에서 점심 먹고 매표소<mask> 찾으러 갈까 하는데 어때? #Person1#<mask>, 스미스 부부가 약속 시간<mask> 30분 앞당<mask> 달라고 해서 11시<mask>분에 도착해야 해. <mask> 그럼 시간이 부족하네, 얼른 자리를 <mask>기는 게 좋겠어. 아, 잊어버리기<mask><mask> 집에 오는<mask> 서점에 들르라고<mask>줄 수 있어? 거기서 책을 주문<mask> 해.<mask>#Person1# 알았어. #Person1# 은 만디에게 영화에<mask> 좌석이 남아있는지 확인하라고 요청한<mask>. <mask>디<mask> 온라인으로 티켓<mask> 예약했다. 그들은 약속을 위해<mask> 것이<mask><mask><mask><mask><pad><pad><pad><mask><mask><pad><pad><pad><pad><pad><pad><pad><pad><mask><mask><mask><pad><pad><pad><pad><pad><pad><pad><pad><mask><pad><pad><pad><pad><pad><mask><pad><pad><pad><pad><mask><mask><pad><pad><mask><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><mask><pad><pad><pad><pad><pad><pad><pad><mask><pad><pad><mask><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><mask><pad><pad><mask><pad><pad><pad><pad><pad><pad><pad><pad><pad><mask><mask><pad><pad><pad><pad><mask><pad><mask><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><mask><pad><pad><pad><pad><mask><pad><pad><pad><mask><pad><pad><pad><pad><pad><mask><pad><pad><pad><pad><pad><pad><mask><pad><pad><pad><mask><pad><pad><mask><pad><pad><pad><mask><pad><pad><mask><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><mask><pad><mask><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><mask><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><mask><mask><mask><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><mask><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><mask><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><mask><pad><mask><pad><pad><mask><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><mask><pad><pad><mask><pad><pad><pad><mask><pad><pad><pad><pad><mask><pad><pad><pad><pad><pad><mask><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><mask><mask><pad><pad><pad>',\n",
       " '#Person1# 만디, 이 오후 영화에 아직 좌석이 남아있는지 확인하기 위해 영화관에 전화해 줄 수 있을까? #Person2# 2시 영화는 인터넷으로 이미 예매했어. 식당에서 점심 먹고 매표소에서 찾으러 갈까 하는데 어때? #Person1# 좋아요, 스미스 부부가 약속 시간을 30분 앞당겨 달라고 해서 11시 30분에 도착해야 해. #Person2# 그럼 시간이 부족하네, 얼른 자리를 옮기는 게 좋겠어. 아, 잊어버리기 전에, 집에 오는 길에 서점에 들르라고 상기시켜줄 수 있어? 거기서 책을 주문해야 해. #Person1# 알았어. #Person1# 은 만디에게 영화에 아직 좌석이 남아있는지 확인하라고 요청한다. 만디는 온라인으로 티켓을 예약했다. 그들은 약속을 위해 움직일 것이다.<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(pretrain_loader))\n",
    "masked_input_ids, original_input_ids = batch[0], batch[1]\n",
    "\n",
    "masked_example = tokenizer.decode(masked_input_ids[0], skip_special_tokens=False)\n",
    "original_example = tokenizer.decode(original_input_ids[0], skip_special_tokens=False)\n",
    "\n",
    "masked_example, original_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_to_words(tokenizer, preds, labels):\n",
    "    decoded_preds = tokenizer.batch_decode(preds, clean_up_tokenization_spaces=True)\n",
    "    labels = tokenizer.batch_decode(labels, clean_up_tokenization_spaces=True)\n",
    "\n",
    "    replaced_predictions = decoded_preds.copy()\n",
    "    replaced_labels = labels.copy()\n",
    "\n",
    "    for token in remove_tokens:\n",
    "        replaced_predictions = [sentence.replace(token,\" \") for sentence in replaced_predictions]\n",
    "        replaced_labels = [sentence.replace(token,\" \") for sentence in replaced_labels]\n",
    "        \n",
    "    return replaced_predictions, replaced_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(replaced_predictions, replaced_labels):\n",
    "    rouge = Rouge()\n",
    "\n",
    "    results = rouge.get_scores(replaced_predictions, replaced_labels,avg=True)\n",
    "    result = {key: value[\"f\"] for key, value in results.items()}\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineAnnealingWarmUpRestarts(_LRScheduler):\n",
    "    def __init__(self, optimizer, T_0, T_mult=1, eta_max=0.1, T_up=0, gamma=1., last_epoch=-1):\n",
    "        if T_0 <= 0 or not isinstance(T_0, int):\n",
    "            raise ValueError(\"Expected positive integer T_0, but got {}\".format(T_0))\n",
    "        if T_mult < 1 or not isinstance(T_mult, int):\n",
    "            raise ValueError(\"Expected integer T_mult >= 1, but got {}\".format(T_mult))\n",
    "        if T_up < 0 or not isinstance(T_up, int):\n",
    "            raise ValueError(\"Expected positive integer T_up, but got {}\".format(T_up))\n",
    "        self.T_0 = T_0\n",
    "        self.T_mult = T_mult\n",
    "        self.base_eta_max = eta_max\n",
    "        self.eta_max = eta_max\n",
    "        self.T_up = T_up\n",
    "        self.T_i = T_0\n",
    "        self.gamma = gamma\n",
    "        self.cycle = 0\n",
    "        self.T_cur = last_epoch\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "    \n",
    "    def get_lr(self):\n",
    "        if self.T_cur == -1:\n",
    "            return self.base_lrs\n",
    "        elif self.T_cur < self.T_up:\n",
    "            return [(self.eta_max - base_lr)*self.T_cur / self.T_up + base_lr for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr + (self.eta_max - base_lr) * (1 + math.cos(math.pi * (self.T_cur-self.T_up) / (self.T_i - self.T_up))) / 2\n",
    "                    for base_lr in self.base_lrs]\n",
    "\n",
    "    def step(self, epoch=None):\n",
    "        if epoch is None:\n",
    "            epoch = self.last_epoch + 1\n",
    "            self.T_cur = self.T_cur + 1\n",
    "            if self.T_cur >= self.T_i:\n",
    "                self.cycle += 1\n",
    "                self.T_cur = self.T_cur - self.T_i\n",
    "                self.T_i = (self.T_i - self.T_up) * self.T_mult + self.T_up\n",
    "        else:\n",
    "            if epoch >= self.T_0:\n",
    "                if self.T_mult == 1:\n",
    "                    self.T_cur = epoch % self.T_0\n",
    "                    self.cycle = epoch // self.T_0\n",
    "                else:\n",
    "                    n = int(math.log((epoch / self.T_0 * (self.T_mult - 1) + 1), self.T_mult))\n",
    "                    self.cycle = n\n",
    "                    self.T_cur = epoch - self.T_0 * (self.T_mult ** n - 1) / (self.T_mult - 1)\n",
    "                    self.T_i = self.T_0 * self.T_mult ** (n)\n",
    "            else:\n",
    "                self.T_i = self.T_0\n",
    "                self.T_cur = epoch\n",
    "                \n",
    "        self.eta_max = self.base_eta_max * (self.gamma**self.cycle)\n",
    "        self.last_epoch = math.floor(epoch)\n",
    "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
    "            param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_epoch(model, device, train_loader, optimizer, epoch, accumulation_steps):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for idx, batch in tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Pretraining Epoch {epoch+1}\", leave=False):\n",
    "        masked_input_ids = batch[0].to(device)\n",
    "        labels = batch[1].to(device)\n",
    "\n",
    "        outputs = model(input_ids=masked_input_ids, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss = loss / accumulation_steps\n",
    "        loss.backward()\n",
    "\n",
    "        if (idx + 1) % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item() * accumulation_steps\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Pretrain Loss: {avg_loss:.6f}\")\n",
    "\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def pretrain_validate(tokenizer, model, device, val_loader, epoch):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in tqdm(enumerate(val_loader), total=len(val_loader), desc=\"Pretrain Validating\", leave=False):\n",
    "            input_ids = batch[0].to(device)\n",
    "            labels = batch[1].to(device)\n",
    "\n",
    "            pred_ids = model.generate(input_ids=input_ids, max_length=sum_max_len, num_beams=4, repetition_penalty=2.0, length_penalty=1.0, early_stopping=True)\n",
    "            loss = model(input_ids=input_ids, labels=labels).loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            replaced_predictions, replaced_labels = ids_to_words(tokenizer, pred_ids, labels)\n",
    "            all_predictions.extend(replaced_predictions)\n",
    "            all_labels.extend(replaced_labels)\n",
    "\n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "\n",
    "    print(f\"Prevalid Loss: {avg_loss:.6f}\")\n",
    "    for i in range(min(3, len(all_predictions))):\n",
    "        print(f\"[예측 문장 {i+1}]: {all_predictions[i]}\")\n",
    "        print(f\"[정답 문장 {i+1}]: {all_labels[i]}\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1000, Current Learning Rate: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Loss: 4.249606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prevalid Loss: 2.925712\n",
      "[예측 문장 1]:  #Person1#:? #Person2#:. #Person1# #Person2# #Person1#:,을 #Person1#:. #Person1#: #Person1#:. #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#:. #Person1#:. #Person1#:. #Person1#:. #Person1#:. #Person1#:. #Person1#:. #Person1#:를 #Person1#:. #Person2#: #Person1#:. #Person1#:. #Person2#:. #Person2#: #Person1#:. #Person1#: #Person1#:. #Person1#: #Person1#: #Person1#: #Person1#:. #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#:. #Person1#:. #Person1#:. #Person1#:. #Person1#:. #Person1#:. #Person2#: #Person2#: #Person1#: #Person2#: #Person1#: #Person1#: #Person1#: #Person1#:. #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person2#: #Person1#: #Person2#: #Person1#: #Person1#: #Person1#: #Person2#: #Person1#: #Person1#: #Person1#: #Person2#: #Person1#: #Person1#: #Person2#:. #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person2#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person2#: #Person1#: #Person1#: #Person1#: #Person2#: #Person1#: #Person2#: #Person1#: #Person2#: #Person1#: #Person1#:. #Person1#: #Person1#: #Person2#: #Person1#: #Person1#:  \n",
      "[정답 문장 1]: #Person1# 외국인과 결혼했군요, 그래서 어떤가요? #Person2# 처음 결혼한 첫 해는 정말로 어려웠어요. 제게 중요한 것들이 그에게는 중요하지 않았고, 그래서 많은 갈등이 있었어요. #Person1# 그렇군요, 알겠어요. 어떤 부부든 결혼 첫 해는 어려워요, 특히 다른 문화권에서 온 두 사람이라면 더욱 그렇죠. #Person2# 그리고 지금 우리는 2살짜리 아들을 둔 상태에요. 그가 건강하고 똑똑해서 정말 행복해요. #Person1# 오, 그럼 그는 중국인과 미국인의 혼혈이군요. 그건 흔치 않네요. 그럼 그는 어떤 언어를 사용하나요? #Person2# 지금은 주로 중국어를 사용하고, 영어 단어를 몇 개 말할 수 있지만, 배울 것이에요. #Person1# 그는 어떻게 생겼나요? 사람들이 알아볼 수 있나요? #Person2# 네, 사람들은 분명히 알아볼 수 있어요. 그는 중국 아이들보다 피부가 희고, 머리카락은 약간 금발이에요. 하지만 남편은 그의 눈이 매우 중국적이라고 말해요. #Person2# 는 #Person1# 에게 외국인과의 결혼 첫 해가 어려웠던 것에 대해 이야기하고, 그녀의 아들에 대해서도 이야기합니다.                                                                                                                                                                                                                                                                                             \n",
      "--------------------------------------------------------------------------------\n",
      "[예측 문장 2]:  #Person1#:? #Person2#:. #Person1# #Person2# #Person1#:,을 #Person1#:. #Person1#: #Person1#:. #Person1#: #Person1#: #Person1#: #Person1#:. #Person1#:. #Person1#:. #Person1#:. #Person1#:. #Person1#:. #Person2#: #Person1#: #Person1#: #Person1#: #Person2#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#:. #Person1#: #Person1#:. #Person1#: #Person1#: #Person1#: #Person1#:. #Person1#:. #Person2#:. #Person2#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#:. #Person1#:. #Person2#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person2#: #Person1#: #Person1#: #Person1#: #Person1#:. #Person2#: #Person1#: #Person1#:. #Person1#: #Person2#: #Person2#: #Person2#: #Person1#: #Person1#: #Person1#: #Person1#: #Person2#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person2#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person2#: #Person2#: #Person2#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person2#: #Person1#: #Person2#: #Person1#: #Person1#: #Person1#: #Person2#: #Person1#: #Person2#: #Person1#: #Person2#: #Person1#: #Person1#:. #Person1#: #Person1#: #Person2#: #Person1#: #Person2#:  \n",
      "[정답 문장 2]: #Person1# 나 너무 배고파. 지금 먹으러 가자, 릭? #Person2# 그래. 어디 가고 싶어? 특별히 먹고 싶은 거 있어? #Person1# 만두 어때? 나 그냥 만두가 너무 좋아. #Person2# 또 만두?! 아, 에이미야, 새로운 걸 한 번 시도해 보자! #Person1# 그럼, 뭐가 생각나? #Person2# 몽골 핫팟 어때? #Person1# 아, 그건 너무 매워. 저번에 양고기 맛볼 때 기억 안 나? 너무 매워서 눈물이 나왔었어! #Person2# 이번에는 연양 팟을 시도해 볼까.  지 않은 국물을 선택할 수 있어. #Person1# 좋아 보여. 거기 국수도 팔아? 나 맛있는 국수도 먹고 싶어. #Person2# 그래. 그들이 제공하는 썰어 만든 국수는 가장 진짜 같은 Shanti 요리 중 하나야. #Person1# 좋아. 가자! #Person2# 잠깐만. 스웨터를 입고 올게. 에이미는 만두를 원하지만, 릭는 핫팟을 원한다. 그들은 결국 연양 팟을 시도하고 국수도 먹기로 결정한다.                                                                                                                                                                                                                                                                                          \n",
      "--------------------------------------------------------------------------------\n",
      "[예측 문장 3]:  #Person1#:. #Person2#:? #Person1# #Person2# #Person1#:,을 #Person1#:. #Person1#: #Person1#:. #Person2#: #Person2#: #Person1#: #Person1#: #Person2#: #Person1#: #Person2#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person2#: #Person1#: #Person1#: #Person1#: #Person2#: #Person2#: #Person2#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person2#: #Person2#: #Person1#: #Person1#:. #Person1#:. #Person1# #Person2#: #Person1#: #Person1#: #Person1#: #Person2#: #Person2#: #Person2#: #Person1#:. #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person2#: #Person1#: #Person2#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person2#: #Person2#: #Person2#: #Person2#: #Person1#: #Person2#: #Person2#: #Person1#: #Person2#: #Person1#: #Person1#: #Person1#: #Person1#: #Person2#: #Person2#: #Person2#: #Person1#: #Person1#: #Person1#: #Person1#: #Person2#: #Person1#: #Person2#: #Person1#: #Person1#: #Person1#: #Person2#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person2#: #Person1#: #Person1#: #Person2#: #Person2#: #Person2#: #Person1#: #Person1#: #Person1#: #Person1#: #Person1#: #Person2#: #Person1#: #Person2#: #Person1#: #Person2#: #Person2#: #Person2#: #Person2#: #Person2#: #Person1#: #Person2#: #Person1#: #Person1#:. #Person2#: #Person2#: #Person2#: #Person1#: #Person2#:  \n",
      "[정답 문장 3]: #Person1# 오, 정말 예쁜 고양이네요! 어떻게 생각하세요? #Person2# 저는 개를 키우는 게 더 좋을 것 같아요. 개가 고양이보다 더 충성심이 높으니까요. #Person1# 그렇지만, 개를 키우는 것은 많은 노력이 필요해요. 매일 산책시키고 뒷정리를 해줄 의향이 있나요? #Person2# 우리는 새장이나 수족관에 많은 돈을 투자해야 할 것이고, 저는 새나 물고기를 어떻게 돌봐야 할지 잘 모르겠어요. #Person1# 그렇군요. 우리는 아직 애완동물을 키울 준비가 되어 있지 않은 것 같아요. #Person2# 네, 맞아요. 커피나 한 잔 하러 가서 이야기해보죠. #Person1# 은 고양이를 좋아하지만, #Person2# 는 개를 좋아한다. 그들은 아직 애완동물을 키울 준비가 되어 있지 않다.                                                                                                                                                                                                                                                                                                                                                               \n",
      "--------------------------------------------------------------------------------\n",
      "Best pretrain model saved at Epoch 1 with validation loss 2.925712\n",
      "\n",
      "Epoch 1/1000, Current Learning Rate: 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretraining Epoch 2:  97%|█████████▋| 3096/3177 [15:32<00:24,  3.26it/s]"
     ]
    }
   ],
   "source": [
    "pretrain_epochs = 10\n",
    "best_pretrain_loss = float('inf')\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=init_lr, weight_decay=0)\n",
    "scheduler = CosineAnnealingWarmUpRestarts(optimizer, T_0=T_0, T_mult=T_mult, eta_max=max_lr,  T_up=warmup_epochs, gamma=T_gamma)\n",
    "\n",
    "for epoch in range(pretrain_epochs):\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Epoch {epoch}/{epochs}, Current Learning Rate: {current_lr:.6f}\")\n",
    "    train_loss = pretrain_epoch(model, device, pretrain_loader, optimizer, epoch, accumulation_steps)\n",
    "    val_loss = pretrain_validate(tokenizer, model, device, preval_loader, epoch)\n",
    "    \n",
    "    scheduler.step()\n",
    "    if val_loss < best_pretrain_loss:\n",
    "        best_pretrain_loss = val_loss\n",
    "        early_stopping_counter = 0 \n",
    "        torch.save(model.state_dict(), os.path.join(weights_path, 'best_pretrain.pth'))\n",
    "        print(f\"Best pretrain model saved at Epoch {epoch+1} with validation loss {best_pretrain_loss:.6f}\\n\")\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        print(f\"No improvement. Early stopping counter: {early_stopping_counter}/{patience}\\n\")\n",
    "    \n",
    "    if early_stopping_counter >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(weights_path, f'epoch-{epoch+1}_pretrain.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
