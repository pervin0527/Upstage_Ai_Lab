{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from koeda import EasyDataAugmentation, AEasierDataAugmentation\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def timeit(func):\n",
    "    \"\"\"이 데코레이터는 함수의 실행 시간을 측정합니다.\"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()  # 시작 시간 측정\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()    # 종료 시간 측정\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f\"'{func.__name__}' 함수 실행 시간: {elapsed_time:.4f}초\")\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../dataset/cleaned_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = random.randint(0, 12000)\n",
    "sample = df.iloc[idx]['dialogue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timeit\n",
    "def augment_text_data_with_EDA(text: str, repetition=1):\n",
    "    eda = EasyDataAugmentation(morpheme_analyzer=\"Mecab\")\n",
    "    \n",
    "    pattern = r'#.*?#:?'\n",
    "    \n",
    "    lines = text.split('\\n')\n",
    "    augmented_texts = []\n",
    "    \n",
    "    for line in lines:\n",
    "        matches = [(m.start(), m.end(), m.group()) for m in re.finditer(pattern, line)]\n",
    "        cleaned_line = line\n",
    "        for start, end, match in matches:\n",
    "            cleaned_line = cleaned_line.replace(match, \"\")\n",
    "        \n",
    "        result = eda(cleaned_line, p=(0.1, 0.1, 0.1, 0.1), repetition=repetition)\n",
    "        \n",
    "        for start, end, match in matches:\n",
    "            result = result[:start] + match + result[start:]\n",
    "        \n",
    "        augmented_texts.append(result.strip())\n",
    "\n",
    "    return augmented_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'augment_text_data_with_EDA' 함수 실행 시간: 0.0072초\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['#Person1#:오, 정말 신나네요. 그럼, 어디에서 결혼하고 싶으세요? 흙덩이 알아요, 마련 알아요, 알아요 동정 . 음, 산 위에서요. 아시 임 죠, 그 아름다운 폭포? 폭포 옆에서 결혼하는 건 어때요?',\n",
       " '#Person2#:음, 잘 모르겠네요.',\n",
       " '#Person1#:오 그런 말 하지 마세요. 정말 좋을 거예요. 너무 아름답, 평화롭고, 정말 로맨틱하죠. 부탁이에요.',\n",
       " '#Person2#:잘 모르겠어요. 제가 야생화 32핵에 알레르기가 있잖아요.',\n",
       " '#Person1#:괜찮을 거예요. 알레르기 을 먹으면 돼요.',\n",
       " '#Person2#:. 그리고 탄탄 심한 발진이 나타날 수도 있어요.',\n",
       " '#Person1#:괜찮을 거예요. 가자고요. 음, 우리가 좋은 걸 생각해낼 호수 있을 거예요. 가자고요. 부탁이에요.',\n",
       " '#Person2#:우우우우리 부모님 집 명가 뒷마당에서 결혼하면 장 어떨까요? [ 뭐라고요? ] 그래요. 개들을 몇 시간만 옮기 체모 면 돼요.',\n",
       " '#Person1#:아니요! 그런 생각도 하지 마세요. 그들의 뒷마당은 정말 쓰.쓰(그녀가 말하려는 것은, 쓰레기 같다는 것). 상태가. 상태가 안 좋아요. 그리고 그들의 집은 고속도로 바로 옆수확에요. 고속도로에서 반 블록밖에 안 떨어져 있어요. 너무 시끄러워요. 부탁수확에요. 몇 마일 떨어진 곳에 정말 좋은 리셉션 홀수확 있어요. 우리가 그곳에서 할 수 있어요. 알레르기 걱정은 안 해도 돼요.',\n",
       " '#Person2#:아, 그게 비싸 보이는데요!',\n",
       " '#Person1#:그렇게 비싼 건 아니에요. 조금 비싸긴 해요. 그리고, 그리고, 요정 봐요. 우리가 케이터링 서비스를 불러서, 그들 백금 이 새우와 랍스터 천수 표제 포 꼬리를 제공하고, 제 친구가 결혼했을 주간 때, 그들은 최고의 디저트를 가지고 있었어요. 고난 부탁이에요, 그리고, 아시다시피, 우리의 결혼식 아침 식사를 위해, 우리는 그 일본 레스토랑에 갈 수 부지 있어요 사상 . 기억이 안 나네요. 그게 미소 뭐였지요?',\n",
       " '#Person2#:삼 스시를 말하는 건가요?',\n",
       " '#Person1#:그래, 삼라이 스시! 그들의 양식이 너무 맛있어요. 가자고요, 가자고요.',\n",
       " '#Person2#:그게 너무 보이는데요.',\n",
       " '#Person1#:괜찮. 그만한 가치가 있어요. 가자고요, 론! 가자고요!',\n",
       " '#Person2#:복귀에 제 엄마의 참치 샌드위치는 어떨까요?',\n",
       " '#Person1#:로날드. 우리가 당신수입 그 오래된 바보같은 노란 항아리에 갖고 있는 것보다 조금 더 많은 돈을 쓸 수 있어요. 가자고요.',\n",
       " '#Person2#:음, 나는 신혼여행을 위해 재을 아끼려고 했어요.',\n",
       " '#Person1#:음, 그래. [ . ] 음, 괜찮아요 , 나도 생각해봤어요. 몇 해봤어요.',\n",
       " '#Person2#:나도 그래. 이제 세요, 이 웹사이트를 보세요. 우리는 유타주 솔트레이크시티 갈 있어요.',\n",
       " '#Person1#:그거 아 멋질 거 같아요! 정말들은 최고의 스노보드와 스키, 그리고 그들은 . 그것의 최고의 눈멋질에요가 이 시기에 가면 완벽할 거예요 그, 정말눈좋은 호텔들이 있어요. 오, 론, 우리. 좋을 그것아할 거예요..그것은 이 거예요. 나는 스키를 타는 것을 좋정말해요.',\n",
       " '#Person2#:나나나는 대신에 내림 현지의 예술 박물관과 자연사 박물관을 방문하는 것을 생각했 위 어요. [ 뭐라고요? ] 스노우 스키는 제 취향이 아니에요 미술관 .',\n",
       " '#Person1#:고리 오, 론. 가자고요.',\n",
       " '#Person2#:당신.당신 알잖아요. 연대는 추위를 잘 못 견디는 편이에요.',\n",
       " '#Person1#:형체!',\n",
       " '#Person2#:오, 그래! [ 뭐? ] 좋은 생각네요. 제 형에게 전화해볼게요. [ 절대 안 돼! ] 그는 거기에 고 있, 우리가 의 집에 수 있게 해줄 수 있을 거예요.',\n",
       " '#Person1#:우리정교 신혼여행을 위해!?!?!',\n",
       " '#Person2#:오, 그래! [ 아니요! ] 기다려, 기다려! 어디 가는 거야? 돌아와. 대천가 뭔가 잘못 말했나요?']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(sample)\n",
    "augment_text_data_with_EDA(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timeit\n",
    "def augment_text_data_with_AEDA(text, repetition):\n",
    "    \"\"\"입력된 문장에 대해서 AEDA를 통해 데이터 증강\"\"\"\n",
    "    aeda = AEasierDataAugmentation(morpheme_analyzer=\"Okt\", punctuations=[\".\", \",\", \"!\", \"?\", \";\", \":\"])\n",
    "\n",
    "    pattern = r'#.*?#:?'\n",
    "    lines = text.split('\\n')\n",
    "    augmented_texts = []\n",
    "    \n",
    "    for line in lines:\n",
    "        matches = [(m.start(), m.end(), m.group()) for m in re.finditer(pattern, line)]\n",
    "        \n",
    "        cleaned_line = line\n",
    "        for start, end, match in matches:\n",
    "            cleaned_line = cleaned_line.replace(match, \"\")\n",
    "    \n",
    "        result = aeda(text, p=0.1, repetition=repetition)\n",
    "    \n",
    "        for start, end, match in matches:\n",
    "            result = result[:start] + match + result[start:]\n",
    "        \n",
    "        augmented_texts.append(result.strip())\n",
    "\n",
    "    return augmented_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43maugment_text_data_with_AEDA\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m, in \u001b[0;36mtimeit.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m      6\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()  \u001b[38;5;66;03m# 시작 시간 측정\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()    \u001b[38;5;66;03m# 종료 시간 측정\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     elapsed_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "Cell \u001b[0;32mIn[7], line 17\u001b[0m, in \u001b[0;36maugment_text_data_with_AEDA\u001b[0;34m(text, repetition)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start, end, match \u001b[38;5;129;01min\u001b[39;00m matches:\n\u001b[1;32m     15\u001b[0m     cleaned_line \u001b[38;5;241m=\u001b[39m cleaned_line\u001b[38;5;241m.\u001b[39mreplace(match, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43maeda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepetition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepetition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start, end, match \u001b[38;5;129;01min\u001b[39;00m matches:\n\u001b[1;32m     20\u001b[0m     result \u001b[38;5;241m=\u001b[39m result[:start] \u001b[38;5;241m+\u001b[39m match \u001b[38;5;241m+\u001b[39m result[start:]\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-project/lib/python3.9/site-packages/koeda/aeda.py:35\u001b[0m, in \u001b[0;36mAEasierDataAugmentation.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maeda\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-project/lib/python3.9/site-packages/koeda/aeda.py:42\u001b[0m, in \u001b[0;36mAEasierDataAugmentation.aeda\u001b[0;34m(self, data, p, repetition)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m repetition \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 42\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_aeda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m     45\u001b[0m             \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aeda, repeat(data, repetition), repeat(p, repetition))\n\u001b[1;32m     46\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-project/lib/python3.9/site-packages/koeda/aeda.py:73\u001b[0m, in \u001b[0;36mAEasierDataAugmentation._aeda\u001b[0;34m(self, data, p)\u001b[0m\n\u001b[1;32m     70\u001b[0m qs \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(split_words)), q)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_special_selection(split_words, qs):\n\u001b[0;32m---> 73\u001b[0m     qs \u001b[38;5;241m=\u001b[39m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_words\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, word \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(split_words):\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m qs:\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp-project/lib/python3.9/random.py:469\u001b[0m, in \u001b[0;36mRandom.sample\u001b[0;34m(self, population, k, counts)\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m selected:\n\u001b[1;32m    468\u001b[0m             j \u001b[38;5;241m=\u001b[39m randbelow(n)\n\u001b[0;32m--> 469\u001b[0m         \u001b[43mselected_add\u001b[49m\u001b[43m(\u001b[49m\u001b[43mj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m         result[i] \u001b[38;5;241m=\u001b[39m population[j]\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "augment_text_data_with_AEDA(sample, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timeit\n",
    "def augment_text_data_with_BT(text, repetition):\n",
    "    \"\"\"입력된 문장에 대해서 BT를 통해 데이터 증강\"\"\"\n",
    "    translator = Translator()\n",
    "    result = []\n",
    "\n",
    "    # 패턴 정의: #문자열#: 또는 #문자열# 추출\n",
    "    pattern = r'#.*?#:?'\n",
    "    matches = [(m.start(), m.end(), m.group()) for m in re.finditer(pattern, text)]\n",
    "    \n",
    "    cleaned_text = text\n",
    "    for start, end, match in matches:\n",
    "        cleaned_text = cleaned_text.replace(match, \"\")\n",
    "\n",
    "    # 번역 실행 (한국어 > 영어 > 한국어)\n",
    "    for i in range(repetition):\n",
    "        translated = translator.translate(cleaned_text, src='ko', dest='en')\n",
    "        re_translated = translator.translate(translated.text, src='en', dest='ko')\n",
    "        augmented_text = re_translated.text\n",
    "        \n",
    "        for start, end, match in matches:\n",
    "            augmented_text = augmented_text[:start] + match + augmented_text[start:]\n",
    "        \n",
    "        result.append(augmented_text)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_text_data_with_BT(sample, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_dataframe(df, repetition=1):\n",
    "    augmented_rows = []\n",
    "\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Augmenting Data\"):\n",
    "        original_dialogue = row['dialogue']\n",
    "        summary = row['summary']\n",
    "        topic = row['topic']\n",
    "\n",
    "        eda_augmented_texts = augment_text_data_with_EDA(original_dialogue, repetition)\n",
    "        aeda_augmented_texts = augment_text_data_with_AEDA(original_dialogue, repetition)\n",
    "        bt_augmented_texts = augment_text_data_with_BT(original_dialogue, repetition)\n",
    "\n",
    "        for text in eda_augmented_texts + bt_augmented_texts + aeda_augmented_texts:\n",
    "        # for text in eda_augmented_texts + bt_augmented_texts:\n",
    "            augmented_rows.append({\n",
    "                'dialogue': text,\n",
    "                'summary': summary,\n",
    "                'topic': topic\n",
    "            })\n",
    "\n",
    "\n",
    "    augmented_df = pd.DataFrame(augmented_rows)\n",
    "    result_df = pd.concat([df, augmented_df], ignore_index=True)\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmented_df = augment_dataframe(df, repetition=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmented_df.to_csv('../dataset/augmented_train.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
